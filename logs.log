2023-03-06 23:02:11,305:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-03-06 23:02:11,306:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-03-06 23:02:11,306:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-03-06 23:02:11,306:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-03-06 23:02:11,822:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-03-06 23:13:57,524:INFO:PyCaret RegressionExperiment
2023-03-06 23:13:57,524:INFO:Logging name: reg-default-name
2023-03-06 23:13:57,524:INFO:ML Usecase: MLUsecase.REGRESSION
2023-03-06 23:13:57,524:INFO:version 3.0.0.rc9
2023-03-06 23:13:57,524:INFO:Initializing setup()
2023-03-06 23:13:57,524:INFO:self.USI: 73b1
2023-03-06 23:13:57,524:INFO:self._variable_keys: {'data', 'USI', 'transform_target_param', 'X', '_available_plots', 'fold_shuffle_param', 'memory', 'gpu_n_jobs_param', 'exp_id', 'y_test', 'pipeline', 'fold_groups_param', 'idx', 'fold_generator', '_ml_usecase', 'target_param', 'html_param', 'exp_name_log', 'gpu_param', 'logging_param', 'seed', 'n_jobs_param', 'X_test', 'y', 'X_train', 'log_plots_param', 'y_train'}
2023-03-06 23:13:57,525:INFO:Checking environment
2023-03-06 23:13:57,525:INFO:python_version: 3.9.13
2023-03-06 23:13:57,525:INFO:python_build: ('main', 'Aug 25 2022 23:51:50')
2023-03-06 23:13:57,525:INFO:machine: AMD64
2023-03-06 23:13:57,534:INFO:platform: Windows-10-10.0.22621-SP0
2023-03-06 23:13:57,534:INFO:Memory: svmem(total=16540884992, available=7198515200, percent=56.5, used=9342369792, free=7198515200)
2023-03-06 23:13:57,534:INFO:Physical Core: 8
2023-03-06 23:13:57,534:INFO:Logical Core: 16
2023-03-06 23:13:57,534:INFO:Checking libraries
2023-03-06 23:13:57,534:INFO:System:
2023-03-06 23:13:57,534:INFO:    python: 3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]
2023-03-06 23:13:57,534:INFO:executable: C:\Users\Roshan\anaconda3\python.exe
2023-03-06 23:13:57,534:INFO:   machine: Windows-10-10.0.22621-SP0
2023-03-06 23:13:57,534:INFO:PyCaret required dependencies:
2023-03-06 23:13:57,534:INFO:                 pip: 22.2.2
2023-03-06 23:13:57,534:INFO:          setuptools: 63.4.1
2023-03-06 23:13:57,534:INFO:             pycaret: 3.0.0rc9
2023-03-06 23:13:57,534:INFO:             IPython: 7.31.1
2023-03-06 23:13:57,534:INFO:          ipywidgets: 7.6.5
2023-03-06 23:13:57,534:INFO:                tqdm: 4.64.1
2023-03-06 23:13:57,534:INFO:               numpy: 1.21.5
2023-03-06 23:13:57,534:INFO:              pandas: 1.4.4
2023-03-06 23:13:57,534:INFO:              jinja2: 2.11.3
2023-03-06 23:13:57,534:INFO:               scipy: 1.9.1
2023-03-06 23:13:57,534:INFO:              joblib: 1.2.0
2023-03-06 23:13:57,536:INFO:             sklearn: 1.0.2
2023-03-06 23:13:57,536:INFO:                pyod: 1.0.7
2023-03-06 23:13:57,536:INFO:            imblearn: 0.10.1
2023-03-06 23:13:57,536:INFO:   category_encoders: 2.6.0
2023-03-06 23:13:57,536:INFO:            lightgbm: 3.3.5
2023-03-06 23:13:57,536:INFO:               numba: 0.55.1
2023-03-06 23:13:57,536:INFO:            requests: 2.28.1
2023-03-06 23:13:57,536:INFO:          matplotlib: 3.5.2
2023-03-06 23:13:57,536:INFO:          scikitplot: 0.3.7
2023-03-06 23:13:57,536:INFO:         yellowbrick: 1.5
2023-03-06 23:13:57,536:INFO:              plotly: 5.9.0
2023-03-06 23:13:57,536:INFO:             kaleido: 0.2.1
2023-03-06 23:13:57,536:INFO:         statsmodels: 0.13.2
2023-03-06 23:13:57,536:INFO:              sktime: 0.16.1
2023-03-06 23:13:57,536:INFO:               tbats: 1.1.2
2023-03-06 23:13:57,536:INFO:            pmdarima: 2.0.2
2023-03-06 23:13:57,536:INFO:              psutil: 5.9.0
2023-03-06 23:13:57,536:INFO:PyCaret optional dependencies:
2023-03-06 23:13:57,549:INFO:                shap: Not installed
2023-03-06 23:13:57,549:INFO:           interpret: Not installed
2023-03-06 23:13:57,549:INFO:                umap: Not installed
2023-03-06 23:13:57,549:INFO:    pandas_profiling: 4.0.0
2023-03-06 23:13:57,549:INFO:  explainerdashboard: Not installed
2023-03-06 23:13:57,549:INFO:             autoviz: Not installed
2023-03-06 23:13:57,549:INFO:           fairlearn: Not installed
2023-03-06 23:13:57,549:INFO:             xgboost: Not installed
2023-03-06 23:13:57,549:INFO:            catboost: Not installed
2023-03-06 23:13:57,549:INFO:              kmodes: Not installed
2023-03-06 23:13:57,549:INFO:             mlxtend: Not installed
2023-03-06 23:13:57,549:INFO:       statsforecast: Not installed
2023-03-06 23:13:57,549:INFO:        tune_sklearn: Not installed
2023-03-06 23:13:57,549:INFO:                 ray: Not installed
2023-03-06 23:13:57,549:INFO:            hyperopt: Not installed
2023-03-06 23:13:57,549:INFO:              optuna: Not installed
2023-03-06 23:13:57,550:INFO:               skopt: Not installed
2023-03-06 23:13:57,550:INFO:              mlflow: Not installed
2023-03-06 23:13:57,550:INFO:              gradio: Not installed
2023-03-06 23:13:57,550:INFO:             fastapi: Not installed
2023-03-06 23:13:57,550:INFO:             uvicorn: Not installed
2023-03-06 23:13:57,550:INFO:              m2cgen: Not installed
2023-03-06 23:13:57,550:INFO:           evidently: Not installed
2023-03-06 23:13:57,550:INFO:               fugue: Not installed
2023-03-06 23:13:57,550:INFO:           streamlit: 1.19.0
2023-03-06 23:13:57,550:INFO:             prophet: Not installed
2023-03-06 23:13:57,550:INFO:None
2023-03-06 23:13:57,550:INFO:Set up data.
2023-03-06 23:13:57,560:INFO:Set up train/test split.
2023-03-06 23:13:57,569:INFO:Set up index.
2023-03-06 23:13:57,570:INFO:Set up folding strategy.
2023-03-06 23:13:57,570:INFO:Assigning column types.
2023-03-06 23:13:57,573:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-03-06 23:13:57,573:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-03-06 23:13:57,578:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-03-06 23:13:57,581:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-03-06 23:13:57,640:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-03-06 23:13:57,691:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-03-06 23:13:57,692:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-06 23:13:57,705:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-06 23:13:57,705:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-03-06 23:13:57,710:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-03-06 23:13:57,715:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-03-06 23:13:57,771:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-03-06 23:13:57,806:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-03-06 23:13:57,806:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-06 23:13:57,807:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-06 23:13:57,807:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-03-06 23:13:57,811:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-03-06 23:13:57,814:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-03-06 23:13:57,861:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-03-06 23:13:57,897:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-03-06 23:13:57,898:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-06 23:13:57,898:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-06 23:13:57,902:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-03-06 23:13:57,905:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-03-06 23:13:57,954:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-03-06 23:13:57,989:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-03-06 23:13:57,990:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-06 23:13:57,990:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-06 23:13:57,990:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-03-06 23:13:57,997:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-03-06 23:13:58,049:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-03-06 23:13:58,086:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-03-06 23:13:58,087:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-06 23:13:58,087:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-06 23:13:58,095:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-03-06 23:13:58,147:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-03-06 23:13:58,185:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-03-06 23:13:58,186:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-06 23:13:58,186:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-06 23:13:58,186:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-03-06 23:13:58,251:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-03-06 23:13:58,314:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-03-06 23:13:58,314:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-06 23:13:58,315:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-06 23:13:58,383:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-03-06 23:13:58,422:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-03-06 23:13:58,423:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-06 23:13:58,425:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-06 23:13:58,425:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-03-06 23:13:58,485:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-03-06 23:13:58,522:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-06 23:13:58,523:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-06 23:13:58,593:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-03-06 23:13:58,638:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-06 23:13:58,638:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-06 23:13:58,638:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-03-06 23:13:58,767:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-06 23:13:58,768:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-06 23:13:58,884:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-06 23:13:58,884:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-06 23:13:58,889:INFO:Preparing preprocessing pipeline...
2023-03-06 23:13:58,890:INFO:Set up column name cleaning.
2023-03-06 23:13:58,890:INFO:Set up simple imputation.
2023-03-06 23:13:58,894:INFO:Set up encoding of ordinal features.
2023-03-06 23:13:58,896:INFO:Set up encoding of categorical features.
2023-03-06 23:13:58,991:INFO:Finished creating preprocessing pipeline.
2023-03-06 23:13:59,012:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Roshan\AppData\Local\Temp\joblib),
         steps=[('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('numerical_imputer',
                 TransformerWrapper(include=['Unnamed: 0', 'Total Volume',
                                             '4046', '4225', '4770',
                                             'Total Bags', 'Small Bags',
                                             'Large Bags', 'XLarge Bags',
                                             'year'],
                                    transformer=SimpleImputer())),
                ('categ...
                 TransformerWrapper(include=['type'],
                                    transformer=OrdinalEncoder(cols=['type'],
                                                               handle_missing='return_nan',
                                                               mapping=[{'col': 'type',
                                                                         'data_type': dtype('O'),
                                                                         'mapping': conventional    0
organic         1
NaN            -1
dtype: int64}]))),
                ('rest_encoding',
                 TransformerWrapper(include=['Date', 'region'],
                                    transformer=LeaveOneOutEncoder(cols=['Date',
                                                                         'region'],
                                                                   handle_missing='return_nan',
                                                                   random_state=3702)))])
2023-03-06 23:13:59,012:INFO:Creating final display dataframe.
2023-03-06 23:13:59,445:INFO:Setup _display_container:                     Description             Value
0                    Session id              3702
1                        Target      AveragePrice
2                   Target type        Regression
3           Original data shape       (18249, 14)
4        Transformed data shape       (18249, 14)
5   Transformed train set shape       (12774, 14)
6    Transformed test set shape        (5475, 14)
7              Ordinal features                 1
8              Numeric features                10
9          Categorical features                 3
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16               Fold Generator             KFold
17                  Fold Number                10
18                     CPU Jobs                -1
19                      Use GPU             False
20               Log Experiment             False
21              Experiment Name  reg-default-name
22                          USI              73b1
2023-03-06 23:13:59,540:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-06 23:13:59,541:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-06 23:13:59,647:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-06 23:13:59,647:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-06 23:13:59,648:INFO:setup() successfully completed in 2.13s...............
2023-03-06 23:13:59,654:INFO:Initializing compare_models()
2023-03-06 23:13:59,654:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F40D2A8340>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x000001F40D2A8340>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-03-06 23:13:59,654:INFO:Checking exceptions
2023-03-06 23:13:59,657:INFO:Preparing display monitor
2023-03-06 23:13:59,661:INFO:Initializing Linear Regression
2023-03-06 23:13:59,661:INFO:Total runtime is 0.0 minutes
2023-03-06 23:13:59,661:INFO:SubProcess create_model() called ==================================
2023-03-06 23:13:59,661:INFO:Initializing create_model()
2023-03-06 23:13:59,661:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F40D2A8340>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F40D9975E0>, model_only=True, return_train_score=False, kwargs={})
2023-03-06 23:13:59,661:INFO:Checking exceptions
2023-03-06 23:13:59,662:INFO:Importing libraries
2023-03-06 23:13:59,662:INFO:Copying training dataset
2023-03-06 23:13:59,668:INFO:Defining folds
2023-03-06 23:13:59,668:INFO:Declaring metric variables
2023-03-06 23:13:59,668:INFO:Importing untrained model
2023-03-06 23:13:59,668:INFO:Linear Regression Imported successfully
2023-03-06 23:13:59,668:INFO:Starting cross validation
2023-03-06 23:13:59,676:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-06 23:14:05,801:INFO:Calculating mean and std
2023-03-06 23:14:05,802:INFO:Creating metrics dataframe
2023-03-06 23:14:05,809:INFO:Uploading results into container
2023-03-06 23:14:05,810:INFO:Uploading model into container now
2023-03-06 23:14:05,811:INFO:_master_model_container: 1
2023-03-06 23:14:05,811:INFO:_display_container: 2
2023-03-06 23:14:05,811:INFO:LinearRegression(n_jobs=-1)
2023-03-06 23:14:05,811:INFO:create_model() successfully completed......................................
2023-03-06 23:14:05,999:INFO:SubProcess create_model() end ==================================
2023-03-06 23:14:05,999:INFO:Creating metrics dataframe
2023-03-06 23:14:06,002:INFO:Initializing Lasso Regression
2023-03-06 23:14:06,002:INFO:Total runtime is 0.10569166739781698 minutes
2023-03-06 23:14:06,002:INFO:SubProcess create_model() called ==================================
2023-03-06 23:14:06,002:INFO:Initializing create_model()
2023-03-06 23:14:06,002:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F40D2A8340>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F40D9975E0>, model_only=True, return_train_score=False, kwargs={})
2023-03-06 23:14:06,002:INFO:Checking exceptions
2023-03-06 23:14:06,002:INFO:Importing libraries
2023-03-06 23:14:06,002:INFO:Copying training dataset
2023-03-06 23:14:06,008:INFO:Defining folds
2023-03-06 23:14:06,008:INFO:Declaring metric variables
2023-03-06 23:14:06,008:INFO:Importing untrained model
2023-03-06 23:14:06,008:INFO:Lasso Regression Imported successfully
2023-03-06 23:14:06,008:INFO:Starting cross validation
2023-03-06 23:14:06,009:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-06 23:14:06,537:WARNING:C:\Users\Roshan\anaconda3\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.204e+01, tolerance: 1.854e-01
  model = cd_fast.enet_coordinate_descent(

2023-03-06 23:14:06,539:WARNING:C:\Users\Roshan\anaconda3\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.251e+01, tolerance: 1.862e-01
  model = cd_fast.enet_coordinate_descent(

2023-03-06 23:14:06,539:WARNING:C:\Users\Roshan\anaconda3\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.108e+01, tolerance: 1.843e-01
  model = cd_fast.enet_coordinate_descent(

2023-03-06 23:14:06,542:WARNING:C:\Users\Roshan\anaconda3\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.225e+01, tolerance: 1.858e-01
  model = cd_fast.enet_coordinate_descent(

2023-03-06 23:14:09,181:WARNING:C:\Users\Roshan\anaconda3\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.235e+01, tolerance: 1.857e-01
  model = cd_fast.enet_coordinate_descent(

2023-03-06 23:14:09,216:WARNING:C:\Users\Roshan\anaconda3\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.206e+01, tolerance: 1.859e-01
  model = cd_fast.enet_coordinate_descent(

2023-03-06 23:14:09,261:WARNING:C:\Users\Roshan\anaconda3\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.058e+01, tolerance: 1.848e-01
  model = cd_fast.enet_coordinate_descent(

2023-03-06 23:14:09,330:WARNING:C:\Users\Roshan\anaconda3\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.163e+01, tolerance: 1.856e-01
  model = cd_fast.enet_coordinate_descent(

2023-03-06 23:14:09,341:WARNING:C:\Users\Roshan\anaconda3\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.192e+01, tolerance: 1.855e-01
  model = cd_fast.enet_coordinate_descent(

2023-03-06 23:14:09,403:WARNING:C:\Users\Roshan\anaconda3\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.203e+01, tolerance: 1.854e-01
  model = cd_fast.enet_coordinate_descent(

2023-03-06 23:14:09,502:INFO:Calculating mean and std
2023-03-06 23:14:09,503:INFO:Creating metrics dataframe
2023-03-06 23:14:09,506:INFO:Uploading results into container
2023-03-06 23:14:09,506:INFO:Uploading model into container now
2023-03-06 23:14:09,506:INFO:_master_model_container: 2
2023-03-06 23:14:09,506:INFO:_display_container: 2
2023-03-06 23:14:09,507:INFO:Lasso(random_state=3702)
2023-03-06 23:14:09,507:INFO:create_model() successfully completed......................................
2023-03-06 23:14:09,626:INFO:SubProcess create_model() end ==================================
2023-03-06 23:14:09,626:INFO:Creating metrics dataframe
2023-03-06 23:14:09,630:INFO:Initializing Ridge Regression
2023-03-06 23:14:09,630:INFO:Total runtime is 0.16616347233454387 minutes
2023-03-06 23:14:09,630:INFO:SubProcess create_model() called ==================================
2023-03-06 23:14:09,630:INFO:Initializing create_model()
2023-03-06 23:14:09,631:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F40D2A8340>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F40D9975E0>, model_only=True, return_train_score=False, kwargs={})
2023-03-06 23:14:09,631:INFO:Checking exceptions
2023-03-06 23:14:09,631:INFO:Importing libraries
2023-03-06 23:14:09,631:INFO:Copying training dataset
2023-03-06 23:14:09,636:INFO:Defining folds
2023-03-06 23:14:09,636:INFO:Declaring metric variables
2023-03-06 23:14:09,636:INFO:Importing untrained model
2023-03-06 23:14:09,637:INFO:Ridge Regression Imported successfully
2023-03-06 23:14:09,637:INFO:Starting cross validation
2023-03-06 23:14:09,638:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-06 23:14:09,955:WARNING:C:\Users\Roshan\anaconda3\lib\site-packages\sklearn\linear_model\_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=7.83755e-17): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2023-03-06 23:14:09,959:WARNING:C:\Users\Roshan\anaconda3\lib\site-packages\sklearn\linear_model\_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=4.7726e-17): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2023-03-06 23:14:09,981:WARNING:C:\Users\Roshan\anaconda3\lib\site-packages\sklearn\linear_model\_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=4.71536e-17): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2023-03-06 23:14:10,011:WARNING:C:\Users\Roshan\anaconda3\lib\site-packages\sklearn\linear_model\_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=6.58673e-17): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2023-03-06 23:14:10,016:WARNING:C:\Users\Roshan\anaconda3\lib\site-packages\sklearn\linear_model\_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=1.07284e-16): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2023-03-06 23:14:10,040:WARNING:C:\Users\Roshan\anaconda3\lib\site-packages\sklearn\linear_model\_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=8.29064e-17): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2023-03-06 23:14:10,110:INFO:Calculating mean and std
2023-03-06 23:14:10,110:INFO:Creating metrics dataframe
2023-03-06 23:14:10,113:INFO:Uploading results into container
2023-03-06 23:14:10,113:INFO:Uploading model into container now
2023-03-06 23:14:10,113:INFO:_master_model_container: 3
2023-03-06 23:14:10,113:INFO:_display_container: 2
2023-03-06 23:14:10,113:INFO:Ridge(random_state=3702)
2023-03-06 23:14:10,113:INFO:create_model() successfully completed......................................
2023-03-06 23:14:10,228:INFO:SubProcess create_model() end ==================================
2023-03-06 23:14:10,228:INFO:Creating metrics dataframe
2023-03-06 23:14:10,231:INFO:Initializing Elastic Net
2023-03-06 23:14:10,231:INFO:Total runtime is 0.17617910305658976 minutes
2023-03-06 23:14:10,231:INFO:SubProcess create_model() called ==================================
2023-03-06 23:14:10,231:INFO:Initializing create_model()
2023-03-06 23:14:10,231:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F40D2A8340>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F40D9975E0>, model_only=True, return_train_score=False, kwargs={})
2023-03-06 23:14:10,231:INFO:Checking exceptions
2023-03-06 23:14:10,232:INFO:Importing libraries
2023-03-06 23:14:10,232:INFO:Copying training dataset
2023-03-06 23:14:10,237:INFO:Defining folds
2023-03-06 23:14:10,237:INFO:Declaring metric variables
2023-03-06 23:14:10,238:INFO:Importing untrained model
2023-03-06 23:14:10,238:INFO:Elastic Net Imported successfully
2023-03-06 23:14:10,238:INFO:Starting cross validation
2023-03-06 23:14:10,239:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-06 23:14:10,571:WARNING:C:\Users\Roshan\anaconda3\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.609e+01, tolerance: 1.848e-01
  model = cd_fast.enet_coordinate_descent(

2023-03-06 23:14:10,613:WARNING:C:\Users\Roshan\anaconda3\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.917e+01, tolerance: 1.857e-01
  model = cd_fast.enet_coordinate_descent(

2023-03-06 23:14:10,633:WARNING:C:\Users\Roshan\anaconda3\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.902e+01, tolerance: 1.859e-01
  model = cd_fast.enet_coordinate_descent(

2023-03-06 23:14:10,645:WARNING:C:\Users\Roshan\anaconda3\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.852e+01, tolerance: 1.855e-01
  model = cd_fast.enet_coordinate_descent(

2023-03-06 23:14:10,736:WARNING:C:\Users\Roshan\anaconda3\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.810e+01, tolerance: 1.856e-01
  model = cd_fast.enet_coordinate_descent(

2023-03-06 23:14:10,741:WARNING:C:\Users\Roshan\anaconda3\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.859e+01, tolerance: 1.854e-01
  model = cd_fast.enet_coordinate_descent(

2023-03-06 23:14:10,774:WARNING:C:\Users\Roshan\anaconda3\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.910e+01, tolerance: 1.854e-01
  model = cd_fast.enet_coordinate_descent(

2023-03-06 23:14:10,812:WARNING:C:\Users\Roshan\anaconda3\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.912e+01, tolerance: 1.858e-01
  model = cd_fast.enet_coordinate_descent(

2023-03-06 23:14:10,839:WARNING:C:\Users\Roshan\anaconda3\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.964e+01, tolerance: 1.862e-01
  model = cd_fast.enet_coordinate_descent(

2023-03-06 23:14:10,844:WARNING:C:\Users\Roshan\anaconda3\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.706e+01, tolerance: 1.843e-01
  model = cd_fast.enet_coordinate_descent(

2023-03-06 23:14:10,941:INFO:Calculating mean and std
2023-03-06 23:14:10,941:INFO:Creating metrics dataframe
2023-03-06 23:14:10,944:INFO:Uploading results into container
2023-03-06 23:14:10,945:INFO:Uploading model into container now
2023-03-06 23:14:10,945:INFO:_master_model_container: 4
2023-03-06 23:14:10,945:INFO:_display_container: 2
2023-03-06 23:14:10,945:INFO:ElasticNet(random_state=3702)
2023-03-06 23:14:10,945:INFO:create_model() successfully completed......................................
2023-03-06 23:14:11,060:INFO:SubProcess create_model() end ==================================
2023-03-06 23:14:11,060:INFO:Creating metrics dataframe
2023-03-06 23:14:11,064:INFO:Initializing Least Angle Regression
2023-03-06 23:14:11,064:INFO:Total runtime is 0.1900537093480428 minutes
2023-03-06 23:14:11,064:INFO:SubProcess create_model() called ==================================
2023-03-06 23:14:11,065:INFO:Initializing create_model()
2023-03-06 23:14:11,065:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F40D2A8340>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F40D9975E0>, model_only=True, return_train_score=False, kwargs={})
2023-03-06 23:14:11,065:INFO:Checking exceptions
2023-03-06 23:14:11,065:INFO:Importing libraries
2023-03-06 23:14:11,065:INFO:Copying training dataset
2023-03-06 23:14:11,071:INFO:Defining folds
2023-03-06 23:14:11,071:INFO:Declaring metric variables
2023-03-06 23:14:11,071:INFO:Importing untrained model
2023-03-06 23:14:11,071:INFO:Least Angle Regression Imported successfully
2023-03-06 23:14:11,072:INFO:Starting cross validation
2023-03-06 23:14:11,072:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-06 23:14:11,358:WARNING:C:\Users\Roshan\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-03-06 23:14:11,360:WARNING:C:\Users\Roshan\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-03-06 23:14:11,362:WARNING:C:\Users\Roshan\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-03-06 23:14:11,362:WARNING:C:\Users\Roshan\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-03-06 23:14:11,387:WARNING:C:\Users\Roshan\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-03-06 23:14:11,391:WARNING:C:\Users\Roshan\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-03-06 23:14:11,414:WARNING:C:\Users\Roshan\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-03-06 23:14:11,432:WARNING:C:\Users\Roshan\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-03-06 23:14:11,454:WARNING:C:\Users\Roshan\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-03-06 23:14:11,465:WARNING:C:\Users\Roshan\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-03-06 23:14:11,544:INFO:Calculating mean and std
2023-03-06 23:14:11,544:INFO:Creating metrics dataframe
2023-03-06 23:14:11,547:INFO:Uploading results into container
2023-03-06 23:14:11,547:INFO:Uploading model into container now
2023-03-06 23:14:11,548:INFO:_master_model_container: 5
2023-03-06 23:14:11,548:INFO:_display_container: 2
2023-03-06 23:14:11,548:INFO:Lars(random_state=3702)
2023-03-06 23:14:11,548:INFO:create_model() successfully completed......................................
2023-03-06 23:14:11,670:INFO:SubProcess create_model() end ==================================
2023-03-06 23:14:11,670:INFO:Creating metrics dataframe
2023-03-06 23:14:11,675:INFO:Initializing Lasso Least Angle Regression
2023-03-06 23:14:11,675:INFO:Total runtime is 0.20023725032806397 minutes
2023-03-06 23:14:11,676:INFO:SubProcess create_model() called ==================================
2023-03-06 23:14:11,676:INFO:Initializing create_model()
2023-03-06 23:14:11,676:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F40D2A8340>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F40D9975E0>, model_only=True, return_train_score=False, kwargs={})
2023-03-06 23:14:11,676:INFO:Checking exceptions
2023-03-06 23:14:11,676:INFO:Importing libraries
2023-03-06 23:14:11,676:INFO:Copying training dataset
2023-03-06 23:14:11,683:INFO:Defining folds
2023-03-06 23:14:11,683:INFO:Declaring metric variables
2023-03-06 23:14:11,683:INFO:Importing untrained model
2023-03-06 23:14:11,683:INFO:Lasso Least Angle Regression Imported successfully
2023-03-06 23:14:11,684:INFO:Starting cross validation
2023-03-06 23:14:11,684:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-06 23:14:11,928:WARNING:C:\Users\Roshan\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-03-06 23:14:11,941:WARNING:C:\Users\Roshan\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-03-06 23:14:11,953:WARNING:C:\Users\Roshan\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-03-06 23:14:11,983:WARNING:C:\Users\Roshan\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-03-06 23:14:11,992:WARNING:C:\Users\Roshan\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-03-06 23:14:12,008:WARNING:C:\Users\Roshan\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-03-06 23:14:12,024:WARNING:C:\Users\Roshan\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-03-06 23:14:12,045:WARNING:C:\Users\Roshan\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-03-06 23:14:12,046:WARNING:C:\Users\Roshan\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-03-06 23:14:12,073:WARNING:C:\Users\Roshan\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-03-06 23:14:12,147:INFO:Calculating mean and std
2023-03-06 23:14:12,148:INFO:Creating metrics dataframe
2023-03-06 23:14:12,150:INFO:Uploading results into container
2023-03-06 23:14:12,150:INFO:Uploading model into container now
2023-03-06 23:14:12,151:INFO:_master_model_container: 6
2023-03-06 23:14:12,151:INFO:_display_container: 2
2023-03-06 23:14:12,151:INFO:LassoLars(random_state=3702)
2023-03-06 23:14:12,151:INFO:create_model() successfully completed......................................
2023-03-06 23:14:12,274:INFO:SubProcess create_model() end ==================================
2023-03-06 23:14:12,274:INFO:Creating metrics dataframe
2023-03-06 23:14:12,277:INFO:Initializing Orthogonal Matching Pursuit
2023-03-06 23:14:12,277:INFO:Total runtime is 0.21027784744898478 minutes
2023-03-06 23:14:12,277:INFO:SubProcess create_model() called ==================================
2023-03-06 23:14:12,278:INFO:Initializing create_model()
2023-03-06 23:14:12,278:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F40D2A8340>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F40D9975E0>, model_only=True, return_train_score=False, kwargs={})
2023-03-06 23:14:12,278:INFO:Checking exceptions
2023-03-06 23:14:12,278:INFO:Importing libraries
2023-03-06 23:14:12,278:INFO:Copying training dataset
2023-03-06 23:14:12,284:INFO:Defining folds
2023-03-06 23:14:12,284:INFO:Declaring metric variables
2023-03-06 23:14:12,284:INFO:Importing untrained model
2023-03-06 23:14:12,284:INFO:Orthogonal Matching Pursuit Imported successfully
2023-03-06 23:14:12,284:INFO:Starting cross validation
2023-03-06 23:14:12,285:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-06 23:14:12,518:WARNING:C:\Users\Roshan\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-03-06 23:14:12,525:WARNING:C:\Users\Roshan\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-03-06 23:14:12,563:WARNING:C:\Users\Roshan\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-03-06 23:14:12,565:WARNING:C:\Users\Roshan\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-03-06 23:14:12,583:WARNING:C:\Users\Roshan\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-03-06 23:14:12,607:WARNING:C:\Users\Roshan\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-03-06 23:14:12,611:WARNING:C:\Users\Roshan\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-03-06 23:14:12,644:WARNING:C:\Users\Roshan\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-03-06 23:14:12,651:WARNING:C:\Users\Roshan\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-03-06 23:14:12,674:WARNING:C:\Users\Roshan\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-03-06 23:14:12,754:INFO:Calculating mean and std
2023-03-06 23:14:12,754:INFO:Creating metrics dataframe
2023-03-06 23:14:12,757:INFO:Uploading results into container
2023-03-06 23:14:12,758:INFO:Uploading model into container now
2023-03-06 23:14:12,758:INFO:_master_model_container: 7
2023-03-06 23:14:12,758:INFO:_display_container: 2
2023-03-06 23:14:12,758:INFO:OrthogonalMatchingPursuit()
2023-03-06 23:14:12,759:INFO:create_model() successfully completed......................................
2023-03-06 23:14:12,892:INFO:SubProcess create_model() end ==================================
2023-03-06 23:14:12,892:INFO:Creating metrics dataframe
2023-03-06 23:14:12,895:INFO:Initializing Bayesian Ridge
2023-03-06 23:14:12,895:INFO:Total runtime is 0.22057258685429892 minutes
2023-03-06 23:14:12,895:INFO:SubProcess create_model() called ==================================
2023-03-06 23:14:12,895:INFO:Initializing create_model()
2023-03-06 23:14:12,896:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F40D2A8340>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F40D9975E0>, model_only=True, return_train_score=False, kwargs={})
2023-03-06 23:14:12,896:INFO:Checking exceptions
2023-03-06 23:14:12,896:INFO:Importing libraries
2023-03-06 23:14:12,896:INFO:Copying training dataset
2023-03-06 23:14:12,901:INFO:Defining folds
2023-03-06 23:14:12,901:INFO:Declaring metric variables
2023-03-06 23:14:12,901:INFO:Importing untrained model
2023-03-06 23:14:12,901:INFO:Bayesian Ridge Imported successfully
2023-03-06 23:14:12,901:INFO:Starting cross validation
2023-03-06 23:14:12,902:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-06 23:14:13,367:INFO:Calculating mean and std
2023-03-06 23:14:13,367:INFO:Creating metrics dataframe
2023-03-06 23:14:13,370:INFO:Uploading results into container
2023-03-06 23:14:13,370:INFO:Uploading model into container now
2023-03-06 23:14:13,370:INFO:_master_model_container: 8
2023-03-06 23:14:13,370:INFO:_display_container: 2
2023-03-06 23:14:13,371:INFO:BayesianRidge()
2023-03-06 23:14:13,371:INFO:create_model() successfully completed......................................
2023-03-06 23:14:13,483:INFO:SubProcess create_model() end ==================================
2023-03-06 23:14:13,483:INFO:Creating metrics dataframe
2023-03-06 23:14:13,487:INFO:Initializing Passive Aggressive Regressor
2023-03-06 23:14:13,487:INFO:Total runtime is 0.2304382920265198 minutes
2023-03-06 23:14:13,487:INFO:SubProcess create_model() called ==================================
2023-03-06 23:14:13,487:INFO:Initializing create_model()
2023-03-06 23:14:13,487:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F40D2A8340>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F40D9975E0>, model_only=True, return_train_score=False, kwargs={})
2023-03-06 23:14:13,487:INFO:Checking exceptions
2023-03-06 23:14:13,487:INFO:Importing libraries
2023-03-06 23:14:13,487:INFO:Copying training dataset
2023-03-06 23:14:13,493:INFO:Defining folds
2023-03-06 23:14:13,493:INFO:Declaring metric variables
2023-03-06 23:14:13,493:INFO:Importing untrained model
2023-03-06 23:14:13,493:INFO:Passive Aggressive Regressor Imported successfully
2023-03-06 23:14:13,493:INFO:Starting cross validation
2023-03-06 23:14:13,494:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-06 23:14:13,964:INFO:Calculating mean and std
2023-03-06 23:14:13,965:INFO:Creating metrics dataframe
2023-03-06 23:14:13,967:INFO:Uploading results into container
2023-03-06 23:14:13,967:INFO:Uploading model into container now
2023-03-06 23:14:13,968:INFO:_master_model_container: 9
2023-03-06 23:14:13,968:INFO:_display_container: 2
2023-03-06 23:14:13,968:INFO:PassiveAggressiveRegressor(random_state=3702)
2023-03-06 23:14:13,968:INFO:create_model() successfully completed......................................
2023-03-06 23:14:14,081:INFO:SubProcess create_model() end ==================================
2023-03-06 23:14:14,081:INFO:Creating metrics dataframe
2023-03-06 23:14:14,085:INFO:Initializing Huber Regressor
2023-03-06 23:14:14,085:INFO:Total runtime is 0.2404048045476278 minutes
2023-03-06 23:14:14,085:INFO:SubProcess create_model() called ==================================
2023-03-06 23:14:14,085:INFO:Initializing create_model()
2023-03-06 23:14:14,085:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F40D2A8340>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F40D9975E0>, model_only=True, return_train_score=False, kwargs={})
2023-03-06 23:14:14,085:INFO:Checking exceptions
2023-03-06 23:14:14,085:INFO:Importing libraries
2023-03-06 23:14:14,085:INFO:Copying training dataset
2023-03-06 23:14:14,091:INFO:Defining folds
2023-03-06 23:14:14,091:INFO:Declaring metric variables
2023-03-06 23:14:14,091:INFO:Importing untrained model
2023-03-06 23:14:14,091:INFO:Huber Regressor Imported successfully
2023-03-06 23:14:14,091:INFO:Starting cross validation
2023-03-06 23:14:14,092:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-06 23:14:15,050:INFO:Calculating mean and std
2023-03-06 23:14:15,050:INFO:Creating metrics dataframe
2023-03-06 23:14:15,052:INFO:Uploading results into container
2023-03-06 23:14:15,053:INFO:Uploading model into container now
2023-03-06 23:14:15,053:INFO:_master_model_container: 10
2023-03-06 23:14:15,053:INFO:_display_container: 2
2023-03-06 23:14:15,053:INFO:HuberRegressor()
2023-03-06 23:14:15,053:INFO:create_model() successfully completed......................................
2023-03-06 23:14:15,168:INFO:SubProcess create_model() end ==================================
2023-03-06 23:14:15,168:INFO:Creating metrics dataframe
2023-03-06 23:14:15,171:INFO:Initializing K Neighbors Regressor
2023-03-06 23:14:15,171:INFO:Total runtime is 0.25850211381912236 minutes
2023-03-06 23:14:15,172:INFO:SubProcess create_model() called ==================================
2023-03-06 23:14:15,172:INFO:Initializing create_model()
2023-03-06 23:14:15,172:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F40D2A8340>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F40D9975E0>, model_only=True, return_train_score=False, kwargs={})
2023-03-06 23:14:15,172:INFO:Checking exceptions
2023-03-06 23:14:15,172:INFO:Importing libraries
2023-03-06 23:14:15,172:INFO:Copying training dataset
2023-03-06 23:14:15,177:INFO:Defining folds
2023-03-06 23:14:15,177:INFO:Declaring metric variables
2023-03-06 23:14:15,177:INFO:Importing untrained model
2023-03-06 23:14:15,177:INFO:K Neighbors Regressor Imported successfully
2023-03-06 23:14:15,178:INFO:Starting cross validation
2023-03-06 23:14:15,179:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-06 23:14:15,679:INFO:Calculating mean and std
2023-03-06 23:14:15,680:INFO:Creating metrics dataframe
2023-03-06 23:14:15,683:INFO:Uploading results into container
2023-03-06 23:14:15,683:INFO:Uploading model into container now
2023-03-06 23:14:15,683:INFO:_master_model_container: 11
2023-03-06 23:14:15,684:INFO:_display_container: 2
2023-03-06 23:14:15,684:INFO:KNeighborsRegressor(n_jobs=-1)
2023-03-06 23:14:15,684:INFO:create_model() successfully completed......................................
2023-03-06 23:14:15,811:INFO:SubProcess create_model() end ==================================
2023-03-06 23:14:15,811:INFO:Creating metrics dataframe
2023-03-06 23:14:15,816:INFO:Initializing Decision Tree Regressor
2023-03-06 23:14:15,816:INFO:Total runtime is 0.2692498326301575 minutes
2023-03-06 23:14:15,816:INFO:SubProcess create_model() called ==================================
2023-03-06 23:14:15,817:INFO:Initializing create_model()
2023-03-06 23:14:15,817:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F40D2A8340>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F40D9975E0>, model_only=True, return_train_score=False, kwargs={})
2023-03-06 23:14:15,817:INFO:Checking exceptions
2023-03-06 23:14:15,817:INFO:Importing libraries
2023-03-06 23:14:15,817:INFO:Copying training dataset
2023-03-06 23:14:15,825:INFO:Defining folds
2023-03-06 23:14:15,825:INFO:Declaring metric variables
2023-03-06 23:14:15,825:INFO:Importing untrained model
2023-03-06 23:14:15,825:INFO:Decision Tree Regressor Imported successfully
2023-03-06 23:14:15,826:INFO:Starting cross validation
2023-03-06 23:14:15,827:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-06 23:14:16,475:INFO:Calculating mean and std
2023-03-06 23:14:16,475:INFO:Creating metrics dataframe
2023-03-06 23:14:16,478:INFO:Uploading results into container
2023-03-06 23:14:16,479:INFO:Uploading model into container now
2023-03-06 23:14:16,479:INFO:_master_model_container: 12
2023-03-06 23:14:16,479:INFO:_display_container: 2
2023-03-06 23:14:16,479:INFO:DecisionTreeRegressor(random_state=3702)
2023-03-06 23:14:16,479:INFO:create_model() successfully completed......................................
2023-03-06 23:14:16,595:INFO:SubProcess create_model() end ==================================
2023-03-06 23:14:16,595:INFO:Creating metrics dataframe
2023-03-06 23:14:16,599:INFO:Initializing Random Forest Regressor
2023-03-06 23:14:16,599:INFO:Total runtime is 0.28230946461359663 minutes
2023-03-06 23:14:16,599:INFO:SubProcess create_model() called ==================================
2023-03-06 23:14:16,599:INFO:Initializing create_model()
2023-03-06 23:14:16,599:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F40D2A8340>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F40D9975E0>, model_only=True, return_train_score=False, kwargs={})
2023-03-06 23:14:16,599:INFO:Checking exceptions
2023-03-06 23:14:16,599:INFO:Importing libraries
2023-03-06 23:14:16,599:INFO:Copying training dataset
2023-03-06 23:14:16,606:INFO:Defining folds
2023-03-06 23:14:16,606:INFO:Declaring metric variables
2023-03-06 23:14:16,606:INFO:Importing untrained model
2023-03-06 23:14:16,607:INFO:Random Forest Regressor Imported successfully
2023-03-06 23:14:16,607:INFO:Starting cross validation
2023-03-06 23:14:16,608:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-06 23:14:20,179:WARNING:C:\Users\Roshan\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.81s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-06 23:14:21,835:WARNING:C:\Users\Roshan\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 1.18s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-06 23:14:22,821:WARNING:C:\Users\Roshan\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:108: UserWarning: Persisting input arguments took 1.20s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = pipeline._memory_transform(transformer, X, y)

2023-03-06 23:14:22,880:WARNING:C:\Users\Roshan\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 1.68s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-06 23:14:23,454:WARNING:C:\Users\Roshan\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.71s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-06 23:14:23,807:WARNING:C:\Users\Roshan\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.85s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-06 23:14:23,995:WARNING:C:\Users\Roshan\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-06 23:14:24,132:WARNING:C:\Users\Roshan\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 0.99s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-03-06 23:14:24,458:INFO:Calculating mean and std
2023-03-06 23:14:24,459:INFO:Creating metrics dataframe
2023-03-06 23:14:24,463:INFO:Uploading results into container
2023-03-06 23:14:24,463:INFO:Uploading model into container now
2023-03-06 23:14:24,464:INFO:_master_model_container: 13
2023-03-06 23:14:24,464:INFO:_display_container: 2
2023-03-06 23:14:24,464:INFO:RandomForestRegressor(n_jobs=-1, random_state=3702)
2023-03-06 23:14:24,465:INFO:create_model() successfully completed......................................
2023-03-06 23:14:24,607:INFO:SubProcess create_model() end ==================================
2023-03-06 23:14:24,607:INFO:Creating metrics dataframe
2023-03-06 23:14:24,611:INFO:Initializing Extra Trees Regressor
2023-03-06 23:14:24,611:INFO:Total runtime is 0.41583485603332526 minutes
2023-03-06 23:14:24,612:INFO:SubProcess create_model() called ==================================
2023-03-06 23:14:24,612:INFO:Initializing create_model()
2023-03-06 23:14:24,612:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F40D2A8340>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F40D9975E0>, model_only=True, return_train_score=False, kwargs={})
2023-03-06 23:14:24,612:INFO:Checking exceptions
2023-03-06 23:14:24,612:INFO:Importing libraries
2023-03-06 23:14:24,612:INFO:Copying training dataset
2023-03-06 23:14:24,618:INFO:Defining folds
2023-03-06 23:14:24,618:INFO:Declaring metric variables
2023-03-06 23:14:24,618:INFO:Importing untrained model
2023-03-06 23:14:24,618:INFO:Extra Trees Regressor Imported successfully
2023-03-06 23:14:24,618:INFO:Starting cross validation
2023-03-06 23:14:24,619:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-06 23:14:27,750:WARNING:C:\Users\Roshan\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.97s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-06 23:14:27,755:WARNING:C:\Users\Roshan\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 1.05s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-06 23:14:28,541:INFO:Calculating mean and std
2023-03-06 23:14:28,542:INFO:Creating metrics dataframe
2023-03-06 23:14:28,546:INFO:Uploading results into container
2023-03-06 23:14:28,547:INFO:Uploading model into container now
2023-03-06 23:14:28,547:INFO:_master_model_container: 14
2023-03-06 23:14:28,547:INFO:_display_container: 2
2023-03-06 23:14:28,548:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=3702)
2023-03-06 23:14:28,548:INFO:create_model() successfully completed......................................
2023-03-06 23:14:28,703:INFO:SubProcess create_model() end ==================================
2023-03-06 23:14:28,703:INFO:Creating metrics dataframe
2023-03-06 23:14:28,708:INFO:Initializing AdaBoost Regressor
2023-03-06 23:14:28,708:INFO:Total runtime is 0.4841249108314515 minutes
2023-03-06 23:14:28,709:INFO:SubProcess create_model() called ==================================
2023-03-06 23:14:28,709:INFO:Initializing create_model()
2023-03-06 23:14:28,709:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F40D2A8340>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F40D9975E0>, model_only=True, return_train_score=False, kwargs={})
2023-03-06 23:14:28,709:INFO:Checking exceptions
2023-03-06 23:14:28,709:INFO:Importing libraries
2023-03-06 23:14:28,709:INFO:Copying training dataset
2023-03-06 23:14:28,717:INFO:Defining folds
2023-03-06 23:14:28,717:INFO:Declaring metric variables
2023-03-06 23:14:28,717:INFO:Importing untrained model
2023-03-06 23:14:28,718:INFO:AdaBoost Regressor Imported successfully
2023-03-06 23:14:28,718:INFO:Starting cross validation
2023-03-06 23:14:28,720:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-06 23:14:30,712:INFO:Calculating mean and std
2023-03-06 23:14:30,714:INFO:Creating metrics dataframe
2023-03-06 23:14:30,717:INFO:Uploading results into container
2023-03-06 23:14:30,717:INFO:Uploading model into container now
2023-03-06 23:14:30,717:INFO:_master_model_container: 15
2023-03-06 23:14:30,717:INFO:_display_container: 2
2023-03-06 23:14:30,718:INFO:AdaBoostRegressor(random_state=3702)
2023-03-06 23:14:30,718:INFO:create_model() successfully completed......................................
2023-03-06 23:14:30,836:INFO:SubProcess create_model() end ==================================
2023-03-06 23:14:30,836:INFO:Creating metrics dataframe
2023-03-06 23:14:30,841:INFO:Initializing Gradient Boosting Regressor
2023-03-06 23:14:30,841:INFO:Total runtime is 0.5196657697359721 minutes
2023-03-06 23:14:30,841:INFO:SubProcess create_model() called ==================================
2023-03-06 23:14:30,841:INFO:Initializing create_model()
2023-03-06 23:14:30,841:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F40D2A8340>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F40D9975E0>, model_only=True, return_train_score=False, kwargs={})
2023-03-06 23:14:30,841:INFO:Checking exceptions
2023-03-06 23:14:30,842:INFO:Importing libraries
2023-03-06 23:14:30,842:INFO:Copying training dataset
2023-03-06 23:14:30,850:INFO:Defining folds
2023-03-06 23:14:30,850:INFO:Declaring metric variables
2023-03-06 23:14:30,850:INFO:Importing untrained model
2023-03-06 23:14:30,851:INFO:Gradient Boosting Regressor Imported successfully
2023-03-06 23:14:30,851:INFO:Starting cross validation
2023-03-06 23:14:30,852:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-06 23:14:35,108:INFO:Calculating mean and std
2023-03-06 23:14:35,109:INFO:Creating metrics dataframe
2023-03-06 23:14:35,111:INFO:Uploading results into container
2023-03-06 23:14:35,111:INFO:Uploading model into container now
2023-03-06 23:14:35,111:INFO:_master_model_container: 16
2023-03-06 23:14:35,111:INFO:_display_container: 2
2023-03-06 23:14:35,112:INFO:GradientBoostingRegressor(random_state=3702)
2023-03-06 23:14:35,112:INFO:create_model() successfully completed......................................
2023-03-06 23:14:35,224:INFO:SubProcess create_model() end ==================================
2023-03-06 23:14:35,224:INFO:Creating metrics dataframe
2023-03-06 23:14:35,227:INFO:Initializing Light Gradient Boosting Machine
2023-03-06 23:14:35,227:INFO:Total runtime is 0.5927747209866842 minutes
2023-03-06 23:14:35,227:INFO:SubProcess create_model() called ==================================
2023-03-06 23:14:35,227:INFO:Initializing create_model()
2023-03-06 23:14:35,227:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F40D2A8340>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F40D9975E0>, model_only=True, return_train_score=False, kwargs={})
2023-03-06 23:14:35,228:INFO:Checking exceptions
2023-03-06 23:14:35,228:INFO:Importing libraries
2023-03-06 23:14:35,228:INFO:Copying training dataset
2023-03-06 23:14:35,234:INFO:Defining folds
2023-03-06 23:14:35,234:INFO:Declaring metric variables
2023-03-06 23:14:35,234:INFO:Importing untrained model
2023-03-06 23:14:35,234:INFO:Light Gradient Boosting Machine Imported successfully
2023-03-06 23:14:35,235:INFO:Starting cross validation
2023-03-06 23:14:35,236:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-06 23:14:37,021:INFO:Calculating mean and std
2023-03-06 23:14:37,022:INFO:Creating metrics dataframe
2023-03-06 23:14:37,025:INFO:Uploading results into container
2023-03-06 23:14:37,025:INFO:Uploading model into container now
2023-03-06 23:14:37,025:INFO:_master_model_container: 17
2023-03-06 23:14:37,025:INFO:_display_container: 2
2023-03-06 23:14:37,026:INFO:LGBMRegressor(random_state=3702)
2023-03-06 23:14:37,026:INFO:create_model() successfully completed......................................
2023-03-06 23:14:37,146:INFO:SubProcess create_model() end ==================================
2023-03-06 23:14:37,146:INFO:Creating metrics dataframe
2023-03-06 23:14:37,149:INFO:Initializing Dummy Regressor
2023-03-06 23:14:37,150:INFO:Total runtime is 0.6248200893402099 minutes
2023-03-06 23:14:37,150:INFO:SubProcess create_model() called ==================================
2023-03-06 23:14:37,150:INFO:Initializing create_model()
2023-03-06 23:14:37,150:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F40D2A8340>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F40D9975E0>, model_only=True, return_train_score=False, kwargs={})
2023-03-06 23:14:37,150:INFO:Checking exceptions
2023-03-06 23:14:37,150:INFO:Importing libraries
2023-03-06 23:14:37,150:INFO:Copying training dataset
2023-03-06 23:14:37,156:INFO:Defining folds
2023-03-06 23:14:37,157:INFO:Declaring metric variables
2023-03-06 23:14:37,157:INFO:Importing untrained model
2023-03-06 23:14:37,157:INFO:Dummy Regressor Imported successfully
2023-03-06 23:14:37,157:INFO:Starting cross validation
2023-03-06 23:14:37,159:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-06 23:14:37,609:INFO:Calculating mean and std
2023-03-06 23:14:37,609:INFO:Creating metrics dataframe
2023-03-06 23:14:37,611:INFO:Uploading results into container
2023-03-06 23:14:37,612:INFO:Uploading model into container now
2023-03-06 23:14:37,612:INFO:_master_model_container: 18
2023-03-06 23:14:37,612:INFO:_display_container: 2
2023-03-06 23:14:37,612:INFO:DummyRegressor()
2023-03-06 23:14:37,612:INFO:create_model() successfully completed......................................
2023-03-06 23:14:37,739:INFO:SubProcess create_model() end ==================================
2023-03-06 23:14:37,740:INFO:Creating metrics dataframe
2023-03-06 23:14:37,746:INFO:Initializing create_model()
2023-03-06 23:14:37,746:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F40D2A8340>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=3702), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-03-06 23:14:37,746:INFO:Checking exceptions
2023-03-06 23:14:37,747:INFO:Importing libraries
2023-03-06 23:14:37,747:INFO:Copying training dataset
2023-03-06 23:14:37,754:INFO:Defining folds
2023-03-06 23:14:37,754:INFO:Declaring metric variables
2023-03-06 23:14:37,754:INFO:Importing untrained model
2023-03-06 23:14:37,754:INFO:Declaring custom model
2023-03-06 23:14:37,755:INFO:Extra Trees Regressor Imported successfully
2023-03-06 23:14:37,756:INFO:Cross validation set to False
2023-03-06 23:14:37,756:INFO:Fitting Model
2023-03-06 23:14:38,370:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=3702)
2023-03-06 23:14:38,371:INFO:create_model() successfully completed......................................
2023-03-06 23:14:38,496:INFO:_master_model_container: 18
2023-03-06 23:14:38,496:INFO:_display_container: 2
2023-03-06 23:14:38,496:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=3702)
2023-03-06 23:14:38,496:INFO:compare_models() successfully completed......................................
2023-03-06 23:20:37,278:INFO:PyCaret RegressionExperiment
2023-03-06 23:20:37,279:INFO:Logging name: reg-default-name
2023-03-06 23:20:37,279:INFO:ML Usecase: MLUsecase.REGRESSION
2023-03-06 23:20:37,279:INFO:version 3.0.0.rc9
2023-03-06 23:20:37,279:INFO:Initializing setup()
2023-03-06 23:20:37,279:INFO:self.USI: be97
2023-03-06 23:20:37,279:INFO:self._variable_keys: {'data', 'USI', 'transform_target_param', 'X', '_available_plots', 'fold_shuffle_param', 'memory', 'gpu_n_jobs_param', 'exp_id', 'y_test', 'pipeline', 'fold_groups_param', 'idx', 'fold_generator', '_ml_usecase', 'target_param', 'html_param', 'exp_name_log', 'gpu_param', 'logging_param', 'seed', 'n_jobs_param', 'X_test', 'y', 'X_train', 'log_plots_param', 'y_train'}
2023-03-06 23:20:37,279:INFO:Checking environment
2023-03-06 23:20:37,279:INFO:python_version: 3.9.13
2023-03-06 23:20:37,279:INFO:python_build: ('main', 'Aug 25 2022 23:51:50')
2023-03-06 23:20:37,279:INFO:machine: AMD64
2023-03-06 23:20:37,279:INFO:platform: Windows-10-10.0.22621-SP0
2023-03-06 23:20:37,279:INFO:Memory: svmem(total=16540884992, available=7180705792, percent=56.6, used=9360179200, free=7180705792)
2023-03-06 23:20:37,279:INFO:Physical Core: 8
2023-03-06 23:20:37,279:INFO:Logical Core: 16
2023-03-06 23:20:37,279:INFO:Checking libraries
2023-03-06 23:20:37,279:INFO:System:
2023-03-06 23:20:37,279:INFO:    python: 3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]
2023-03-06 23:20:37,279:INFO:executable: C:\Users\Roshan\anaconda3\python.exe
2023-03-06 23:20:37,280:INFO:   machine: Windows-10-10.0.22621-SP0
2023-03-06 23:20:37,280:INFO:PyCaret required dependencies:
2023-03-06 23:20:37,280:INFO:                 pip: 22.2.2
2023-03-06 23:20:37,280:INFO:          setuptools: 63.4.1
2023-03-06 23:20:37,280:INFO:             pycaret: 3.0.0rc9
2023-03-06 23:20:37,280:INFO:             IPython: 7.31.1
2023-03-06 23:20:37,280:INFO:          ipywidgets: 7.6.5
2023-03-06 23:20:37,280:INFO:                tqdm: 4.64.1
2023-03-06 23:20:37,280:INFO:               numpy: 1.21.5
2023-03-06 23:20:37,280:INFO:              pandas: 1.4.4
2023-03-06 23:20:37,280:INFO:              jinja2: 2.11.3
2023-03-06 23:20:37,280:INFO:               scipy: 1.9.1
2023-03-06 23:20:37,280:INFO:              joblib: 1.2.0
2023-03-06 23:20:37,280:INFO:             sklearn: 1.0.2
2023-03-06 23:20:37,280:INFO:                pyod: 1.0.7
2023-03-06 23:20:37,280:INFO:            imblearn: 0.10.1
2023-03-06 23:20:37,280:INFO:   category_encoders: 2.6.0
2023-03-06 23:20:37,280:INFO:            lightgbm: 3.3.5
2023-03-06 23:20:37,280:INFO:               numba: 0.55.1
2023-03-06 23:20:37,280:INFO:            requests: 2.28.1
2023-03-06 23:20:37,280:INFO:          matplotlib: 3.5.2
2023-03-06 23:20:37,280:INFO:          scikitplot: 0.3.7
2023-03-06 23:20:37,280:INFO:         yellowbrick: 1.5
2023-03-06 23:20:37,280:INFO:              plotly: 5.9.0
2023-03-06 23:20:37,280:INFO:             kaleido: 0.2.1
2023-03-06 23:20:37,280:INFO:         statsmodels: 0.13.2
2023-03-06 23:20:37,280:INFO:              sktime: 0.16.1
2023-03-06 23:20:37,280:INFO:               tbats: 1.1.2
2023-03-06 23:20:37,280:INFO:            pmdarima: 2.0.2
2023-03-06 23:20:37,280:INFO:              psutil: 5.9.0
2023-03-06 23:20:37,280:INFO:PyCaret optional dependencies:
2023-03-06 23:20:37,280:INFO:                shap: Not installed
2023-03-06 23:20:37,280:INFO:           interpret: Not installed
2023-03-06 23:20:37,280:INFO:                umap: Not installed
2023-03-06 23:20:37,280:INFO:    pandas_profiling: 4.0.0
2023-03-06 23:20:37,282:INFO:  explainerdashboard: Not installed
2023-03-06 23:20:37,282:INFO:             autoviz: Not installed
2023-03-06 23:20:37,282:INFO:           fairlearn: Not installed
2023-03-06 23:20:37,282:INFO:             xgboost: Not installed
2023-03-06 23:20:37,282:INFO:            catboost: Not installed
2023-03-06 23:20:37,282:INFO:              kmodes: Not installed
2023-03-06 23:20:37,282:INFO:             mlxtend: Not installed
2023-03-06 23:20:37,282:INFO:       statsforecast: Not installed
2023-03-06 23:20:37,282:INFO:        tune_sklearn: Not installed
2023-03-06 23:20:37,282:INFO:                 ray: Not installed
2023-03-06 23:20:37,282:INFO:            hyperopt: Not installed
2023-03-06 23:20:37,282:INFO:              optuna: Not installed
2023-03-06 23:20:37,282:INFO:               skopt: Not installed
2023-03-06 23:20:37,282:INFO:              mlflow: Not installed
2023-03-06 23:20:37,282:INFO:              gradio: Not installed
2023-03-06 23:20:37,282:INFO:             fastapi: Not installed
2023-03-06 23:20:37,282:INFO:             uvicorn: Not installed
2023-03-06 23:20:37,282:INFO:              m2cgen: Not installed
2023-03-06 23:20:37,282:INFO:           evidently: Not installed
2023-03-06 23:20:37,282:INFO:               fugue: Not installed
2023-03-06 23:20:37,282:INFO:           streamlit: 1.19.0
2023-03-06 23:20:37,282:INFO:             prophet: Not installed
2023-03-06 23:20:37,282:INFO:None
2023-03-06 23:20:37,282:INFO:Set up data.
2023-03-06 23:20:37,294:INFO:Set up train/test split.
2023-03-06 23:20:37,302:INFO:Set up index.
2023-03-06 23:20:37,302:INFO:Set up folding strategy.
2023-03-06 23:20:37,302:INFO:Assigning column types.
2023-03-06 23:20:37,307:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-03-06 23:20:37,307:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-03-06 23:20:37,313:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-03-06 23:20:37,319:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-03-06 23:20:37,372:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-03-06 23:20:37,410:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-03-06 23:20:37,411:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-06 23:20:37,411:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-06 23:20:37,411:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-03-06 23:20:37,416:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-03-06 23:20:37,419:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-03-06 23:20:37,468:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-03-06 23:20:37,506:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-03-06 23:20:37,507:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-06 23:20:37,507:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-06 23:20:37,507:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-03-06 23:20:37,511:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-03-06 23:20:37,514:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-03-06 23:20:37,563:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-03-06 23:20:37,598:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-03-06 23:20:37,598:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-06 23:20:37,598:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-06 23:20:37,602:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-03-06 23:20:37,605:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-03-06 23:20:37,665:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-03-06 23:20:37,714:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-03-06 23:20:37,715:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-06 23:20:37,715:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-06 23:20:37,715:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-03-06 23:20:37,726:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-03-06 23:20:37,786:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-03-06 23:20:37,822:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-03-06 23:20:37,823:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-06 23:20:37,823:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-06 23:20:37,830:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-03-06 23:20:37,877:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-03-06 23:20:37,911:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-03-06 23:20:37,911:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-06 23:20:37,912:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-06 23:20:37,912:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-03-06 23:20:37,965:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-03-06 23:20:38,003:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-03-06 23:20:38,004:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-06 23:20:38,004:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-06 23:20:38,057:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-03-06 23:20:38,091:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-03-06 23:20:38,092:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-06 23:20:38,092:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-06 23:20:38,092:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-03-06 23:20:38,148:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-03-06 23:20:38,190:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-06 23:20:38,191:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-06 23:20:38,252:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-03-06 23:20:38,287:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-06 23:20:38,287:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-06 23:20:38,287:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-03-06 23:20:38,377:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-06 23:20:38,377:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-06 23:20:38,466:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-06 23:20:38,466:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-06 23:20:38,467:INFO:Preparing preprocessing pipeline...
2023-03-06 23:20:38,468:INFO:Set up column name cleaning.
2023-03-06 23:20:38,468:INFO:Set up simple imputation.
2023-03-06 23:20:38,471:INFO:Set up encoding of ordinal features.
2023-03-06 23:20:38,473:INFO:Set up encoding of categorical features.
2023-03-06 23:20:38,552:INFO:Finished creating preprocessing pipeline.
2023-03-06 23:20:38,571:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Roshan\AppData\Local\Temp\joblib),
         steps=[('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('numerical_imputer',
                 TransformerWrapper(include=['Unnamed: 0', 'Total Volume',
                                             '4046', '4225', '4770',
                                             'Total Bags', 'Small Bags',
                                             'Large Bags', 'XLarge Bags',
                                             'year'],
                                    transformer=SimpleImputer())),
                ('categ...
                 TransformerWrapper(include=['type'],
                                    transformer=OrdinalEncoder(cols=['type'],
                                                               handle_missing='return_nan',
                                                               mapping=[{'col': 'type',
                                                                         'data_type': dtype('O'),
                                                                         'mapping': conventional    0
organic         1
NaN            -1
dtype: int64}]))),
                ('rest_encoding',
                 TransformerWrapper(include=['Date', 'region'],
                                    transformer=LeaveOneOutEncoder(cols=['Date',
                                                                         'region'],
                                                                   handle_missing='return_nan',
                                                                   random_state=6070)))])
2023-03-06 23:20:38,571:INFO:Creating final display dataframe.
2023-03-06 23:20:39,013:INFO:Setup _display_container:                     Description             Value
0                    Session id              6070
1                        Target      AveragePrice
2                   Target type        Regression
3           Original data shape       (18249, 14)
4        Transformed data shape       (18249, 14)
5   Transformed train set shape       (12774, 14)
6    Transformed test set shape        (5475, 14)
7              Ordinal features                 1
8              Numeric features                10
9          Categorical features                 3
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16               Fold Generator             KFold
17                  Fold Number                10
18                     CPU Jobs                -1
19                      Use GPU             False
20               Log Experiment             False
21              Experiment Name  reg-default-name
22                          USI              be97
2023-03-06 23:20:39,163:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-06 23:20:39,164:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-06 23:20:39,298:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-06 23:20:39,300:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-06 23:20:39,300:INFO:setup() successfully completed in 2.02s...............
2023-03-06 23:20:39,303:INFO:Initializing compare_models()
2023-03-06 23:20:39,303:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F40D235070>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x000001F40D235070>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-03-06 23:20:39,303:INFO:Checking exceptions
2023-03-06 23:20:39,306:INFO:Preparing display monitor
2023-03-06 23:20:39,307:INFO:Initializing Linear Regression
2023-03-06 23:20:39,307:INFO:Total runtime is 0.0 minutes
2023-03-06 23:20:39,308:INFO:SubProcess create_model() called ==================================
2023-03-06 23:20:39,308:INFO:Initializing create_model()
2023-03-06 23:20:39,308:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F40D235070>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F40DCF5220>, model_only=True, return_train_score=False, kwargs={})
2023-03-06 23:20:39,308:INFO:Checking exceptions
2023-03-06 23:20:39,308:INFO:Importing libraries
2023-03-06 23:20:39,308:INFO:Copying training dataset
2023-03-06 23:20:39,315:INFO:Defining folds
2023-03-06 23:20:39,315:INFO:Declaring metric variables
2023-03-06 23:20:39,315:INFO:Importing untrained model
2023-03-06 23:20:39,316:INFO:Linear Regression Imported successfully
2023-03-06 23:20:39,316:INFO:Starting cross validation
2023-03-06 23:20:39,317:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-06 23:20:43,762:INFO:Calculating mean and std
2023-03-06 23:20:43,763:INFO:Creating metrics dataframe
2023-03-06 23:20:43,767:INFO:Uploading results into container
2023-03-06 23:20:43,767:INFO:Uploading model into container now
2023-03-06 23:20:43,768:INFO:_master_model_container: 1
2023-03-06 23:20:43,768:INFO:_display_container: 2
2023-03-06 23:20:43,768:INFO:LinearRegression(n_jobs=-1)
2023-03-06 23:20:43,768:INFO:create_model() successfully completed......................................
2023-03-06 23:20:43,919:INFO:SubProcess create_model() end ==================================
2023-03-06 23:20:43,919:INFO:Creating metrics dataframe
2023-03-06 23:20:43,922:INFO:Initializing Lasso Regression
2023-03-06 23:20:43,922:INFO:Total runtime is 0.07691502571105957 minutes
2023-03-06 23:20:43,922:INFO:SubProcess create_model() called ==================================
2023-03-06 23:20:43,922:INFO:Initializing create_model()
2023-03-06 23:20:43,923:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F40D235070>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F40DCF5220>, model_only=True, return_train_score=False, kwargs={})
2023-03-06 23:20:43,923:INFO:Checking exceptions
2023-03-06 23:20:43,923:INFO:Importing libraries
2023-03-06 23:20:43,923:INFO:Copying training dataset
2023-03-06 23:20:43,928:INFO:Defining folds
2023-03-06 23:20:43,928:INFO:Declaring metric variables
2023-03-06 23:20:43,928:INFO:Importing untrained model
2023-03-06 23:20:43,928:INFO:Lasso Regression Imported successfully
2023-03-06 23:20:43,929:INFO:Starting cross validation
2023-03-06 23:20:43,929:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-06 23:20:47,277:WARNING:C:\Users\Roshan\anaconda3\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.974e+01, tolerance: 1.845e-01
  model = cd_fast.enet_coordinate_descent(

2023-03-06 23:20:47,416:WARNING:C:\Users\Roshan\anaconda3\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.351e+01, tolerance: 1.850e-01
  model = cd_fast.enet_coordinate_descent(

2023-03-06 23:20:47,435:WARNING:C:\Users\Roshan\anaconda3\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.795e+01, tolerance: 1.841e-01
  model = cd_fast.enet_coordinate_descent(

2023-03-06 23:20:47,455:WARNING:C:\Users\Roshan\anaconda3\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.248e+01, tolerance: 1.836e-01
  model = cd_fast.enet_coordinate_descent(

2023-03-06 23:20:47,456:WARNING:C:\Users\Roshan\anaconda3\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.189e+01, tolerance: 1.852e-01
  model = cd_fast.enet_coordinate_descent(

2023-03-06 23:20:47,526:WARNING:C:\Users\Roshan\anaconda3\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.690e+01, tolerance: 1.846e-01
  model = cd_fast.enet_coordinate_descent(

2023-03-06 23:20:47,537:WARNING:C:\Users\Roshan\anaconda3\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.579e+01, tolerance: 1.842e-01
  model = cd_fast.enet_coordinate_descent(

2023-03-06 23:20:47,551:WARNING:C:\Users\Roshan\anaconda3\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.701e+01, tolerance: 1.853e-01
  model = cd_fast.enet_coordinate_descent(

2023-03-06 23:20:47,561:WARNING:C:\Users\Roshan\anaconda3\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.728e+01, tolerance: 1.836e-01
  model = cd_fast.enet_coordinate_descent(

2023-03-06 23:20:47,569:WARNING:C:\Users\Roshan\anaconda3\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.047e+01, tolerance: 1.840e-01
  model = cd_fast.enet_coordinate_descent(

2023-03-06 23:20:47,707:INFO:Calculating mean and std
2023-03-06 23:20:47,708:INFO:Creating metrics dataframe
2023-03-06 23:20:47,712:INFO:Uploading results into container
2023-03-06 23:20:47,713:INFO:Uploading model into container now
2023-03-06 23:20:47,713:INFO:_master_model_container: 2
2023-03-06 23:20:47,713:INFO:_display_container: 2
2023-03-06 23:20:47,715:INFO:Lasso(random_state=6070)
2023-03-06 23:20:47,715:INFO:create_model() successfully completed......................................
2023-03-06 23:20:47,866:INFO:SubProcess create_model() end ==================================
2023-03-06 23:20:47,866:INFO:Creating metrics dataframe
2023-03-06 23:20:47,870:INFO:Initializing Ridge Regression
2023-03-06 23:20:47,870:INFO:Total runtime is 0.14271305799484252 minutes
2023-03-06 23:20:47,871:INFO:SubProcess create_model() called ==================================
2023-03-06 23:20:47,871:INFO:Initializing create_model()
2023-03-06 23:20:47,871:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F40D235070>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F40DCF5220>, model_only=True, return_train_score=False, kwargs={})
2023-03-06 23:20:47,871:INFO:Checking exceptions
2023-03-06 23:20:47,871:INFO:Importing libraries
2023-03-06 23:20:47,871:INFO:Copying training dataset
2023-03-06 23:20:47,879:INFO:Defining folds
2023-03-06 23:20:47,879:INFO:Declaring metric variables
2023-03-06 23:20:47,879:INFO:Importing untrained model
2023-03-06 23:20:47,880:INFO:Ridge Regression Imported successfully
2023-03-06 23:20:47,880:INFO:Starting cross validation
2023-03-06 23:20:47,881:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-06 23:20:48,119:WARNING:C:\Users\Roshan\anaconda3\lib\site-packages\sklearn\linear_model\_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=8.34837e-17): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2023-03-06 23:20:48,133:WARNING:C:\Users\Roshan\anaconda3\lib\site-packages\sklearn\linear_model\_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=4.27432e-17): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2023-03-06 23:20:48,180:WARNING:C:\Users\Roshan\anaconda3\lib\site-packages\sklearn\linear_model\_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=4.24336e-17): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2023-03-06 23:20:48,193:WARNING:C:\Users\Roshan\anaconda3\lib\site-packages\sklearn\linear_model\_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=7.39544e-17): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2023-03-06 23:20:48,237:WARNING:C:\Users\Roshan\anaconda3\lib\site-packages\sklearn\linear_model\_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=6.49268e-18): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2023-03-06 23:20:48,253:WARNING:C:\Users\Roshan\anaconda3\lib\site-packages\sklearn\linear_model\_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=2.92372e-17): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2023-03-06 23:20:50,159:WARNING:C:\Users\Roshan\anaconda3\lib\site-packages\sklearn\linear_model\_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=3.00125e-17): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2023-03-06 23:20:50,210:INFO:Calculating mean and std
2023-03-06 23:20:50,210:INFO:Creating metrics dataframe
2023-03-06 23:20:50,213:INFO:Uploading results into container
2023-03-06 23:20:50,213:INFO:Uploading model into container now
2023-03-06 23:20:50,213:INFO:_master_model_container: 3
2023-03-06 23:20:50,213:INFO:_display_container: 2
2023-03-06 23:20:50,214:INFO:Ridge(random_state=6070)
2023-03-06 23:20:50,214:INFO:create_model() successfully completed......................................
2023-03-06 23:20:50,332:INFO:SubProcess create_model() end ==================================
2023-03-06 23:20:50,333:INFO:Creating metrics dataframe
2023-03-06 23:20:50,337:INFO:Initializing Elastic Net
2023-03-06 23:20:50,337:INFO:Total runtime is 0.18383247852325438 minutes
2023-03-06 23:20:50,337:INFO:SubProcess create_model() called ==================================
2023-03-06 23:20:50,337:INFO:Initializing create_model()
2023-03-06 23:20:50,337:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F40D235070>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F40DCF5220>, model_only=True, return_train_score=False, kwargs={})
2023-03-06 23:20:50,337:INFO:Checking exceptions
2023-03-06 23:20:50,337:INFO:Importing libraries
2023-03-06 23:20:50,337:INFO:Copying training dataset
2023-03-06 23:20:50,345:INFO:Defining folds
2023-03-06 23:20:50,345:INFO:Declaring metric variables
2023-03-06 23:20:50,345:INFO:Importing untrained model
2023-03-06 23:20:50,345:INFO:Elastic Net Imported successfully
2023-03-06 23:20:50,346:INFO:Starting cross validation
2023-03-06 23:20:50,346:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-06 23:20:50,730:WARNING:C:\Users\Roshan\anaconda3\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.079e+02, tolerance: 1.845e-01
  model = cd_fast.enet_coordinate_descent(

2023-03-06 23:20:50,743:WARNING:C:\Users\Roshan\anaconda3\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.185e+02, tolerance: 1.850e-01
  model = cd_fast.enet_coordinate_descent(

2023-03-06 23:20:50,752:WARNING:C:\Users\Roshan\anaconda3\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.531e+02, tolerance: 1.846e-01
  model = cd_fast.enet_coordinate_descent(

2023-03-06 23:20:50,797:WARNING:C:\Users\Roshan\anaconda3\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.384e+02, tolerance: 1.836e-01
  model = cd_fast.enet_coordinate_descent(

2023-03-06 23:20:50,800:WARNING:C:\Users\Roshan\anaconda3\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.130e+02, tolerance: 1.836e-01
  model = cd_fast.enet_coordinate_descent(

2023-03-06 23:20:50,864:WARNING:C:\Users\Roshan\anaconda3\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.171e+02, tolerance: 1.852e-01
  model = cd_fast.enet_coordinate_descent(

2023-03-06 23:20:50,876:WARNING:C:\Users\Roshan\anaconda3\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.510e+02, tolerance: 1.853e-01
  model = cd_fast.enet_coordinate_descent(

2023-03-06 23:20:50,896:WARNING:C:\Users\Roshan\anaconda3\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.301e+02, tolerance: 1.840e-01
  model = cd_fast.enet_coordinate_descent(

2023-03-06 23:20:50,896:WARNING:C:\Users\Roshan\anaconda3\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.039e+02, tolerance: 1.842e-01
  model = cd_fast.enet_coordinate_descent(

2023-03-06 23:20:50,925:WARNING:C:\Users\Roshan\anaconda3\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.775e+02, tolerance: 1.841e-01
  model = cd_fast.enet_coordinate_descent(

2023-03-06 23:20:51,024:INFO:Calculating mean and std
2023-03-06 23:20:51,024:INFO:Creating metrics dataframe
2023-03-06 23:20:51,026:INFO:Uploading results into container
2023-03-06 23:20:51,027:INFO:Uploading model into container now
2023-03-06 23:20:51,027:INFO:_master_model_container: 4
2023-03-06 23:20:51,027:INFO:_display_container: 2
2023-03-06 23:20:51,027:INFO:ElasticNet(random_state=6070)
2023-03-06 23:20:51,027:INFO:create_model() successfully completed......................................
2023-03-06 23:20:51,143:INFO:SubProcess create_model() end ==================================
2023-03-06 23:20:51,143:INFO:Creating metrics dataframe
2023-03-06 23:20:51,145:INFO:Initializing Least Angle Regression
2023-03-06 23:20:51,145:INFO:Total runtime is 0.1973102569580078 minutes
2023-03-06 23:20:51,146:INFO:SubProcess create_model() called ==================================
2023-03-06 23:20:51,146:INFO:Initializing create_model()
2023-03-06 23:20:51,146:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F40D235070>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F40DCF5220>, model_only=True, return_train_score=False, kwargs={})
2023-03-06 23:20:51,146:INFO:Checking exceptions
2023-03-06 23:20:51,146:INFO:Importing libraries
2023-03-06 23:20:51,146:INFO:Copying training dataset
2023-03-06 23:20:51,152:INFO:Defining folds
2023-03-06 23:20:51,152:INFO:Declaring metric variables
2023-03-06 23:20:51,152:INFO:Importing untrained model
2023-03-06 23:20:51,153:INFO:Least Angle Regression Imported successfully
2023-03-06 23:20:51,153:INFO:Starting cross validation
2023-03-06 23:20:51,153:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-06 23:20:51,379:WARNING:C:\Users\Roshan\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-03-06 23:20:51,396:WARNING:C:\Users\Roshan\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-03-06 23:20:51,417:WARNING:C:\Users\Roshan\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-03-06 23:20:51,430:WARNING:C:\Users\Roshan\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-03-06 23:20:51,456:WARNING:C:\Users\Roshan\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-03-06 23:20:51,478:WARNING:C:\Users\Roshan\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-03-06 23:20:51,486:WARNING:C:\Users\Roshan\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-03-06 23:20:51,514:WARNING:C:\Users\Roshan\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-03-06 23:20:51,518:WARNING:C:\Users\Roshan\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-03-06 23:20:51,536:WARNING:C:\Users\Roshan\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-03-06 23:20:51,611:INFO:Calculating mean and std
2023-03-06 23:20:51,612:INFO:Creating metrics dataframe
2023-03-06 23:20:51,615:INFO:Uploading results into container
2023-03-06 23:20:51,616:INFO:Uploading model into container now
2023-03-06 23:20:51,616:INFO:_master_model_container: 5
2023-03-06 23:20:51,616:INFO:_display_container: 2
2023-03-06 23:20:51,616:INFO:Lars(random_state=6070)
2023-03-06 23:20:51,616:INFO:create_model() successfully completed......................................
2023-03-06 23:20:51,746:INFO:SubProcess create_model() end ==================================
2023-03-06 23:20:51,746:INFO:Creating metrics dataframe
2023-03-06 23:20:51,751:INFO:Initializing Lasso Least Angle Regression
2023-03-06 23:20:51,751:INFO:Total runtime is 0.20741164684295654 minutes
2023-03-06 23:20:51,751:INFO:SubProcess create_model() called ==================================
2023-03-06 23:20:51,751:INFO:Initializing create_model()
2023-03-06 23:20:51,751:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F40D235070>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F40DCF5220>, model_only=True, return_train_score=False, kwargs={})
2023-03-06 23:20:51,751:INFO:Checking exceptions
2023-03-06 23:20:51,751:INFO:Importing libraries
2023-03-06 23:20:51,751:INFO:Copying training dataset
2023-03-06 23:20:51,759:INFO:Defining folds
2023-03-06 23:20:51,759:INFO:Declaring metric variables
2023-03-06 23:20:51,759:INFO:Importing untrained model
2023-03-06 23:20:51,759:INFO:Lasso Least Angle Regression Imported successfully
2023-03-06 23:20:51,759:INFO:Starting cross validation
2023-03-06 23:20:51,761:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-06 23:20:51,993:WARNING:C:\Users\Roshan\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-03-06 23:20:52,021:WARNING:C:\Users\Roshan\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-03-06 23:20:52,031:WARNING:C:\Users\Roshan\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-03-06 23:20:52,044:WARNING:C:\Users\Roshan\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-03-06 23:20:52,063:WARNING:C:\Users\Roshan\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-03-06 23:20:52,077:WARNING:C:\Users\Roshan\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-03-06 23:20:52,100:WARNING:C:\Users\Roshan\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-03-06 23:20:52,121:WARNING:C:\Users\Roshan\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-03-06 23:20:52,144:WARNING:C:\Users\Roshan\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-03-06 23:20:52,153:WARNING:C:\Users\Roshan\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-03-06 23:20:52,218:INFO:Calculating mean and std
2023-03-06 23:20:52,218:INFO:Creating metrics dataframe
2023-03-06 23:20:52,221:INFO:Uploading results into container
2023-03-06 23:20:52,222:INFO:Uploading model into container now
2023-03-06 23:20:52,222:INFO:_master_model_container: 6
2023-03-06 23:20:52,222:INFO:_display_container: 2
2023-03-06 23:20:52,222:INFO:LassoLars(random_state=6070)
2023-03-06 23:20:52,222:INFO:create_model() successfully completed......................................
2023-03-06 23:20:52,335:INFO:SubProcess create_model() end ==================================
2023-03-06 23:20:52,335:INFO:Creating metrics dataframe
2023-03-06 23:20:52,338:INFO:Initializing Orthogonal Matching Pursuit
2023-03-06 23:20:52,338:INFO:Total runtime is 0.21718831857045492 minutes
2023-03-06 23:20:52,338:INFO:SubProcess create_model() called ==================================
2023-03-06 23:20:52,338:INFO:Initializing create_model()
2023-03-06 23:20:52,339:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F40D235070>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F40DCF5220>, model_only=True, return_train_score=False, kwargs={})
2023-03-06 23:20:52,339:INFO:Checking exceptions
2023-03-06 23:20:52,339:INFO:Importing libraries
2023-03-06 23:20:52,339:INFO:Copying training dataset
2023-03-06 23:20:52,344:INFO:Defining folds
2023-03-06 23:20:52,344:INFO:Declaring metric variables
2023-03-06 23:20:52,345:INFO:Importing untrained model
2023-03-06 23:20:52,345:INFO:Orthogonal Matching Pursuit Imported successfully
2023-03-06 23:20:52,345:INFO:Starting cross validation
2023-03-06 23:20:52,345:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-06 23:20:52,568:WARNING:C:\Users\Roshan\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-03-06 23:20:52,589:WARNING:C:\Users\Roshan\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-03-06 23:20:52,605:WARNING:C:\Users\Roshan\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-03-06 23:20:52,615:WARNING:C:\Users\Roshan\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-03-06 23:20:52,636:WARNING:C:\Users\Roshan\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-03-06 23:20:52,664:WARNING:C:\Users\Roshan\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-03-06 23:20:52,677:WARNING:C:\Users\Roshan\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-03-06 23:20:52,679:WARNING:C:\Users\Roshan\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-03-06 23:20:52,709:WARNING:C:\Users\Roshan\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-03-06 23:20:52,725:WARNING:C:\Users\Roshan\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-03-06 23:20:52,805:INFO:Calculating mean and std
2023-03-06 23:20:52,806:INFO:Creating metrics dataframe
2023-03-06 23:20:52,809:INFO:Uploading results into container
2023-03-06 23:20:52,810:INFO:Uploading model into container now
2023-03-06 23:20:52,810:INFO:_master_model_container: 7
2023-03-06 23:20:52,810:INFO:_display_container: 2
2023-03-06 23:20:52,810:INFO:OrthogonalMatchingPursuit()
2023-03-06 23:20:52,810:INFO:create_model() successfully completed......................................
2023-03-06 23:20:52,935:INFO:SubProcess create_model() end ==================================
2023-03-06 23:20:52,935:INFO:Creating metrics dataframe
2023-03-06 23:20:52,938:INFO:Initializing Bayesian Ridge
2023-03-06 23:20:52,938:INFO:Total runtime is 0.22719231446584068 minutes
2023-03-06 23:20:52,938:INFO:SubProcess create_model() called ==================================
2023-03-06 23:20:52,938:INFO:Initializing create_model()
2023-03-06 23:20:52,938:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F40D235070>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F40DCF5220>, model_only=True, return_train_score=False, kwargs={})
2023-03-06 23:20:52,938:INFO:Checking exceptions
2023-03-06 23:20:52,938:INFO:Importing libraries
2023-03-06 23:20:52,938:INFO:Copying training dataset
2023-03-06 23:20:52,943:INFO:Defining folds
2023-03-06 23:20:52,943:INFO:Declaring metric variables
2023-03-06 23:20:52,944:INFO:Importing untrained model
2023-03-06 23:20:52,944:INFO:Bayesian Ridge Imported successfully
2023-03-06 23:20:52,944:INFO:Starting cross validation
2023-03-06 23:20:52,945:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-06 23:20:53,392:INFO:Calculating mean and std
2023-03-06 23:20:53,392:INFO:Creating metrics dataframe
2023-03-06 23:20:53,396:INFO:Uploading results into container
2023-03-06 23:20:53,396:INFO:Uploading model into container now
2023-03-06 23:20:53,396:INFO:_master_model_container: 8
2023-03-06 23:20:53,396:INFO:_display_container: 2
2023-03-06 23:20:53,396:INFO:BayesianRidge()
2023-03-06 23:20:53,396:INFO:create_model() successfully completed......................................
2023-03-06 23:20:53,510:INFO:SubProcess create_model() end ==================================
2023-03-06 23:20:53,510:INFO:Creating metrics dataframe
2023-03-06 23:20:53,514:INFO:Initializing Passive Aggressive Regressor
2023-03-06 23:20:53,514:INFO:Total runtime is 0.2367838025093079 minutes
2023-03-06 23:20:53,514:INFO:SubProcess create_model() called ==================================
2023-03-06 23:20:53,514:INFO:Initializing create_model()
2023-03-06 23:20:53,514:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F40D235070>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F40DCF5220>, model_only=True, return_train_score=False, kwargs={})
2023-03-06 23:20:53,514:INFO:Checking exceptions
2023-03-06 23:20:53,514:INFO:Importing libraries
2023-03-06 23:20:53,514:INFO:Copying training dataset
2023-03-06 23:20:53,520:INFO:Defining folds
2023-03-06 23:20:53,520:INFO:Declaring metric variables
2023-03-06 23:20:53,520:INFO:Importing untrained model
2023-03-06 23:20:53,520:INFO:Passive Aggressive Regressor Imported successfully
2023-03-06 23:20:53,520:INFO:Starting cross validation
2023-03-06 23:20:53,521:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-06 23:20:53,978:INFO:Calculating mean and std
2023-03-06 23:20:53,979:INFO:Creating metrics dataframe
2023-03-06 23:20:53,982:INFO:Uploading results into container
2023-03-06 23:20:53,982:INFO:Uploading model into container now
2023-03-06 23:20:53,982:INFO:_master_model_container: 9
2023-03-06 23:20:53,982:INFO:_display_container: 2
2023-03-06 23:20:53,982:INFO:PassiveAggressiveRegressor(random_state=6070)
2023-03-06 23:20:53,983:INFO:create_model() successfully completed......................................
2023-03-06 23:20:54,094:INFO:SubProcess create_model() end ==================================
2023-03-06 23:20:54,094:INFO:Creating metrics dataframe
2023-03-06 23:20:54,099:INFO:Initializing Huber Regressor
2023-03-06 23:20:54,099:INFO:Total runtime is 0.24653424024581913 minutes
2023-03-06 23:20:54,099:INFO:SubProcess create_model() called ==================================
2023-03-06 23:20:54,099:INFO:Initializing create_model()
2023-03-06 23:20:54,099:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F40D235070>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F40DCF5220>, model_only=True, return_train_score=False, kwargs={})
2023-03-06 23:20:54,099:INFO:Checking exceptions
2023-03-06 23:20:54,099:INFO:Importing libraries
2023-03-06 23:20:54,099:INFO:Copying training dataset
2023-03-06 23:20:54,105:INFO:Defining folds
2023-03-06 23:20:54,105:INFO:Declaring metric variables
2023-03-06 23:20:54,105:INFO:Importing untrained model
2023-03-06 23:20:54,105:INFO:Huber Regressor Imported successfully
2023-03-06 23:20:54,105:INFO:Starting cross validation
2023-03-06 23:20:54,106:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-06 23:20:54,907:WARNING:C:\Users\Roshan\anaconda3\lib\site-packages\sklearn\linear_model\_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-03-06 23:20:55,005:INFO:Calculating mean and std
2023-03-06 23:20:55,007:INFO:Creating metrics dataframe
2023-03-06 23:20:55,009:INFO:Uploading results into container
2023-03-06 23:20:55,009:INFO:Uploading model into container now
2023-03-06 23:20:55,010:INFO:_master_model_container: 10
2023-03-06 23:20:55,010:INFO:_display_container: 2
2023-03-06 23:20:55,010:INFO:HuberRegressor()
2023-03-06 23:20:55,010:INFO:create_model() successfully completed......................................
2023-03-06 23:20:55,125:INFO:SubProcess create_model() end ==================================
2023-03-06 23:20:55,125:INFO:Creating metrics dataframe
2023-03-06 23:20:55,128:INFO:Initializing K Neighbors Regressor
2023-03-06 23:20:55,129:INFO:Total runtime is 0.26371006568272914 minutes
2023-03-06 23:20:55,129:INFO:SubProcess create_model() called ==================================
2023-03-06 23:20:55,129:INFO:Initializing create_model()
2023-03-06 23:20:55,129:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F40D235070>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F40DCF5220>, model_only=True, return_train_score=False, kwargs={})
2023-03-06 23:20:55,129:INFO:Checking exceptions
2023-03-06 23:20:55,129:INFO:Importing libraries
2023-03-06 23:20:55,129:INFO:Copying training dataset
2023-03-06 23:20:55,135:INFO:Defining folds
2023-03-06 23:20:55,135:INFO:Declaring metric variables
2023-03-06 23:20:55,135:INFO:Importing untrained model
2023-03-06 23:20:55,135:INFO:K Neighbors Regressor Imported successfully
2023-03-06 23:20:55,135:INFO:Starting cross validation
2023-03-06 23:20:55,136:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-06 23:20:55,632:INFO:Calculating mean and std
2023-03-06 23:20:55,632:INFO:Creating metrics dataframe
2023-03-06 23:20:55,634:INFO:Uploading results into container
2023-03-06 23:20:55,635:INFO:Uploading model into container now
2023-03-06 23:20:55,635:INFO:_master_model_container: 11
2023-03-06 23:20:55,635:INFO:_display_container: 2
2023-03-06 23:20:55,635:INFO:KNeighborsRegressor(n_jobs=-1)
2023-03-06 23:20:55,635:INFO:create_model() successfully completed......................................
2023-03-06 23:20:55,763:INFO:SubProcess create_model() end ==================================
2023-03-06 23:20:55,763:INFO:Creating metrics dataframe
2023-03-06 23:20:55,767:INFO:Initializing Decision Tree Regressor
2023-03-06 23:20:55,767:INFO:Total runtime is 0.2743447979291281 minutes
2023-03-06 23:20:55,767:INFO:SubProcess create_model() called ==================================
2023-03-06 23:20:55,767:INFO:Initializing create_model()
2023-03-06 23:20:55,767:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F40D235070>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F40DCF5220>, model_only=True, return_train_score=False, kwargs={})
2023-03-06 23:20:55,767:INFO:Checking exceptions
2023-03-06 23:20:55,767:INFO:Importing libraries
2023-03-06 23:20:55,769:INFO:Copying training dataset
2023-03-06 23:20:55,775:INFO:Defining folds
2023-03-06 23:20:55,775:INFO:Declaring metric variables
2023-03-06 23:20:55,775:INFO:Importing untrained model
2023-03-06 23:20:55,775:INFO:Decision Tree Regressor Imported successfully
2023-03-06 23:20:55,775:INFO:Starting cross validation
2023-03-06 23:20:55,777:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-06 23:20:56,407:INFO:Calculating mean and std
2023-03-06 23:20:56,407:INFO:Creating metrics dataframe
2023-03-06 23:20:56,410:INFO:Uploading results into container
2023-03-06 23:20:56,411:INFO:Uploading model into container now
2023-03-06 23:20:56,412:INFO:_master_model_container: 12
2023-03-06 23:20:56,412:INFO:_display_container: 2
2023-03-06 23:20:56,412:INFO:DecisionTreeRegressor(random_state=6070)
2023-03-06 23:20:56,412:INFO:create_model() successfully completed......................................
2023-03-06 23:20:56,526:INFO:SubProcess create_model() end ==================================
2023-03-06 23:20:56,526:INFO:Creating metrics dataframe
2023-03-06 23:20:56,529:INFO:Initializing Random Forest Regressor
2023-03-06 23:20:56,529:INFO:Total runtime is 0.28703956206639614 minutes
2023-03-06 23:20:56,529:INFO:SubProcess create_model() called ==================================
2023-03-06 23:20:56,529:INFO:Initializing create_model()
2023-03-06 23:20:56,529:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F40D235070>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F40DCF5220>, model_only=True, return_train_score=False, kwargs={})
2023-03-06 23:20:56,529:INFO:Checking exceptions
2023-03-06 23:20:56,529:INFO:Importing libraries
2023-03-06 23:20:56,529:INFO:Copying training dataset
2023-03-06 23:20:56,535:INFO:Defining folds
2023-03-06 23:20:56,535:INFO:Declaring metric variables
2023-03-06 23:20:56,535:INFO:Importing untrained model
2023-03-06 23:20:56,535:INFO:Random Forest Regressor Imported successfully
2023-03-06 23:20:56,536:INFO:Starting cross validation
2023-03-06 23:20:56,536:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-06 23:21:00,744:WARNING:C:\Users\Roshan\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 1.00s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-06 23:21:02,484:WARNING:C:\Users\Roshan\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 1.00s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-06 23:21:02,725:WARNING:C:\Users\Roshan\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 1.38s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-06 23:21:03,494:WARNING:C:\Users\Roshan\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.86s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-06 23:21:03,562:WARNING:C:\Users\Roshan\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 1.03s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-06 23:21:03,594:WARNING:C:\Users\Roshan\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.88s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-06 23:21:03,865:WARNING:C:\Users\Roshan\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 1.00s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-03-06 23:21:04,134:INFO:Calculating mean and std
2023-03-06 23:21:04,135:INFO:Creating metrics dataframe
2023-03-06 23:21:04,139:INFO:Uploading results into container
2023-03-06 23:21:04,139:INFO:Uploading model into container now
2023-03-06 23:21:04,141:INFO:_master_model_container: 13
2023-03-06 23:21:04,141:INFO:_display_container: 2
2023-03-06 23:21:04,141:INFO:RandomForestRegressor(n_jobs=-1, random_state=6070)
2023-03-06 23:21:04,141:INFO:create_model() successfully completed......................................
2023-03-06 23:21:04,295:INFO:SubProcess create_model() end ==================================
2023-03-06 23:21:04,295:INFO:Creating metrics dataframe
2023-03-06 23:21:04,298:INFO:Initializing Extra Trees Regressor
2023-03-06 23:21:04,298:INFO:Total runtime is 0.41651653051376347 minutes
2023-03-06 23:21:04,299:INFO:SubProcess create_model() called ==================================
2023-03-06 23:21:04,299:INFO:Initializing create_model()
2023-03-06 23:21:04,299:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F40D235070>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F40DCF5220>, model_only=True, return_train_score=False, kwargs={})
2023-03-06 23:21:04,299:INFO:Checking exceptions
2023-03-06 23:21:04,299:INFO:Importing libraries
2023-03-06 23:21:04,299:INFO:Copying training dataset
2023-03-06 23:21:04,305:INFO:Defining folds
2023-03-06 23:21:04,305:INFO:Declaring metric variables
2023-03-06 23:21:04,305:INFO:Importing untrained model
2023-03-06 23:21:04,305:INFO:Extra Trees Regressor Imported successfully
2023-03-06 23:21:04,306:INFO:Starting cross validation
2023-03-06 23:21:04,306:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-06 23:21:06,974:WARNING:C:\Users\Roshan\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 1.28s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-06 23:21:07,610:WARNING:C:\Users\Roshan\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.69s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-06 23:21:08,259:INFO:Calculating mean and std
2023-03-06 23:21:08,259:INFO:Creating metrics dataframe
2023-03-06 23:21:08,263:INFO:Uploading results into container
2023-03-06 23:21:08,264:INFO:Uploading model into container now
2023-03-06 23:21:08,264:INFO:_master_model_container: 14
2023-03-06 23:21:08,264:INFO:_display_container: 2
2023-03-06 23:21:08,264:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=6070)
2023-03-06 23:21:08,265:INFO:create_model() successfully completed......................................
2023-03-06 23:21:08,427:INFO:SubProcess create_model() end ==================================
2023-03-06 23:21:08,427:INFO:Creating metrics dataframe
2023-03-06 23:21:08,432:INFO:Initializing AdaBoost Regressor
2023-03-06 23:21:08,432:INFO:Total runtime is 0.4854198296864828 minutes
2023-03-06 23:21:08,433:INFO:SubProcess create_model() called ==================================
2023-03-06 23:21:08,433:INFO:Initializing create_model()
2023-03-06 23:21:08,433:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F40D235070>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F40DCF5220>, model_only=True, return_train_score=False, kwargs={})
2023-03-06 23:21:08,433:INFO:Checking exceptions
2023-03-06 23:21:08,433:INFO:Importing libraries
2023-03-06 23:21:08,433:INFO:Copying training dataset
2023-03-06 23:21:08,441:INFO:Defining folds
2023-03-06 23:21:08,442:INFO:Declaring metric variables
2023-03-06 23:21:08,442:INFO:Importing untrained model
2023-03-06 23:21:08,442:INFO:AdaBoost Regressor Imported successfully
2023-03-06 23:21:08,443:INFO:Starting cross validation
2023-03-06 23:21:08,444:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-06 23:21:10,368:INFO:Calculating mean and std
2023-03-06 23:21:10,368:INFO:Creating metrics dataframe
2023-03-06 23:21:10,371:INFO:Uploading results into container
2023-03-06 23:21:10,371:INFO:Uploading model into container now
2023-03-06 23:21:10,372:INFO:_master_model_container: 15
2023-03-06 23:21:10,372:INFO:_display_container: 2
2023-03-06 23:21:10,372:INFO:AdaBoostRegressor(random_state=6070)
2023-03-06 23:21:10,372:INFO:create_model() successfully completed......................................
2023-03-06 23:21:10,522:INFO:SubProcess create_model() end ==================================
2023-03-06 23:21:10,522:INFO:Creating metrics dataframe
2023-03-06 23:21:10,525:INFO:Initializing Gradient Boosting Regressor
2023-03-06 23:21:10,525:INFO:Total runtime is 0.5202977856000265 minutes
2023-03-06 23:21:10,526:INFO:SubProcess create_model() called ==================================
2023-03-06 23:21:10,526:INFO:Initializing create_model()
2023-03-06 23:21:10,526:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F40D235070>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F40DCF5220>, model_only=True, return_train_score=False, kwargs={})
2023-03-06 23:21:10,526:INFO:Checking exceptions
2023-03-06 23:21:10,526:INFO:Importing libraries
2023-03-06 23:21:10,526:INFO:Copying training dataset
2023-03-06 23:21:10,533:INFO:Defining folds
2023-03-06 23:21:10,533:INFO:Declaring metric variables
2023-03-06 23:21:10,533:INFO:Importing untrained model
2023-03-06 23:21:10,533:INFO:Gradient Boosting Regressor Imported successfully
2023-03-06 23:21:10,534:INFO:Starting cross validation
2023-03-06 23:21:10,535:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-06 23:21:14,958:INFO:Calculating mean and std
2023-03-06 23:21:14,959:INFO:Creating metrics dataframe
2023-03-06 23:21:14,962:INFO:Uploading results into container
2023-03-06 23:21:14,962:INFO:Uploading model into container now
2023-03-06 23:21:14,962:INFO:_master_model_container: 16
2023-03-06 23:21:14,963:INFO:_display_container: 2
2023-03-06 23:21:14,963:INFO:GradientBoostingRegressor(random_state=6070)
2023-03-06 23:21:14,963:INFO:create_model() successfully completed......................................
2023-03-06 23:21:15,096:INFO:SubProcess create_model() end ==================================
2023-03-06 23:21:15,096:INFO:Creating metrics dataframe
2023-03-06 23:21:15,099:INFO:Initializing Light Gradient Boosting Machine
2023-03-06 23:21:15,099:INFO:Total runtime is 0.5965432524681091 minutes
2023-03-06 23:21:15,099:INFO:SubProcess create_model() called ==================================
2023-03-06 23:21:15,099:INFO:Initializing create_model()
2023-03-06 23:21:15,099:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F40D235070>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F40DCF5220>, model_only=True, return_train_score=False, kwargs={})
2023-03-06 23:21:15,099:INFO:Checking exceptions
2023-03-06 23:21:15,099:INFO:Importing libraries
2023-03-06 23:21:15,099:INFO:Copying training dataset
2023-03-06 23:21:15,105:INFO:Defining folds
2023-03-06 23:21:15,105:INFO:Declaring metric variables
2023-03-06 23:21:15,105:INFO:Importing untrained model
2023-03-06 23:21:15,106:INFO:Light Gradient Boosting Machine Imported successfully
2023-03-06 23:21:15,106:INFO:Starting cross validation
2023-03-06 23:21:15,107:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-06 23:21:16,856:INFO:Calculating mean and std
2023-03-06 23:21:16,856:INFO:Creating metrics dataframe
2023-03-06 23:21:16,859:INFO:Uploading results into container
2023-03-06 23:21:16,859:INFO:Uploading model into container now
2023-03-06 23:21:16,859:INFO:_master_model_container: 17
2023-03-06 23:21:16,859:INFO:_display_container: 2
2023-03-06 23:21:16,860:INFO:LGBMRegressor(random_state=6070)
2023-03-06 23:21:16,860:INFO:create_model() successfully completed......................................
2023-03-06 23:21:16,980:INFO:SubProcess create_model() end ==================================
2023-03-06 23:21:16,980:INFO:Creating metrics dataframe
2023-03-06 23:21:16,984:INFO:Initializing Dummy Regressor
2023-03-06 23:21:16,984:INFO:Total runtime is 0.6279586752255758 minutes
2023-03-06 23:21:16,984:INFO:SubProcess create_model() called ==================================
2023-03-06 23:21:16,984:INFO:Initializing create_model()
2023-03-06 23:21:16,984:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F40D235070>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F40DCF5220>, model_only=True, return_train_score=False, kwargs={})
2023-03-06 23:21:16,984:INFO:Checking exceptions
2023-03-06 23:21:16,984:INFO:Importing libraries
2023-03-06 23:21:16,984:INFO:Copying training dataset
2023-03-06 23:21:16,990:INFO:Defining folds
2023-03-06 23:21:16,990:INFO:Declaring metric variables
2023-03-06 23:21:16,991:INFO:Importing untrained model
2023-03-06 23:21:16,991:INFO:Dummy Regressor Imported successfully
2023-03-06 23:21:16,991:INFO:Starting cross validation
2023-03-06 23:21:16,992:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-06 23:21:17,442:INFO:Calculating mean and std
2023-03-06 23:21:17,443:INFO:Creating metrics dataframe
2023-03-06 23:21:17,446:INFO:Uploading results into container
2023-03-06 23:21:17,447:INFO:Uploading model into container now
2023-03-06 23:21:17,447:INFO:_master_model_container: 18
2023-03-06 23:21:17,447:INFO:_display_container: 2
2023-03-06 23:21:17,447:INFO:DummyRegressor()
2023-03-06 23:21:17,447:INFO:create_model() successfully completed......................................
2023-03-06 23:21:17,600:INFO:SubProcess create_model() end ==================================
2023-03-06 23:21:17,600:INFO:Creating metrics dataframe
2023-03-06 23:21:17,606:INFO:Initializing create_model()
2023-03-06 23:21:17,606:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001F40D235070>, estimator=LGBMRegressor(random_state=6070), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-03-06 23:21:17,606:INFO:Checking exceptions
2023-03-06 23:21:17,607:INFO:Importing libraries
2023-03-06 23:21:17,607:INFO:Copying training dataset
2023-03-06 23:21:17,612:INFO:Defining folds
2023-03-06 23:21:17,612:INFO:Declaring metric variables
2023-03-06 23:21:17,612:INFO:Importing untrained model
2023-03-06 23:21:17,612:INFO:Declaring custom model
2023-03-06 23:21:17,612:INFO:Light Gradient Boosting Machine Imported successfully
2023-03-06 23:21:17,613:INFO:Cross validation set to False
2023-03-06 23:21:17,613:INFO:Fitting Model
2023-03-06 23:21:17,767:INFO:LGBMRegressor(random_state=6070)
2023-03-06 23:21:17,767:INFO:create_model() successfully completed......................................
2023-03-06 23:21:17,911:INFO:_master_model_container: 18
2023-03-06 23:21:17,911:INFO:_display_container: 2
2023-03-06 23:21:17,911:INFO:LGBMRegressor(random_state=6070)
2023-03-06 23:21:17,911:INFO:compare_models() successfully completed......................................
2023-03-06 23:21:17,932:INFO:Initializing save_model()
2023-03-06 23:21:17,932:INFO:save_model(model=LGBMRegressor(random_state=6070), model_name=best_model, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\Roshan\AppData\Local\Temp\joblib),
         steps=[('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('numerical_imputer',
                 TransformerWrapper(include=['Unnamed: 0', 'Total Volume',
                                             '4046', '4225', '4770',
                                             'Total Bags', 'Small Bags',
                                             'Large Bags', 'XLarge Bags',
                                             'year'],
                                    transformer=SimpleImputer())),
                ('categ...
                 TransformerWrapper(include=['type'],
                                    transformer=OrdinalEncoder(cols=['type'],
                                                               handle_missing='return_nan',
                                                               mapping=[{'col': 'type',
                                                                         'data_type': dtype('O'),
                                                                         'mapping': conventional    0
organic         1
NaN            -1
dtype: int64}]))),
                ('rest_encoding',
                 TransformerWrapper(include=['Date', 'region'],
                                    transformer=LeaveOneOutEncoder(cols=['Date',
                                                                         'region'],
                                                                   handle_missing='return_nan',
                                                                   random_state=6070)))]), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2023-03-06 23:21:17,933:INFO:Adding model into prep_pipe
2023-03-06 23:21:17,943:INFO:best_model.pkl saved in current working directory
2023-03-06 23:21:17,969:INFO:Pipeline(memory=FastMemory(location=C:\Users\Roshan\AppData\Local\Temp\joblib),
         steps=[('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('numerical_imputer',
                 TransformerWrapper(include=['Unnamed: 0', 'Total Volume',
                                             '4046', '4225', '4770',
                                             'Total Bags', 'Small Bags',
                                             'Large Bags', 'XLarge Bags',
                                             'year'],
                                    transformer=SimpleImputer())),
                ('categ...
                                    transformer=OrdinalEncoder(cols=['type'],
                                                               handle_missing='return_nan',
                                                               mapping=[{'col': 'type',
                                                                         'data_type': dtype('O'),
                                                                         'mapping': conventional    0
organic         1
NaN            -1
dtype: int64}]))),
                ('rest_encoding',
                 TransformerWrapper(include=['Date', 'region'],
                                    transformer=LeaveOneOutEncoder(cols=['Date',
                                                                         'region'],
                                                                   handle_missing='return_nan',
                                                                   random_state=6070))),
                ('trained_model', LGBMRegressor(random_state=6070))])
2023-03-06 23:21:17,969:INFO:save_model() successfully completed......................................
2023-03-20 17:11:16,690:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-03-20 17:11:16,690:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-03-20 17:11:16,690:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-03-20 17:11:16,690:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-03-20 17:11:18,268:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-03-20 17:18:31,325:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-03-20 17:18:31,325:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-03-20 17:18:31,325:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-03-20 17:18:31,325:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-03-20 17:18:32,389:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-03-20 17:20:04,943:INFO:PyCaret RegressionExperiment
2023-03-20 17:20:04,943:INFO:Logging name: reg-default-name
2023-03-20 17:20:04,943:INFO:ML Usecase: MLUsecase.REGRESSION
2023-03-20 17:20:04,943:INFO:version 3.0.0.rc9
2023-03-20 17:20:04,943:INFO:Initializing setup()
2023-03-20 17:20:04,943:INFO:self.USI: 806b
2023-03-20 17:20:04,943:INFO:self._variable_keys: {'fold_shuffle_param', 'y_test', 'USI', 'memory', 'X_test', 'fold_generator', 'n_jobs_param', 'gpu_param', 'y', 'log_plots_param', 'logging_param', 'X', 'X_train', 'target_param', '_ml_usecase', 'html_param', 'gpu_n_jobs_param', 'exp_name_log', 'pipeline', '_available_plots', 'transform_target_param', 'idx', 'fold_groups_param', 'seed', 'exp_id', 'y_train', 'data'}
2023-03-20 17:20:04,943:INFO:Checking environment
2023-03-20 17:20:04,943:INFO:python_version: 3.9.13
2023-03-20 17:20:04,943:INFO:python_build: ('main', 'Aug 25 2022 23:51:50')
2023-03-20 17:20:04,943:INFO:machine: AMD64
2023-03-20 17:20:04,974:INFO:platform: Windows-10-10.0.22621-SP0
2023-03-20 17:20:04,974:INFO:Memory: svmem(total=16540884992, available=6415564800, percent=61.2, used=10125320192, free=6415564800)
2023-03-20 17:20:04,974:INFO:Physical Core: 8
2023-03-20 17:20:04,974:INFO:Logical Core: 16
2023-03-20 17:20:04,974:INFO:Checking libraries
2023-03-20 17:20:04,974:INFO:System:
2023-03-20 17:20:04,974:INFO:    python: 3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]
2023-03-20 17:20:04,974:INFO:executable: C:\Users\Roshan\anaconda3\python.exe
2023-03-20 17:20:04,974:INFO:   machine: Windows-10-10.0.22621-SP0
2023-03-20 17:20:04,974:INFO:PyCaret required dependencies:
2023-03-20 17:20:04,974:INFO:                 pip: 22.2.2
2023-03-20 17:20:04,974:INFO:          setuptools: 63.4.1
2023-03-20 17:20:04,974:INFO:             pycaret: 3.0.0rc9
2023-03-20 17:20:04,974:INFO:             IPython: 7.31.1
2023-03-20 17:20:04,974:INFO:          ipywidgets: 7.6.5
2023-03-20 17:20:04,974:INFO:                tqdm: 4.64.1
2023-03-20 17:20:04,974:INFO:               numpy: 1.21.5
2023-03-20 17:20:04,974:INFO:              pandas: 1.4.4
2023-03-20 17:20:04,974:INFO:              jinja2: 2.11.3
2023-03-20 17:20:04,974:INFO:               scipy: 1.9.1
2023-03-20 17:20:04,974:INFO:              joblib: 1.2.0
2023-03-20 17:20:04,974:INFO:             sklearn: 1.0.2
2023-03-20 17:20:04,974:INFO:                pyod: 1.0.7
2023-03-20 17:20:04,974:INFO:            imblearn: 0.10.1
2023-03-20 17:20:04,974:INFO:   category_encoders: 2.6.0
2023-03-20 17:20:04,974:INFO:            lightgbm: 3.3.5
2023-03-20 17:20:04,974:INFO:               numba: 0.55.1
2023-03-20 17:20:04,974:INFO:            requests: 2.28.1
2023-03-20 17:20:04,974:INFO:          matplotlib: 3.5.2
2023-03-20 17:20:04,974:INFO:          scikitplot: 0.3.7
2023-03-20 17:20:04,974:INFO:         yellowbrick: 1.5
2023-03-20 17:20:04,974:INFO:              plotly: 5.9.0
2023-03-20 17:20:04,974:INFO:             kaleido: 0.2.1
2023-03-20 17:20:04,974:INFO:         statsmodels: 0.13.2
2023-03-20 17:20:04,974:INFO:              sktime: 0.16.1
2023-03-20 17:20:04,974:INFO:               tbats: 1.1.2
2023-03-20 17:20:04,974:INFO:            pmdarima: 2.0.2
2023-03-20 17:20:04,974:INFO:              psutil: 5.9.0
2023-03-20 17:20:04,974:INFO:PyCaret optional dependencies:
2023-03-20 17:20:05,005:INFO:                shap: Not installed
2023-03-20 17:20:05,005:INFO:           interpret: Not installed
2023-03-20 17:20:05,005:INFO:                umap: Not installed
2023-03-20 17:20:05,005:INFO:    pandas_profiling: 4.0.0
2023-03-20 17:20:05,005:INFO:  explainerdashboard: Not installed
2023-03-20 17:20:05,005:INFO:             autoviz: Not installed
2023-03-20 17:20:05,005:INFO:           fairlearn: Not installed
2023-03-20 17:20:05,005:INFO:             xgboost: Not installed
2023-03-20 17:20:05,005:INFO:            catboost: Not installed
2023-03-20 17:20:05,005:INFO:              kmodes: Not installed
2023-03-20 17:20:05,005:INFO:             mlxtend: Not installed
2023-03-20 17:20:05,005:INFO:       statsforecast: Not installed
2023-03-20 17:20:05,005:INFO:        tune_sklearn: Not installed
2023-03-20 17:20:05,005:INFO:                 ray: Not installed
2023-03-20 17:20:05,005:INFO:            hyperopt: Not installed
2023-03-20 17:20:05,005:INFO:              optuna: Not installed
2023-03-20 17:20:05,005:INFO:               skopt: Not installed
2023-03-20 17:20:05,005:INFO:              mlflow: Not installed
2023-03-20 17:20:05,005:INFO:              gradio: Not installed
2023-03-20 17:20:05,005:INFO:             fastapi: Not installed
2023-03-20 17:20:05,005:INFO:             uvicorn: Not installed
2023-03-20 17:20:05,005:INFO:              m2cgen: Not installed
2023-03-20 17:20:05,005:INFO:           evidently: Not installed
2023-03-20 17:20:05,005:INFO:               fugue: Not installed
2023-03-20 17:20:05,005:INFO:           streamlit: 1.19.0
2023-03-20 17:20:05,005:INFO:             prophet: Not installed
2023-03-20 17:20:05,005:INFO:None
2023-03-20 17:20:05,005:INFO:Set up data.
2023-03-20 17:20:05,036:INFO:Set up train/test split.
2023-03-20 17:20:05,052:INFO:Set up index.
2023-03-20 17:20:05,052:INFO:Set up folding strategy.
2023-03-20 17:20:05,052:INFO:Assigning column types.
2023-03-20 17:20:05,068:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-03-20 17:20:05,068:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-03-20 17:20:05,068:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-03-20 17:20:05,083:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-03-20 17:20:05,217:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-03-20 17:20:05,302:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-03-20 17:20:05,302:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-20 17:20:05,349:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-20 17:20:05,349:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-03-20 17:20:05,365:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-03-20 17:20:05,381:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-03-20 17:20:05,490:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-03-20 17:20:05,585:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-03-20 17:20:05,585:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-20 17:20:05,585:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-20 17:20:05,585:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-03-20 17:20:05,585:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-03-20 17:20:05,600:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-03-20 17:20:05,710:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-03-20 17:20:05,804:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-03-20 17:20:05,804:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-20 17:20:05,804:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-20 17:20:05,819:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-03-20 17:20:05,819:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-03-20 17:20:05,944:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-03-20 17:20:06,038:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-03-20 17:20:06,038:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-20 17:20:06,038:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-20 17:20:06,038:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-03-20 17:20:06,054:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-03-20 17:20:06,163:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-03-20 17:20:06,257:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-03-20 17:20:06,257:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-20 17:20:06,257:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-20 17:20:06,273:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-03-20 17:20:06,382:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-03-20 17:20:06,476:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-03-20 17:20:06,476:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-20 17:20:06,476:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-20 17:20:06,491:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-03-20 17:20:06,616:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-03-20 17:20:06,694:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-03-20 17:20:06,694:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-20 17:20:06,710:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-20 17:20:06,835:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-03-20 17:20:06,929:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-03-20 17:20:06,929:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-20 17:20:06,929:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-20 17:20:06,929:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-03-20 17:20:07,070:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-03-20 17:20:07,148:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-20 17:20:07,148:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-20 17:20:07,288:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-03-20 17:20:07,383:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-20 17:20:07,383:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-20 17:20:07,384:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-03-20 17:20:07,585:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-20 17:20:07,585:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-20 17:20:07,820:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-20 17:20:07,820:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-20 17:20:07,836:INFO:Preparing preprocessing pipeline...
2023-03-20 17:20:07,836:INFO:Set up column name cleaning.
2023-03-20 17:20:07,836:INFO:Set up simple imputation.
2023-03-20 17:20:07,852:INFO:Set up encoding of ordinal features.
2023-03-20 17:20:07,852:INFO:Set up encoding of categorical features.
2023-03-20 17:20:08,055:INFO:Finished creating preprocessing pipeline.
2023-03-20 17:20:08,102:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Roshan\AppData\Local\Temp\joblib),
         steps=[('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('numerical_imputer',
                 TransformerWrapper(include=['Unnamed: 0', 'Total Volume',
                                             '4046', '4225', '4770',
                                             'Total Bags', 'Small Bags',
                                             'Large Bags', 'XLarge Bags',
                                             'year'],
                                    transformer=SimpleImputer())),
                ('categ...
                 TransformerWrapper(include=['type'],
                                    transformer=OrdinalEncoder(cols=['type'],
                                                               handle_missing='return_nan',
                                                               mapping=[{'col': 'type',
                                                                         'data_type': dtype('O'),
                                                                         'mapping': conventional    0
organic         1
NaN            -1
dtype: int64}]))),
                ('rest_encoding',
                 TransformerWrapper(include=['Date', 'region'],
                                    transformer=LeaveOneOutEncoder(cols=['Date',
                                                                         'region'],
                                                                   handle_missing='return_nan',
                                                                   random_state=7770)))])
2023-03-20 17:20:08,102:INFO:Creating final display dataframe.
2023-03-20 17:20:08,743:INFO:Setup _display_container:                     Description             Value
0                    Session id              7770
1                        Target      AveragePrice
2                   Target type        Regression
3           Original data shape       (18249, 14)
4        Transformed data shape       (18249, 14)
5   Transformed train set shape       (12774, 14)
6    Transformed test set shape        (5475, 14)
7              Ordinal features                 1
8              Numeric features                10
9          Categorical features                 3
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16               Fold Generator             KFold
17                  Fold Number                10
18                     CPU Jobs                -1
19                      Use GPU             False
20               Log Experiment             False
21              Experiment Name  reg-default-name
22                          USI              806b
2023-03-20 17:20:08,962:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-20 17:20:08,962:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-20 17:20:09,181:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-20 17:20:09,181:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-20 17:20:09,196:INFO:setup() successfully completed in 4.25s...............
2023-03-20 17:20:09,212:INFO:Initializing compare_models()
2023-03-20 17:20:09,212:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E86E44F670>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x000001E86E44F670>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-03-20 17:20:09,212:INFO:Checking exceptions
2023-03-20 17:20:09,212:INFO:Preparing display monitor
2023-03-20 17:20:09,212:INFO:Initializing Linear Regression
2023-03-20 17:20:09,212:INFO:Total runtime is 0.0 minutes
2023-03-20 17:20:09,212:INFO:SubProcess create_model() called ==================================
2023-03-20 17:20:09,212:INFO:Initializing create_model()
2023-03-20 17:20:09,212:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E86E44F670>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E866F1A460>, model_only=True, return_train_score=False, kwargs={})
2023-03-20 17:20:09,212:INFO:Checking exceptions
2023-03-20 17:20:09,212:INFO:Importing libraries
2023-03-20 17:20:09,212:INFO:Copying training dataset
2023-03-20 17:20:09,244:INFO:Defining folds
2023-03-20 17:20:09,244:INFO:Declaring metric variables
2023-03-20 17:20:09,244:INFO:Importing untrained model
2023-03-20 17:20:09,244:INFO:Linear Regression Imported successfully
2023-03-20 17:20:09,244:INFO:Starting cross validation
2023-03-20 17:20:09,259:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-20 17:20:25,362:INFO:Calculating mean and std
2023-03-20 17:20:25,378:INFO:Creating metrics dataframe
2023-03-20 17:20:25,378:INFO:Uploading results into container
2023-03-20 17:20:25,378:INFO:Uploading model into container now
2023-03-20 17:20:25,378:INFO:_master_model_container: 1
2023-03-20 17:20:25,378:INFO:_display_container: 2
2023-03-20 17:20:25,378:INFO:LinearRegression(n_jobs=-1)
2023-03-20 17:20:25,378:INFO:create_model() successfully completed......................................
2023-03-20 17:20:25,634:INFO:SubProcess create_model() end ==================================
2023-03-20 17:20:25,634:INFO:Creating metrics dataframe
2023-03-20 17:20:25,641:INFO:Initializing Lasso Regression
2023-03-20 17:20:25,641:INFO:Total runtime is 0.2738163153330485 minutes
2023-03-20 17:20:25,641:INFO:SubProcess create_model() called ==================================
2023-03-20 17:20:25,641:INFO:Initializing create_model()
2023-03-20 17:20:25,641:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E86E44F670>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E866F1A460>, model_only=True, return_train_score=False, kwargs={})
2023-03-20 17:20:25,641:INFO:Checking exceptions
2023-03-20 17:20:25,641:INFO:Importing libraries
2023-03-20 17:20:25,641:INFO:Copying training dataset
2023-03-20 17:20:25,655:INFO:Defining folds
2023-03-20 17:20:25,655:INFO:Declaring metric variables
2023-03-20 17:20:25,655:INFO:Importing untrained model
2023-03-20 17:20:25,655:INFO:Lasso Regression Imported successfully
2023-03-20 17:20:25,655:INFO:Starting cross validation
2023-03-20 17:20:25,655:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-20 17:20:26,602:WARNING:C:\Users\Roshan\anaconda3\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.671e+01, tolerance: 1.860e-01
  model = cd_fast.enet_coordinate_descent(

2023-03-20 17:20:26,602:WARNING:C:\Users\Roshan\anaconda3\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.614e+01, tolerance: 1.846e-01
  model = cd_fast.enet_coordinate_descent(

2023-03-20 17:20:26,617:WARNING:C:\Users\Roshan\anaconda3\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.719e+01, tolerance: 1.881e-01
  model = cd_fast.enet_coordinate_descent(

2023-03-20 17:20:26,649:WARNING:C:\Users\Roshan\anaconda3\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.573e+01, tolerance: 1.872e-01
  model = cd_fast.enet_coordinate_descent(

2023-03-20 17:20:31,950:WARNING:C:\Users\Roshan\anaconda3\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.620e+01, tolerance: 1.860e-01
  model = cd_fast.enet_coordinate_descent(

2023-03-20 17:20:31,982:WARNING:C:\Users\Roshan\anaconda3\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.644e+01, tolerance: 1.848e-01
  model = cd_fast.enet_coordinate_descent(

2023-03-20 17:20:31,982:WARNING:C:\Users\Roshan\anaconda3\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.193e+01, tolerance: 1.857e-01
  model = cd_fast.enet_coordinate_descent(

2023-03-20 17:20:31,997:WARNING:C:\Users\Roshan\anaconda3\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.532e+01, tolerance: 1.845e-01
  model = cd_fast.enet_coordinate_descent(

2023-03-20 17:20:32,169:WARNING:C:\Users\Roshan\anaconda3\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.662e+01, tolerance: 1.861e-01
  model = cd_fast.enet_coordinate_descent(

2023-03-20 17:20:32,185:WARNING:C:\Users\Roshan\anaconda3\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.686e+01, tolerance: 1.862e-01
  model = cd_fast.enet_coordinate_descent(

2023-03-20 17:20:32,551:INFO:Calculating mean and std
2023-03-20 17:20:32,561:INFO:Creating metrics dataframe
2023-03-20 17:20:32,561:INFO:Uploading results into container
2023-03-20 17:20:32,561:INFO:Uploading model into container now
2023-03-20 17:20:32,561:INFO:_master_model_container: 2
2023-03-20 17:20:32,561:INFO:_display_container: 2
2023-03-20 17:20:32,561:INFO:Lasso(random_state=7770)
2023-03-20 17:20:32,561:INFO:create_model() successfully completed......................................
2023-03-20 17:20:32,749:INFO:SubProcess create_model() end ==================================
2023-03-20 17:20:32,749:INFO:Creating metrics dataframe
2023-03-20 17:20:32,765:INFO:Initializing Ridge Regression
2023-03-20 17:20:32,765:INFO:Total runtime is 0.39253806670506797 minutes
2023-03-20 17:20:32,765:INFO:SubProcess create_model() called ==================================
2023-03-20 17:20:32,765:INFO:Initializing create_model()
2023-03-20 17:20:32,765:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E86E44F670>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E866F1A460>, model_only=True, return_train_score=False, kwargs={})
2023-03-20 17:20:32,765:INFO:Checking exceptions
2023-03-20 17:20:32,765:INFO:Importing libraries
2023-03-20 17:20:32,765:INFO:Copying training dataset
2023-03-20 17:20:32,765:INFO:Defining folds
2023-03-20 17:20:32,765:INFO:Declaring metric variables
2023-03-20 17:20:32,765:INFO:Importing untrained model
2023-03-20 17:20:32,765:INFO:Ridge Regression Imported successfully
2023-03-20 17:20:32,780:INFO:Starting cross validation
2023-03-20 17:20:32,780:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-20 17:20:33,280:WARNING:C:\Users\Roshan\anaconda3\lib\site-packages\sklearn\linear_model\_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=3.12124e-17): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2023-03-20 17:20:33,280:WARNING:C:\Users\Roshan\anaconda3\lib\site-packages\sklearn\linear_model\_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=7.5002e-17): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2023-03-20 17:20:33,296:WARNING:C:\Users\Roshan\anaconda3\lib\site-packages\sklearn\linear_model\_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=3.22422e-17): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2023-03-20 17:20:33,342:WARNING:C:\Users\Roshan\anaconda3\lib\site-packages\sklearn\linear_model\_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=5.7334e-17): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2023-03-20 17:20:33,374:WARNING:C:\Users\Roshan\anaconda3\lib\site-packages\sklearn\linear_model\_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=2.76147e-17): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2023-03-20 17:20:33,467:WARNING:C:\Users\Roshan\anaconda3\lib\site-packages\sklearn\linear_model\_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=3.5587e-17): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2023-03-20 17:20:33,499:WARNING:C:\Users\Roshan\anaconda3\lib\site-packages\sklearn\linear_model\_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=5.67633e-17): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2023-03-20 17:20:33,530:WARNING:C:\Users\Roshan\anaconda3\lib\site-packages\sklearn\linear_model\_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=9.05123e-17): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2023-03-20 17:20:33,811:INFO:Calculating mean and std
2023-03-20 17:20:33,811:INFO:Creating metrics dataframe
2023-03-20 17:20:33,827:INFO:Uploading results into container
2023-03-20 17:20:33,827:INFO:Uploading model into container now
2023-03-20 17:20:33,827:INFO:_master_model_container: 3
2023-03-20 17:20:33,827:INFO:_display_container: 2
2023-03-20 17:20:33,827:INFO:Ridge(random_state=7770)
2023-03-20 17:20:33,827:INFO:create_model() successfully completed......................................
2023-03-20 17:20:34,014:INFO:SubProcess create_model() end ==================================
2023-03-20 17:20:34,014:INFO:Creating metrics dataframe
2023-03-20 17:20:34,014:INFO:Initializing Elastic Net
2023-03-20 17:20:34,014:INFO:Total runtime is 0.4133685429890951 minutes
2023-03-20 17:20:34,014:INFO:SubProcess create_model() called ==================================
2023-03-20 17:20:34,014:INFO:Initializing create_model()
2023-03-20 17:20:34,014:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E86E44F670>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E866F1A460>, model_only=True, return_train_score=False, kwargs={})
2023-03-20 17:20:34,014:INFO:Checking exceptions
2023-03-20 17:20:34,014:INFO:Importing libraries
2023-03-20 17:20:34,014:INFO:Copying training dataset
2023-03-20 17:20:34,030:INFO:Defining folds
2023-03-20 17:20:34,030:INFO:Declaring metric variables
2023-03-20 17:20:34,030:INFO:Importing untrained model
2023-03-20 17:20:34,030:INFO:Elastic Net Imported successfully
2023-03-20 17:20:34,030:INFO:Starting cross validation
2023-03-20 17:20:34,030:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-20 17:20:34,717:WARNING:C:\Users\Roshan\anaconda3\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.896e+01, tolerance: 1.857e-01
  model = cd_fast.enet_coordinate_descent(

2023-03-20 17:20:34,780:WARNING:C:\Users\Roshan\anaconda3\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.249e+02, tolerance: 1.848e-01
  model = cd_fast.enet_coordinate_descent(

2023-03-20 17:20:34,811:WARNING:C:\Users\Roshan\anaconda3\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.158e+02, tolerance: 1.860e-01
  model = cd_fast.enet_coordinate_descent(

2023-03-20 17:20:34,874:WARNING:C:\Users\Roshan\anaconda3\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.125e+02, tolerance: 1.845e-01
  model = cd_fast.enet_coordinate_descent(

2023-03-20 17:20:34,905:WARNING:C:\Users\Roshan\anaconda3\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.336e+02, tolerance: 1.862e-01
  model = cd_fast.enet_coordinate_descent(

2023-03-20 17:20:34,983:WARNING:C:\Users\Roshan\anaconda3\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.260e+02, tolerance: 1.861e-01
  model = cd_fast.enet_coordinate_descent(

2023-03-20 17:20:35,000:WARNING:C:\Users\Roshan\anaconda3\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.327e+02, tolerance: 1.860e-01
  model = cd_fast.enet_coordinate_descent(

2023-03-20 17:20:35,032:WARNING:C:\Users\Roshan\anaconda3\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.229e+02, tolerance: 1.846e-01
  model = cd_fast.enet_coordinate_descent(

2023-03-20 17:20:35,066:WARNING:C:\Users\Roshan\anaconda3\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.369e+02, tolerance: 1.881e-01
  model = cd_fast.enet_coordinate_descent(

2023-03-20 17:20:35,094:WARNING:C:\Users\Roshan\anaconda3\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.133e+02, tolerance: 1.872e-01
  model = cd_fast.enet_coordinate_descent(

2023-03-20 17:20:35,455:INFO:Calculating mean and std
2023-03-20 17:20:35,455:INFO:Creating metrics dataframe
2023-03-20 17:20:35,455:INFO:Uploading results into container
2023-03-20 17:20:35,455:INFO:Uploading model into container now
2023-03-20 17:20:35,455:INFO:_master_model_container: 4
2023-03-20 17:20:35,455:INFO:_display_container: 2
2023-03-20 17:20:35,455:INFO:ElasticNet(random_state=7770)
2023-03-20 17:20:35,455:INFO:create_model() successfully completed......................................
2023-03-20 17:20:35,674:INFO:SubProcess create_model() end ==================================
2023-03-20 17:20:35,674:INFO:Creating metrics dataframe
2023-03-20 17:20:35,674:INFO:Initializing Least Angle Regression
2023-03-20 17:20:35,674:INFO:Total runtime is 0.4410357793172201 minutes
2023-03-20 17:20:35,674:INFO:SubProcess create_model() called ==================================
2023-03-20 17:20:35,674:INFO:Initializing create_model()
2023-03-20 17:20:35,674:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E86E44F670>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E866F1A460>, model_only=True, return_train_score=False, kwargs={})
2023-03-20 17:20:35,674:INFO:Checking exceptions
2023-03-20 17:20:35,674:INFO:Importing libraries
2023-03-20 17:20:35,674:INFO:Copying training dataset
2023-03-20 17:20:35,690:INFO:Defining folds
2023-03-20 17:20:35,690:INFO:Declaring metric variables
2023-03-20 17:20:35,690:INFO:Importing untrained model
2023-03-20 17:20:35,690:INFO:Least Angle Regression Imported successfully
2023-03-20 17:20:35,690:INFO:Starting cross validation
2023-03-20 17:20:35,706:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-20 17:20:36,175:WARNING:C:\Users\Roshan\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-03-20 17:20:36,190:WARNING:C:\Users\Roshan\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-03-20 17:20:36,206:WARNING:C:\Users\Roshan\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-03-20 17:20:36,253:WARNING:C:\Users\Roshan\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-03-20 17:20:36,268:WARNING:C:\Users\Roshan\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-03-20 17:20:36,300:WARNING:C:\Users\Roshan\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-03-20 17:20:36,347:WARNING:C:\Users\Roshan\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-03-20 17:20:36,362:WARNING:C:\Users\Roshan\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-03-20 17:20:36,393:WARNING:C:\Users\Roshan\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-03-20 17:20:36,425:WARNING:C:\Users\Roshan\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-03-20 17:20:36,706:INFO:Calculating mean and std
2023-03-20 17:20:36,706:INFO:Creating metrics dataframe
2023-03-20 17:20:36,722:INFO:Uploading results into container
2023-03-20 17:20:36,722:INFO:Uploading model into container now
2023-03-20 17:20:36,722:INFO:_master_model_container: 5
2023-03-20 17:20:36,722:INFO:_display_container: 2
2023-03-20 17:20:36,722:INFO:Lars(random_state=7770)
2023-03-20 17:20:36,722:INFO:create_model() successfully completed......................................
2023-03-20 17:20:36,894:INFO:SubProcess create_model() end ==================================
2023-03-20 17:20:36,894:INFO:Creating metrics dataframe
2023-03-20 17:20:36,909:INFO:Initializing Lasso Least Angle Regression
2023-03-20 17:20:36,909:INFO:Total runtime is 0.4616151809692383 minutes
2023-03-20 17:20:36,909:INFO:SubProcess create_model() called ==================================
2023-03-20 17:20:36,909:INFO:Initializing create_model()
2023-03-20 17:20:36,909:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E86E44F670>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E866F1A460>, model_only=True, return_train_score=False, kwargs={})
2023-03-20 17:20:36,909:INFO:Checking exceptions
2023-03-20 17:20:36,909:INFO:Importing libraries
2023-03-20 17:20:36,909:INFO:Copying training dataset
2023-03-20 17:20:36,925:INFO:Defining folds
2023-03-20 17:20:36,925:INFO:Declaring metric variables
2023-03-20 17:20:36,925:INFO:Importing untrained model
2023-03-20 17:20:36,925:INFO:Lasso Least Angle Regression Imported successfully
2023-03-20 17:20:36,925:INFO:Starting cross validation
2023-03-20 17:20:36,925:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-20 17:20:37,378:WARNING:C:\Users\Roshan\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-03-20 17:20:37,409:WARNING:C:\Users\Roshan\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-03-20 17:20:37,456:WARNING:C:\Users\Roshan\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-03-20 17:20:37,503:WARNING:C:\Users\Roshan\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-03-20 17:20:37,503:WARNING:C:\Users\Roshan\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-03-20 17:20:37,550:WARNING:C:\Users\Roshan\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-03-20 17:20:37,565:WARNING:C:\Users\Roshan\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-03-20 17:20:37,596:WARNING:C:\Users\Roshan\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-03-20 17:20:37,612:WARNING:C:\Users\Roshan\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-03-20 17:20:37,659:WARNING:C:\Users\Roshan\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-03-20 17:20:37,956:INFO:Calculating mean and std
2023-03-20 17:20:37,956:INFO:Creating metrics dataframe
2023-03-20 17:20:37,956:INFO:Uploading results into container
2023-03-20 17:20:37,956:INFO:Uploading model into container now
2023-03-20 17:20:37,956:INFO:_master_model_container: 6
2023-03-20 17:20:37,956:INFO:_display_container: 2
2023-03-20 17:20:37,956:INFO:LassoLars(random_state=7770)
2023-03-20 17:20:37,956:INFO:create_model() successfully completed......................................
2023-03-20 17:20:38,159:INFO:SubProcess create_model() end ==================================
2023-03-20 17:20:38,159:INFO:Creating metrics dataframe
2023-03-20 17:20:38,159:INFO:Initializing Orthogonal Matching Pursuit
2023-03-20 17:20:38,159:INFO:Total runtime is 0.48244724273681644 minutes
2023-03-20 17:20:38,159:INFO:SubProcess create_model() called ==================================
2023-03-20 17:20:38,159:INFO:Initializing create_model()
2023-03-20 17:20:38,159:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E86E44F670>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E866F1A460>, model_only=True, return_train_score=False, kwargs={})
2023-03-20 17:20:38,159:INFO:Checking exceptions
2023-03-20 17:20:38,159:INFO:Importing libraries
2023-03-20 17:20:38,159:INFO:Copying training dataset
2023-03-20 17:20:38,175:INFO:Defining folds
2023-03-20 17:20:38,175:INFO:Declaring metric variables
2023-03-20 17:20:38,175:INFO:Importing untrained model
2023-03-20 17:20:38,175:INFO:Orthogonal Matching Pursuit Imported successfully
2023-03-20 17:20:38,175:INFO:Starting cross validation
2023-03-20 17:20:38,175:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-20 17:20:38,628:WARNING:C:\Users\Roshan\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-03-20 17:20:38,660:WARNING:C:\Users\Roshan\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-03-20 17:20:38,691:WARNING:C:\Users\Roshan\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-03-20 17:20:38,722:WARNING:C:\Users\Roshan\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-03-20 17:20:38,753:WARNING:C:\Users\Roshan\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-03-20 17:20:38,800:WARNING:C:\Users\Roshan\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-03-20 17:20:38,832:WARNING:C:\Users\Roshan\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-03-20 17:20:38,847:WARNING:C:\Users\Roshan\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-03-20 17:20:38,894:WARNING:C:\Users\Roshan\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-03-20 17:20:38,925:WARNING:C:\Users\Roshan\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-03-20 17:20:39,207:INFO:Calculating mean and std
2023-03-20 17:20:39,207:INFO:Creating metrics dataframe
2023-03-20 17:20:39,223:INFO:Uploading results into container
2023-03-20 17:20:39,223:INFO:Uploading model into container now
2023-03-20 17:20:39,223:INFO:_master_model_container: 7
2023-03-20 17:20:39,223:INFO:_display_container: 2
2023-03-20 17:20:39,223:INFO:OrthogonalMatchingPursuit()
2023-03-20 17:20:39,223:INFO:create_model() successfully completed......................................
2023-03-20 17:20:39,410:INFO:SubProcess create_model() end ==================================
2023-03-20 17:20:39,410:INFO:Creating metrics dataframe
2023-03-20 17:20:39,410:INFO:Initializing Bayesian Ridge
2023-03-20 17:20:39,410:INFO:Total runtime is 0.5032924095789592 minutes
2023-03-20 17:20:39,410:INFO:SubProcess create_model() called ==================================
2023-03-20 17:20:39,410:INFO:Initializing create_model()
2023-03-20 17:20:39,410:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E86E44F670>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E866F1A460>, model_only=True, return_train_score=False, kwargs={})
2023-03-20 17:20:39,410:INFO:Checking exceptions
2023-03-20 17:20:39,410:INFO:Importing libraries
2023-03-20 17:20:39,410:INFO:Copying training dataset
2023-03-20 17:20:39,425:INFO:Defining folds
2023-03-20 17:20:39,425:INFO:Declaring metric variables
2023-03-20 17:20:39,425:INFO:Importing untrained model
2023-03-20 17:20:39,425:INFO:Bayesian Ridge Imported successfully
2023-03-20 17:20:39,425:INFO:Starting cross validation
2023-03-20 17:20:39,425:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-20 17:20:40,461:INFO:Calculating mean and std
2023-03-20 17:20:40,461:INFO:Creating metrics dataframe
2023-03-20 17:20:40,461:INFO:Uploading results into container
2023-03-20 17:20:40,461:INFO:Uploading model into container now
2023-03-20 17:20:40,461:INFO:_master_model_container: 8
2023-03-20 17:20:40,461:INFO:_display_container: 2
2023-03-20 17:20:40,461:INFO:BayesianRidge()
2023-03-20 17:20:40,461:INFO:create_model() successfully completed......................................
2023-03-20 17:20:40,648:INFO:SubProcess create_model() end ==================================
2023-03-20 17:20:40,648:INFO:Creating metrics dataframe
2023-03-20 17:20:40,648:INFO:Initializing Passive Aggressive Regressor
2023-03-20 17:20:40,648:INFO:Total runtime is 0.523933744430542 minutes
2023-03-20 17:20:40,648:INFO:SubProcess create_model() called ==================================
2023-03-20 17:20:40,648:INFO:Initializing create_model()
2023-03-20 17:20:40,648:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E86E44F670>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E866F1A460>, model_only=True, return_train_score=False, kwargs={})
2023-03-20 17:20:40,648:INFO:Checking exceptions
2023-03-20 17:20:40,648:INFO:Importing libraries
2023-03-20 17:20:40,648:INFO:Copying training dataset
2023-03-20 17:20:40,664:INFO:Defining folds
2023-03-20 17:20:40,664:INFO:Declaring metric variables
2023-03-20 17:20:40,664:INFO:Importing untrained model
2023-03-20 17:20:40,664:INFO:Passive Aggressive Regressor Imported successfully
2023-03-20 17:20:40,664:INFO:Starting cross validation
2023-03-20 17:20:40,664:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-20 17:20:41,696:INFO:Calculating mean and std
2023-03-20 17:20:41,696:INFO:Creating metrics dataframe
2023-03-20 17:20:41,696:INFO:Uploading results into container
2023-03-20 17:20:41,696:INFO:Uploading model into container now
2023-03-20 17:20:41,696:INFO:_master_model_container: 9
2023-03-20 17:20:41,696:INFO:_display_container: 2
2023-03-20 17:20:41,696:INFO:PassiveAggressiveRegressor(random_state=7770)
2023-03-20 17:20:41,696:INFO:create_model() successfully completed......................................
2023-03-20 17:20:41,884:INFO:SubProcess create_model() end ==================================
2023-03-20 17:20:41,884:INFO:Creating metrics dataframe
2023-03-20 17:20:41,884:INFO:Initializing Huber Regressor
2023-03-20 17:20:41,884:INFO:Total runtime is 0.5445249875386555 minutes
2023-03-20 17:20:41,884:INFO:SubProcess create_model() called ==================================
2023-03-20 17:20:41,884:INFO:Initializing create_model()
2023-03-20 17:20:41,884:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E86E44F670>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E866F1A460>, model_only=True, return_train_score=False, kwargs={})
2023-03-20 17:20:41,884:INFO:Checking exceptions
2023-03-20 17:20:41,884:INFO:Importing libraries
2023-03-20 17:20:41,884:INFO:Copying training dataset
2023-03-20 17:20:41,899:INFO:Defining folds
2023-03-20 17:20:41,899:INFO:Declaring metric variables
2023-03-20 17:20:41,899:INFO:Importing untrained model
2023-03-20 17:20:41,899:INFO:Huber Regressor Imported successfully
2023-03-20 17:20:41,899:INFO:Starting cross validation
2023-03-20 17:20:41,899:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-20 17:20:43,325:INFO:Calculating mean and std
2023-03-20 17:20:43,325:INFO:Creating metrics dataframe
2023-03-20 17:20:43,325:INFO:Uploading results into container
2023-03-20 17:20:43,325:INFO:Uploading model into container now
2023-03-20 17:20:43,325:INFO:_master_model_container: 10
2023-03-20 17:20:43,325:INFO:_display_container: 2
2023-03-20 17:20:43,325:INFO:HuberRegressor()
2023-03-20 17:20:43,325:INFO:create_model() successfully completed......................................
2023-03-20 17:20:43,513:INFO:SubProcess create_model() end ==================================
2023-03-20 17:20:43,513:INFO:Creating metrics dataframe
2023-03-20 17:20:43,513:INFO:Initializing K Neighbors Regressor
2023-03-20 17:20:43,513:INFO:Total runtime is 0.5716746052106221 minutes
2023-03-20 17:20:43,513:INFO:SubProcess create_model() called ==================================
2023-03-20 17:20:43,513:INFO:Initializing create_model()
2023-03-20 17:20:43,513:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E86E44F670>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E866F1A460>, model_only=True, return_train_score=False, kwargs={})
2023-03-20 17:20:43,513:INFO:Checking exceptions
2023-03-20 17:20:43,513:INFO:Importing libraries
2023-03-20 17:20:43,513:INFO:Copying training dataset
2023-03-20 17:20:43,528:INFO:Defining folds
2023-03-20 17:20:43,528:INFO:Declaring metric variables
2023-03-20 17:20:43,528:INFO:Importing untrained model
2023-03-20 17:20:43,528:INFO:K Neighbors Regressor Imported successfully
2023-03-20 17:20:43,528:INFO:Starting cross validation
2023-03-20 17:20:43,528:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-20 17:20:44,648:INFO:Calculating mean and std
2023-03-20 17:20:44,648:INFO:Creating metrics dataframe
2023-03-20 17:20:44,655:INFO:Uploading results into container
2023-03-20 17:20:44,658:INFO:Uploading model into container now
2023-03-20 17:20:44,658:INFO:_master_model_container: 11
2023-03-20 17:20:44,658:INFO:_display_container: 2
2023-03-20 17:20:44,658:INFO:KNeighborsRegressor(n_jobs=-1)
2023-03-20 17:20:44,658:INFO:create_model() successfully completed......................................
2023-03-20 17:20:44,831:INFO:SubProcess create_model() end ==================================
2023-03-20 17:20:44,831:INFO:Creating metrics dataframe
2023-03-20 17:20:44,847:INFO:Initializing Decision Tree Regressor
2023-03-20 17:20:44,847:INFO:Total runtime is 0.5939071059226989 minutes
2023-03-20 17:20:44,847:INFO:SubProcess create_model() called ==================================
2023-03-20 17:20:44,847:INFO:Initializing create_model()
2023-03-20 17:20:44,847:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E86E44F670>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E866F1A460>, model_only=True, return_train_score=False, kwargs={})
2023-03-20 17:20:44,847:INFO:Checking exceptions
2023-03-20 17:20:44,847:INFO:Importing libraries
2023-03-20 17:20:44,847:INFO:Copying training dataset
2023-03-20 17:20:44,862:INFO:Defining folds
2023-03-20 17:20:44,862:INFO:Declaring metric variables
2023-03-20 17:20:44,862:INFO:Importing untrained model
2023-03-20 17:20:44,862:INFO:Decision Tree Regressor Imported successfully
2023-03-20 17:20:44,862:INFO:Starting cross validation
2023-03-20 17:20:44,862:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-20 17:20:46,191:INFO:Calculating mean and std
2023-03-20 17:20:46,191:INFO:Creating metrics dataframe
2023-03-20 17:20:46,191:INFO:Uploading results into container
2023-03-20 17:20:46,191:INFO:Uploading model into container now
2023-03-20 17:20:46,191:INFO:_master_model_container: 12
2023-03-20 17:20:46,191:INFO:_display_container: 2
2023-03-20 17:20:46,191:INFO:DecisionTreeRegressor(random_state=7770)
2023-03-20 17:20:46,191:INFO:create_model() successfully completed......................................
2023-03-20 17:20:46,379:INFO:SubProcess create_model() end ==================================
2023-03-20 17:20:46,379:INFO:Creating metrics dataframe
2023-03-20 17:20:46,379:INFO:Initializing Random Forest Regressor
2023-03-20 17:20:46,379:INFO:Total runtime is 0.6194393237431843 minutes
2023-03-20 17:20:46,379:INFO:SubProcess create_model() called ==================================
2023-03-20 17:20:46,379:INFO:Initializing create_model()
2023-03-20 17:20:46,379:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E86E44F670>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E866F1A460>, model_only=True, return_train_score=False, kwargs={})
2023-03-20 17:20:46,379:INFO:Checking exceptions
2023-03-20 17:20:46,379:INFO:Importing libraries
2023-03-20 17:20:46,379:INFO:Copying training dataset
2023-03-20 17:20:46,394:INFO:Defining folds
2023-03-20 17:20:46,394:INFO:Declaring metric variables
2023-03-20 17:20:46,394:INFO:Importing untrained model
2023-03-20 17:20:46,394:INFO:Random Forest Regressor Imported successfully
2023-03-20 17:20:46,394:INFO:Starting cross validation
2023-03-20 17:20:46,394:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-20 17:20:54,306:WARNING:C:\Users\Roshan\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 1.76s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-20 17:20:56,558:WARNING:C:\Users\Roshan\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 1.70s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-20 17:20:57,747:WARNING:C:\Users\Roshan\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 1.04s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-20 17:20:57,794:WARNING:C:\Users\Roshan\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.95s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-20 17:20:58,870:WARNING:C:\Users\Roshan\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 1.11s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-03-20 17:20:59,678:INFO:Calculating mean and std
2023-03-20 17:20:59,678:INFO:Creating metrics dataframe
2023-03-20 17:20:59,678:INFO:Uploading results into container
2023-03-20 17:20:59,678:INFO:Uploading model into container now
2023-03-20 17:20:59,678:INFO:_master_model_container: 13
2023-03-20 17:20:59,678:INFO:_display_container: 2
2023-03-20 17:20:59,678:INFO:RandomForestRegressor(n_jobs=-1, random_state=7770)
2023-03-20 17:20:59,678:INFO:create_model() successfully completed......................................
2023-03-20 17:20:59,865:INFO:SubProcess create_model() end ==================================
2023-03-20 17:20:59,865:INFO:Creating metrics dataframe
2023-03-20 17:20:59,865:INFO:Initializing Extra Trees Regressor
2023-03-20 17:20:59,865:INFO:Total runtime is 0.8442193786303201 minutes
2023-03-20 17:20:59,881:INFO:SubProcess create_model() called ==================================
2023-03-20 17:20:59,881:INFO:Initializing create_model()
2023-03-20 17:20:59,881:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E86E44F670>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E866F1A460>, model_only=True, return_train_score=False, kwargs={})
2023-03-20 17:20:59,881:INFO:Checking exceptions
2023-03-20 17:20:59,881:INFO:Importing libraries
2023-03-20 17:20:59,881:INFO:Copying training dataset
2023-03-20 17:20:59,881:INFO:Defining folds
2023-03-20 17:20:59,881:INFO:Declaring metric variables
2023-03-20 17:20:59,881:INFO:Importing untrained model
2023-03-20 17:20:59,881:INFO:Extra Trees Regressor Imported successfully
2023-03-20 17:20:59,881:INFO:Starting cross validation
2023-03-20 17:20:59,897:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-20 17:21:06,774:INFO:Calculating mean and std
2023-03-20 17:21:06,774:INFO:Creating metrics dataframe
2023-03-20 17:21:06,774:INFO:Uploading results into container
2023-03-20 17:21:06,774:INFO:Uploading model into container now
2023-03-20 17:21:06,774:INFO:_master_model_container: 14
2023-03-20 17:21:06,774:INFO:_display_container: 2
2023-03-20 17:21:06,774:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=7770)
2023-03-20 17:21:06,774:INFO:create_model() successfully completed......................................
2023-03-20 17:21:06,993:INFO:SubProcess create_model() end ==================================
2023-03-20 17:21:06,993:INFO:Creating metrics dataframe
2023-03-20 17:21:06,993:INFO:Initializing AdaBoost Regressor
2023-03-20 17:21:06,993:INFO:Total runtime is 0.9630145589510599 minutes
2023-03-20 17:21:06,993:INFO:SubProcess create_model() called ==================================
2023-03-20 17:21:06,993:INFO:Initializing create_model()
2023-03-20 17:21:07,009:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E86E44F670>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E866F1A460>, model_only=True, return_train_score=False, kwargs={})
2023-03-20 17:21:07,009:INFO:Checking exceptions
2023-03-20 17:21:07,009:INFO:Importing libraries
2023-03-20 17:21:07,009:INFO:Copying training dataset
2023-03-20 17:21:07,009:INFO:Defining folds
2023-03-20 17:21:07,009:INFO:Declaring metric variables
2023-03-20 17:21:07,009:INFO:Importing untrained model
2023-03-20 17:21:07,009:INFO:AdaBoost Regressor Imported successfully
2023-03-20 17:21:07,009:INFO:Starting cross validation
2023-03-20 17:21:07,024:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-20 17:21:10,426:INFO:Calculating mean and std
2023-03-20 17:21:10,426:INFO:Creating metrics dataframe
2023-03-20 17:21:10,426:INFO:Uploading results into container
2023-03-20 17:21:10,426:INFO:Uploading model into container now
2023-03-20 17:21:10,426:INFO:_master_model_container: 15
2023-03-20 17:21:10,426:INFO:_display_container: 2
2023-03-20 17:21:10,426:INFO:AdaBoostRegressor(random_state=7770)
2023-03-20 17:21:10,426:INFO:create_model() successfully completed......................................
2023-03-20 17:21:10,613:INFO:SubProcess create_model() end ==================================
2023-03-20 17:21:10,613:INFO:Creating metrics dataframe
2023-03-20 17:21:10,613:INFO:Initializing Gradient Boosting Regressor
2023-03-20 17:21:10,613:INFO:Total runtime is 1.0233541210492452 minutes
2023-03-20 17:21:10,629:INFO:SubProcess create_model() called ==================================
2023-03-20 17:21:10,629:INFO:Initializing create_model()
2023-03-20 17:21:10,629:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E86E44F670>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E866F1A460>, model_only=True, return_train_score=False, kwargs={})
2023-03-20 17:21:10,629:INFO:Checking exceptions
2023-03-20 17:21:10,629:INFO:Importing libraries
2023-03-20 17:21:10,629:INFO:Copying training dataset
2023-03-20 17:21:10,629:INFO:Defining folds
2023-03-20 17:21:10,629:INFO:Declaring metric variables
2023-03-20 17:21:10,629:INFO:Importing untrained model
2023-03-20 17:21:10,629:INFO:Gradient Boosting Regressor Imported successfully
2023-03-20 17:21:10,629:INFO:Starting cross validation
2023-03-20 17:21:10,645:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-20 17:21:18,620:INFO:Calculating mean and std
2023-03-20 17:21:18,621:INFO:Creating metrics dataframe
2023-03-20 17:21:18,627:INFO:Uploading results into container
2023-03-20 17:21:18,628:INFO:Uploading model into container now
2023-03-20 17:21:18,628:INFO:_master_model_container: 16
2023-03-20 17:21:18,628:INFO:_display_container: 2
2023-03-20 17:21:18,628:INFO:GradientBoostingRegressor(random_state=7770)
2023-03-20 17:21:18,628:INFO:create_model() successfully completed......................................
2023-03-20 17:21:18,815:INFO:SubProcess create_model() end ==================================
2023-03-20 17:21:18,815:INFO:Creating metrics dataframe
2023-03-20 17:21:18,821:INFO:Initializing Light Gradient Boosting Machine
2023-03-20 17:21:18,821:INFO:Total runtime is 1.1601533850034078 minutes
2023-03-20 17:21:18,821:INFO:SubProcess create_model() called ==================================
2023-03-20 17:21:18,821:INFO:Initializing create_model()
2023-03-20 17:21:18,821:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E86E44F670>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E866F1A460>, model_only=True, return_train_score=False, kwargs={})
2023-03-20 17:21:18,821:INFO:Checking exceptions
2023-03-20 17:21:18,821:INFO:Importing libraries
2023-03-20 17:21:18,821:INFO:Copying training dataset
2023-03-20 17:21:18,835:INFO:Defining folds
2023-03-20 17:21:18,835:INFO:Declaring metric variables
2023-03-20 17:21:18,835:INFO:Importing untrained model
2023-03-20 17:21:18,835:INFO:Light Gradient Boosting Machine Imported successfully
2023-03-20 17:21:18,835:INFO:Starting cross validation
2023-03-20 17:21:18,835:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-20 17:21:22,148:INFO:Calculating mean and std
2023-03-20 17:21:22,152:INFO:Creating metrics dataframe
2023-03-20 17:21:22,152:INFO:Uploading results into container
2023-03-20 17:21:22,152:INFO:Uploading model into container now
2023-03-20 17:21:22,152:INFO:_master_model_container: 17
2023-03-20 17:21:22,152:INFO:_display_container: 2
2023-03-20 17:21:22,152:INFO:LGBMRegressor(random_state=7770)
2023-03-20 17:21:22,152:INFO:create_model() successfully completed......................................
2023-03-20 17:21:22,342:INFO:SubProcess create_model() end ==================================
2023-03-20 17:21:22,342:INFO:Creating metrics dataframe
2023-03-20 17:21:22,342:INFO:Initializing Dummy Regressor
2023-03-20 17:21:22,342:INFO:Total runtime is 1.2188351551691692 minutes
2023-03-20 17:21:22,342:INFO:SubProcess create_model() called ==================================
2023-03-20 17:21:22,342:INFO:Initializing create_model()
2023-03-20 17:21:22,342:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E86E44F670>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E866F1A460>, model_only=True, return_train_score=False, kwargs={})
2023-03-20 17:21:22,342:INFO:Checking exceptions
2023-03-20 17:21:22,342:INFO:Importing libraries
2023-03-20 17:21:22,342:INFO:Copying training dataset
2023-03-20 17:21:22,358:INFO:Defining folds
2023-03-20 17:21:22,358:INFO:Declaring metric variables
2023-03-20 17:21:22,358:INFO:Importing untrained model
2023-03-20 17:21:22,358:INFO:Dummy Regressor Imported successfully
2023-03-20 17:21:22,358:INFO:Starting cross validation
2023-03-20 17:21:22,358:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-20 17:21:23,321:INFO:Calculating mean and std
2023-03-20 17:21:23,323:INFO:Creating metrics dataframe
2023-03-20 17:21:23,323:INFO:Uploading results into container
2023-03-20 17:21:23,323:INFO:Uploading model into container now
2023-03-20 17:21:23,323:INFO:_master_model_container: 18
2023-03-20 17:21:23,323:INFO:_display_container: 2
2023-03-20 17:21:23,323:INFO:DummyRegressor()
2023-03-20 17:21:23,323:INFO:create_model() successfully completed......................................
2023-03-20 17:21:23,510:INFO:SubProcess create_model() end ==================================
2023-03-20 17:21:23,510:INFO:Creating metrics dataframe
2023-03-20 17:21:23,525:INFO:Initializing create_model()
2023-03-20 17:21:23,525:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E86E44F670>, estimator=LGBMRegressor(random_state=7770), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-03-20 17:21:23,525:INFO:Checking exceptions
2023-03-20 17:21:23,525:INFO:Importing libraries
2023-03-20 17:21:23,525:INFO:Copying training dataset
2023-03-20 17:21:23,525:INFO:Defining folds
2023-03-20 17:21:23,525:INFO:Declaring metric variables
2023-03-20 17:21:23,525:INFO:Importing untrained model
2023-03-20 17:21:23,525:INFO:Declaring custom model
2023-03-20 17:21:23,525:INFO:Light Gradient Boosting Machine Imported successfully
2023-03-20 17:21:23,541:INFO:Cross validation set to False
2023-03-20 17:21:23,541:INFO:Fitting Model
2023-03-20 17:21:24,089:INFO:LGBMRegressor(random_state=7770)
2023-03-20 17:21:24,089:INFO:create_model() successfully completed......................................
2023-03-20 17:21:24,315:INFO:_master_model_container: 18
2023-03-20 17:21:24,315:INFO:_display_container: 2
2023-03-20 17:21:24,315:INFO:LGBMRegressor(random_state=7770)
2023-03-20 17:21:24,315:INFO:compare_models() successfully completed......................................
2023-03-20 17:21:24,373:INFO:Initializing save_model()
2023-03-20 17:21:24,373:INFO:save_model(model=LGBMRegressor(random_state=7770), model_name=best_model, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\Roshan\AppData\Local\Temp\joblib),
         steps=[('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('numerical_imputer',
                 TransformerWrapper(include=['Unnamed: 0', 'Total Volume',
                                             '4046', '4225', '4770',
                                             'Total Bags', 'Small Bags',
                                             'Large Bags', 'XLarge Bags',
                                             'year'],
                                    transformer=SimpleImputer())),
                ('categ...
                 TransformerWrapper(include=['type'],
                                    transformer=OrdinalEncoder(cols=['type'],
                                                               handle_missing='return_nan',
                                                               mapping=[{'col': 'type',
                                                                         'data_type': dtype('O'),
                                                                         'mapping': conventional    0
organic         1
NaN            -1
dtype: int64}]))),
                ('rest_encoding',
                 TransformerWrapper(include=['Date', 'region'],
                                    transformer=LeaveOneOutEncoder(cols=['Date',
                                                                         'region'],
                                                                   handle_missing='return_nan',
                                                                   random_state=7770)))]), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2023-03-20 17:21:24,373:INFO:Adding model into prep_pipe
2023-03-20 17:21:24,404:INFO:best_model.pkl saved in current working directory
2023-03-20 17:21:24,451:INFO:Pipeline(memory=FastMemory(location=C:\Users\Roshan\AppData\Local\Temp\joblib),
         steps=[('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('numerical_imputer',
                 TransformerWrapper(include=['Unnamed: 0', 'Total Volume',
                                             '4046', '4225', '4770',
                                             'Total Bags', 'Small Bags',
                                             'Large Bags', 'XLarge Bags',
                                             'year'],
                                    transformer=SimpleImputer())),
                ('categ...
                                    transformer=OrdinalEncoder(cols=['type'],
                                                               handle_missing='return_nan',
                                                               mapping=[{'col': 'type',
                                                                         'data_type': dtype('O'),
                                                                         'mapping': conventional    0
organic         1
NaN            -1
dtype: int64}]))),
                ('rest_encoding',
                 TransformerWrapper(include=['Date', 'region'],
                                    transformer=LeaveOneOutEncoder(cols=['Date',
                                                                         'region'],
                                                                   handle_missing='return_nan',
                                                                   random_state=7770))),
                ('trained_model', LGBMRegressor(random_state=7770))])
2023-03-20 17:21:24,451:INFO:save_model() successfully completed......................................
2023-03-20 17:52:46,990:INFO:PyCaret RegressionExperiment
2023-03-20 17:52:46,990:INFO:Logging name: reg-default-name
2023-03-20 17:52:46,990:INFO:ML Usecase: MLUsecase.REGRESSION
2023-03-20 17:52:46,990:INFO:version 3.0.0.rc9
2023-03-20 17:52:46,990:INFO:Initializing setup()
2023-03-20 17:52:46,990:INFO:self.USI: 576d
2023-03-20 17:52:46,990:INFO:self._variable_keys: {'fold_shuffle_param', 'y_test', 'USI', 'memory', 'X_test', 'fold_generator', 'n_jobs_param', 'gpu_param', 'y', 'log_plots_param', 'logging_param', 'X', 'X_train', 'target_param', '_ml_usecase', 'html_param', 'gpu_n_jobs_param', 'exp_name_log', 'pipeline', '_available_plots', 'transform_target_param', 'idx', 'fold_groups_param', 'seed', 'exp_id', 'y_train', 'data'}
2023-03-20 17:52:46,990:INFO:Checking environment
2023-03-20 17:52:46,990:INFO:python_version: 3.9.13
2023-03-20 17:52:46,990:INFO:python_build: ('main', 'Aug 25 2022 23:51:50')
2023-03-20 17:52:46,990:INFO:machine: AMD64
2023-03-20 17:52:46,990:INFO:platform: Windows-10-10.0.22621-SP0
2023-03-20 17:52:46,990:INFO:Memory: svmem(total=16540884992, available=6260858880, percent=62.1, used=10280026112, free=6260858880)
2023-03-20 17:52:46,990:INFO:Physical Core: 8
2023-03-20 17:52:46,990:INFO:Logical Core: 16
2023-03-20 17:52:46,990:INFO:Checking libraries
2023-03-20 17:52:46,990:INFO:System:
2023-03-20 17:52:46,994:INFO:    python: 3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]
2023-03-20 17:52:46,994:INFO:executable: C:\Users\Roshan\anaconda3\python.exe
2023-03-20 17:52:46,994:INFO:   machine: Windows-10-10.0.22621-SP0
2023-03-20 17:52:46,994:INFO:PyCaret required dependencies:
2023-03-20 17:52:46,994:INFO:                 pip: 22.2.2
2023-03-20 17:52:46,994:INFO:          setuptools: 63.4.1
2023-03-20 17:52:46,994:INFO:             pycaret: 3.0.0rc9
2023-03-20 17:52:46,994:INFO:             IPython: 7.31.1
2023-03-20 17:52:46,994:INFO:          ipywidgets: 7.6.5
2023-03-20 17:52:46,994:INFO:                tqdm: 4.64.1
2023-03-20 17:52:46,994:INFO:               numpy: 1.21.5
2023-03-20 17:52:46,994:INFO:              pandas: 1.4.4
2023-03-20 17:52:46,994:INFO:              jinja2: 2.11.3
2023-03-20 17:52:46,994:INFO:               scipy: 1.9.1
2023-03-20 17:52:46,994:INFO:              joblib: 1.2.0
2023-03-20 17:52:46,994:INFO:             sklearn: 1.0.2
2023-03-20 17:52:46,994:INFO:                pyod: 1.0.7
2023-03-20 17:52:46,994:INFO:            imblearn: 0.10.1
2023-03-20 17:52:46,994:INFO:   category_encoders: 2.6.0
2023-03-20 17:52:46,994:INFO:            lightgbm: 3.3.5
2023-03-20 17:52:46,994:INFO:               numba: 0.55.1
2023-03-20 17:52:46,994:INFO:            requests: 2.28.1
2023-03-20 17:52:46,994:INFO:          matplotlib: 3.5.2
2023-03-20 17:52:46,994:INFO:          scikitplot: 0.3.7
2023-03-20 17:52:46,994:INFO:         yellowbrick: 1.5
2023-03-20 17:52:46,994:INFO:              plotly: 5.9.0
2023-03-20 17:52:46,994:INFO:             kaleido: 0.2.1
2023-03-20 17:52:46,994:INFO:         statsmodels: 0.13.2
2023-03-20 17:52:46,994:INFO:              sktime: 0.16.1
2023-03-20 17:52:46,994:INFO:               tbats: 1.1.2
2023-03-20 17:52:46,994:INFO:            pmdarima: 2.0.2
2023-03-20 17:52:46,994:INFO:              psutil: 5.9.0
2023-03-20 17:52:46,994:INFO:PyCaret optional dependencies:
2023-03-20 17:52:46,994:INFO:                shap: Not installed
2023-03-20 17:52:46,994:INFO:           interpret: Not installed
2023-03-20 17:52:46,994:INFO:                umap: Not installed
2023-03-20 17:52:46,994:INFO:    pandas_profiling: 4.0.0
2023-03-20 17:52:46,994:INFO:  explainerdashboard: Not installed
2023-03-20 17:52:46,994:INFO:             autoviz: Not installed
2023-03-20 17:52:46,997:INFO:           fairlearn: Not installed
2023-03-20 17:52:46,997:INFO:             xgboost: Not installed
2023-03-20 17:52:46,997:INFO:            catboost: Not installed
2023-03-20 17:52:46,997:INFO:              kmodes: Not installed
2023-03-20 17:52:46,997:INFO:             mlxtend: Not installed
2023-03-20 17:52:46,997:INFO:       statsforecast: Not installed
2023-03-20 17:52:46,997:INFO:        tune_sklearn: Not installed
2023-03-20 17:52:46,997:INFO:                 ray: Not installed
2023-03-20 17:52:46,997:INFO:            hyperopt: Not installed
2023-03-20 17:52:46,997:INFO:              optuna: Not installed
2023-03-20 17:52:46,997:INFO:               skopt: Not installed
2023-03-20 17:52:46,997:INFO:              mlflow: Not installed
2023-03-20 17:52:46,997:INFO:              gradio: Not installed
2023-03-20 17:52:46,997:INFO:             fastapi: Not installed
2023-03-20 17:52:46,997:INFO:             uvicorn: Not installed
2023-03-20 17:52:46,997:INFO:              m2cgen: Not installed
2023-03-20 17:52:46,997:INFO:           evidently: Not installed
2023-03-20 17:52:46,997:INFO:               fugue: Not installed
2023-03-20 17:52:46,997:INFO:           streamlit: 1.19.0
2023-03-20 17:52:46,997:INFO:             prophet: Not installed
2023-03-20 17:52:46,997:INFO:None
2023-03-20 17:52:46,997:INFO:Set up data.
2023-03-20 17:52:47,022:INFO:Set up train/test split.
2023-03-20 17:52:47,034:INFO:Set up index.
2023-03-20 17:52:47,038:INFO:Set up folding strategy.
2023-03-20 17:52:47,039:INFO:Assigning column types.
2023-03-20 17:52:47,048:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-03-20 17:52:47,048:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-03-20 17:52:47,054:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-03-20 17:52:47,054:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-03-20 17:52:47,186:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-03-20 17:52:47,260:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-03-20 17:52:47,260:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-20 17:52:47,260:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-20 17:52:47,260:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-03-20 17:52:47,274:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-03-20 17:52:47,274:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-03-20 17:52:47,388:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-03-20 17:52:47,478:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-03-20 17:52:47,478:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-20 17:52:47,478:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-20 17:52:47,478:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-03-20 17:52:47,478:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-03-20 17:52:47,494:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-03-20 17:52:47,609:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-03-20 17:52:47,683:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-03-20 17:52:47,683:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-20 17:52:47,683:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-20 17:52:47,698:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-03-20 17:52:47,698:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-03-20 17:52:47,810:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-03-20 17:52:47,902:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-03-20 17:52:47,902:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-20 17:52:47,902:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-20 17:52:47,902:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-03-20 17:52:47,923:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-03-20 17:52:48,031:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-03-20 17:52:48,108:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-03-20 17:52:48,108:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-20 17:52:48,108:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-20 17:52:48,127:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-03-20 17:52:48,234:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-03-20 17:52:48,314:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-03-20 17:52:48,314:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-20 17:52:48,328:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-20 17:52:48,328:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-03-20 17:52:48,454:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-03-20 17:52:48,533:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-03-20 17:52:48,533:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-20 17:52:48,533:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-20 17:52:48,660:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-03-20 17:52:48,739:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-03-20 17:52:48,753:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-20 17:52:48,754:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-20 17:52:48,755:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-03-20 17:52:48,878:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-03-20 17:52:48,963:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-20 17:52:48,963:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-20 17:52:49,081:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-03-20 17:52:49,159:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-20 17:52:49,159:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-20 17:52:49,175:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-03-20 17:52:49,378:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-20 17:52:49,378:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-20 17:52:49,596:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-20 17:52:49,596:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-20 17:52:49,597:INFO:Preparing preprocessing pipeline...
2023-03-20 17:52:49,600:INFO:Set up column name cleaning.
2023-03-20 17:52:49,600:INFO:Set up simple imputation.
2023-03-20 17:52:49,600:INFO:Set up encoding of ordinal features.
2023-03-20 17:52:49,609:INFO:Set up encoding of categorical features.
2023-03-20 17:52:49,772:INFO:Finished creating preprocessing pipeline.
2023-03-20 17:52:49,825:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\Roshan\AppData\Local\Temp\joblib),
         steps=[('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('numerical_imputer',
                 TransformerWrapper(include=['Unnamed: 0', 'Total Volume',
                                             '4046', '4225', '4770',
                                             'Total Bags', 'Small Bags',
                                             'Large Bags', 'XLarge Bags',
                                             'year'],
                                    transformer=SimpleImputer())),
                ('categ...
                 TransformerWrapper(include=['type'],
                                    transformer=OrdinalEncoder(cols=['type'],
                                                               handle_missing='return_nan',
                                                               mapping=[{'col': 'type',
                                                                         'data_type': dtype('O'),
                                                                         'mapping': conventional    0
organic         1
NaN            -1
dtype: int64}]))),
                ('rest_encoding',
                 TransformerWrapper(include=['Date', 'region'],
                                    transformer=LeaveOneOutEncoder(cols=['Date',
                                                                         'region'],
                                                                   handle_missing='return_nan',
                                                                   random_state=807)))])
2023-03-20 17:52:49,825:INFO:Creating final display dataframe.
2023-03-20 17:52:50,413:INFO:Setup _display_container:                     Description             Value
0                    Session id               807
1                        Target      AveragePrice
2                   Target type        Regression
3           Original data shape       (18249, 14)
4        Transformed data shape       (18249, 14)
5   Transformed train set shape       (12774, 14)
6    Transformed test set shape        (5475, 14)
7              Ordinal features                 1
8              Numeric features                10
9          Categorical features                 3
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16               Fold Generator             KFold
17                  Fold Number                10
18                     CPU Jobs                -1
19                      Use GPU             False
20               Log Experiment             False
21              Experiment Name  reg-default-name
22                          USI              576d
2023-03-20 17:52:50,641:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-20 17:52:50,641:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-20 17:52:50,844:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-20 17:52:50,844:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-03-20 17:52:50,844:INFO:setup() successfully completed in 3.86s...............
2023-03-20 17:52:50,861:INFO:Initializing compare_models()
2023-03-20 17:52:50,861:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E87127AB80>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x000001E87127AB80>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-03-20 17:52:50,861:INFO:Checking exceptions
2023-03-20 17:52:50,867:INFO:Preparing display monitor
2023-03-20 17:52:50,867:INFO:Initializing Linear Regression
2023-03-20 17:52:50,867:INFO:Total runtime is 0.0 minutes
2023-03-20 17:52:50,867:INFO:SubProcess create_model() called ==================================
2023-03-20 17:52:50,867:INFO:Initializing create_model()
2023-03-20 17:52:50,867:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E87127AB80>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E86F80FB20>, model_only=True, return_train_score=False, kwargs={})
2023-03-20 17:52:50,867:INFO:Checking exceptions
2023-03-20 17:52:50,867:INFO:Importing libraries
2023-03-20 17:52:50,867:INFO:Copying training dataset
2023-03-20 17:52:50,876:INFO:Defining folds
2023-03-20 17:52:50,876:INFO:Declaring metric variables
2023-03-20 17:52:50,876:INFO:Importing untrained model
2023-03-20 17:52:50,876:INFO:Linear Regression Imported successfully
2023-03-20 17:52:50,892:INFO:Starting cross validation
2023-03-20 17:52:50,892:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-20 17:53:01,458:INFO:Calculating mean and std
2023-03-20 17:53:01,458:INFO:Creating metrics dataframe
2023-03-20 17:53:01,458:INFO:Uploading results into container
2023-03-20 17:53:01,458:INFO:Uploading model into container now
2023-03-20 17:53:01,458:INFO:_master_model_container: 1
2023-03-20 17:53:01,458:INFO:_display_container: 2
2023-03-20 17:53:01,458:INFO:LinearRegression(n_jobs=-1)
2023-03-20 17:53:01,458:INFO:create_model() successfully completed......................................
2023-03-20 17:53:01,662:INFO:SubProcess create_model() end ==================================
2023-03-20 17:53:01,662:INFO:Creating metrics dataframe
2023-03-20 17:53:01,662:INFO:Initializing Lasso Regression
2023-03-20 17:53:01,662:INFO:Total runtime is 0.17990809679031372 minutes
2023-03-20 17:53:01,662:INFO:SubProcess create_model() called ==================================
2023-03-20 17:53:01,662:INFO:Initializing create_model()
2023-03-20 17:53:01,662:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E87127AB80>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E86F80FB20>, model_only=True, return_train_score=False, kwargs={})
2023-03-20 17:53:01,662:INFO:Checking exceptions
2023-03-20 17:53:01,662:INFO:Importing libraries
2023-03-20 17:53:01,662:INFO:Copying training dataset
2023-03-20 17:53:01,687:INFO:Defining folds
2023-03-20 17:53:01,687:INFO:Declaring metric variables
2023-03-20 17:53:01,688:INFO:Importing untrained model
2023-03-20 17:53:01,688:INFO:Lasso Regression Imported successfully
2023-03-20 17:53:01,688:INFO:Starting cross validation
2023-03-20 17:53:01,692:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-20 17:53:02,672:WARNING:C:\Users\Roshan\anaconda3\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.786e+01, tolerance: 1.880e-01
  model = cd_fast.enet_coordinate_descent(

2023-03-20 17:53:02,677:WARNING:C:\Users\Roshan\anaconda3\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.901e+01, tolerance: 1.880e-01
  model = cd_fast.enet_coordinate_descent(

2023-03-20 17:53:02,739:WARNING:C:\Users\Roshan\anaconda3\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.888e+01, tolerance: 1.869e-01
  model = cd_fast.enet_coordinate_descent(

2023-03-20 17:53:02,751:WARNING:C:\Users\Roshan\anaconda3\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.343e+01, tolerance: 1.860e-01
  model = cd_fast.enet_coordinate_descent(

2023-03-20 17:53:07,975:WARNING:C:\Users\Roshan\anaconda3\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.735e+01, tolerance: 1.868e-01
  model = cd_fast.enet_coordinate_descent(

2023-03-20 17:53:08,075:WARNING:C:\Users\Roshan\anaconda3\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.804e+01, tolerance: 1.877e-01
  model = cd_fast.enet_coordinate_descent(

2023-03-20 17:53:08,150:WARNING:C:\Users\Roshan\anaconda3\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.797e+01, tolerance: 1.880e-01
  model = cd_fast.enet_coordinate_descent(

2023-03-20 17:53:08,211:WARNING:C:\Users\Roshan\anaconda3\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.821e+01, tolerance: 1.886e-01
  model = cd_fast.enet_coordinate_descent(

2023-03-20 17:53:08,211:WARNING:C:\Users\Roshan\anaconda3\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.817e+01, tolerance: 1.881e-01
  model = cd_fast.enet_coordinate_descent(

2023-03-20 17:53:08,227:WARNING:C:\Users\Roshan\anaconda3\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.917e+01, tolerance: 1.888e-01
  model = cd_fast.enet_coordinate_descent(

2023-03-20 17:53:08,578:INFO:Calculating mean and std
2023-03-20 17:53:08,578:INFO:Creating metrics dataframe
2023-03-20 17:53:08,592:INFO:Uploading results into container
2023-03-20 17:53:08,593:INFO:Uploading model into container now
2023-03-20 17:53:08,593:INFO:_master_model_container: 2
2023-03-20 17:53:08,593:INFO:_display_container: 2
2023-03-20 17:53:08,595:INFO:Lasso(random_state=807)
2023-03-20 17:53:08,595:INFO:create_model() successfully completed......................................
2023-03-20 17:53:08,762:INFO:SubProcess create_model() end ==================================
2023-03-20 17:53:08,762:INFO:Creating metrics dataframe
2023-03-20 17:53:08,781:INFO:Initializing Ridge Regression
2023-03-20 17:53:08,781:INFO:Total runtime is 0.2985656499862671 minutes
2023-03-20 17:53:08,781:INFO:SubProcess create_model() called ==================================
2023-03-20 17:53:08,781:INFO:Initializing create_model()
2023-03-20 17:53:08,781:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E87127AB80>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E86F80FB20>, model_only=True, return_train_score=False, kwargs={})
2023-03-20 17:53:08,781:INFO:Checking exceptions
2023-03-20 17:53:08,781:INFO:Importing libraries
2023-03-20 17:53:08,781:INFO:Copying training dataset
2023-03-20 17:53:08,796:INFO:Defining folds
2023-03-20 17:53:08,796:INFO:Declaring metric variables
2023-03-20 17:53:08,796:INFO:Importing untrained model
2023-03-20 17:53:08,796:INFO:Ridge Regression Imported successfully
2023-03-20 17:53:08,796:INFO:Starting cross validation
2023-03-20 17:53:08,796:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-20 17:53:09,265:WARNING:C:\Users\Roshan\anaconda3\lib\site-packages\sklearn\linear_model\_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=8.60343e-17): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2023-03-20 17:53:09,313:WARNING:C:\Users\Roshan\anaconda3\lib\site-packages\sklearn\linear_model\_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=1.03023e-16): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2023-03-20 17:53:09,328:WARNING:C:\Users\Roshan\anaconda3\lib\site-packages\sklearn\linear_model\_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=6.56794e-17): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2023-03-20 17:53:09,361:WARNING:C:\Users\Roshan\anaconda3\lib\site-packages\sklearn\linear_model\_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=3.74e-17): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2023-03-20 17:53:09,418:WARNING:C:\Users\Roshan\anaconda3\lib\site-packages\sklearn\linear_model\_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=1.01455e-17): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2023-03-20 17:53:09,423:WARNING:C:\Users\Roshan\anaconda3\lib\site-packages\sklearn\linear_model\_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=5.15401e-17): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2023-03-20 17:53:09,471:WARNING:C:\Users\Roshan\anaconda3\lib\site-packages\sklearn\linear_model\_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=7.47341e-17): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2023-03-20 17:53:09,555:WARNING:C:\Users\Roshan\anaconda3\lib\site-packages\sklearn\linear_model\_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=9.3597e-17): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2023-03-20 17:53:09,566:WARNING:C:\Users\Roshan\anaconda3\lib\site-packages\sklearn\linear_model\_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=9.66923e-17): result may not be accurate.
  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T

2023-03-20 17:53:09,837:INFO:Calculating mean and std
2023-03-20 17:53:09,837:INFO:Creating metrics dataframe
2023-03-20 17:53:09,837:INFO:Uploading results into container
2023-03-20 17:53:09,837:INFO:Uploading model into container now
2023-03-20 17:53:09,837:INFO:_master_model_container: 3
2023-03-20 17:53:09,837:INFO:_display_container: 2
2023-03-20 17:53:09,837:INFO:Ridge(random_state=807)
2023-03-20 17:53:09,837:INFO:create_model() successfully completed......................................
2023-03-20 17:53:10,024:INFO:SubProcess create_model() end ==================================
2023-03-20 17:53:10,024:INFO:Creating metrics dataframe
2023-03-20 17:53:10,024:INFO:Initializing Elastic Net
2023-03-20 17:53:10,024:INFO:Total runtime is 0.31928674777348837 minutes
2023-03-20 17:53:10,024:INFO:SubProcess create_model() called ==================================
2023-03-20 17:53:10,024:INFO:Initializing create_model()
2023-03-20 17:53:10,024:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E87127AB80>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E86F80FB20>, model_only=True, return_train_score=False, kwargs={})
2023-03-20 17:53:10,024:INFO:Checking exceptions
2023-03-20 17:53:10,024:INFO:Importing libraries
2023-03-20 17:53:10,024:INFO:Copying training dataset
2023-03-20 17:53:10,040:INFO:Defining folds
2023-03-20 17:53:10,040:INFO:Declaring metric variables
2023-03-20 17:53:10,040:INFO:Importing untrained model
2023-03-20 17:53:10,040:INFO:Elastic Net Imported successfully
2023-03-20 17:53:10,040:INFO:Starting cross validation
2023-03-20 17:53:10,040:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-20 17:53:10,796:WARNING:C:\Users\Roshan\anaconda3\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.577e+02, tolerance: 1.877e-01
  model = cd_fast.enet_coordinate_descent(

2023-03-20 17:53:10,827:WARNING:C:\Users\Roshan\anaconda3\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.705e+02, tolerance: 1.886e-01
  model = cd_fast.enet_coordinate_descent(

2023-03-20 17:53:10,874:WARNING:C:\Users\Roshan\anaconda3\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.522e+02, tolerance: 1.868e-01
  model = cd_fast.enet_coordinate_descent(

2023-03-20 17:53:10,890:WARNING:C:\Users\Roshan\anaconda3\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.565e+02, tolerance: 1.881e-01
  model = cd_fast.enet_coordinate_descent(

2023-03-20 17:53:11,001:WARNING:C:\Users\Roshan\anaconda3\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.573e+02, tolerance: 1.880e-01
  model = cd_fast.enet_coordinate_descent(

2023-03-20 17:53:11,001:WARNING:C:\Users\Roshan\anaconda3\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.878e+02, tolerance: 1.888e-01
  model = cd_fast.enet_coordinate_descent(

2023-03-20 17:53:11,033:WARNING:C:\Users\Roshan\anaconda3\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.533e+02, tolerance: 1.880e-01
  model = cd_fast.enet_coordinate_descent(

2023-03-20 17:53:11,096:WARNING:C:\Users\Roshan\anaconda3\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.797e+02, tolerance: 1.869e-01
  model = cd_fast.enet_coordinate_descent(

2023-03-20 17:53:11,112:WARNING:C:\Users\Roshan\anaconda3\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.752e+02, tolerance: 1.880e-01
  model = cd_fast.enet_coordinate_descent(

2023-03-20 17:53:11,135:WARNING:C:\Users\Roshan\anaconda3\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.878e+01, tolerance: 1.860e-01
  model = cd_fast.enet_coordinate_descent(

2023-03-20 17:53:11,474:INFO:Calculating mean and std
2023-03-20 17:53:11,474:INFO:Creating metrics dataframe
2023-03-20 17:53:11,474:INFO:Uploading results into container
2023-03-20 17:53:11,474:INFO:Uploading model into container now
2023-03-20 17:53:11,474:INFO:_master_model_container: 4
2023-03-20 17:53:11,474:INFO:_display_container: 2
2023-03-20 17:53:11,489:INFO:ElasticNet(random_state=807)
2023-03-20 17:53:11,489:INFO:create_model() successfully completed......................................
2023-03-20 17:53:11,678:INFO:SubProcess create_model() end ==================================
2023-03-20 17:53:11,678:INFO:Creating metrics dataframe
2023-03-20 17:53:11,678:INFO:Initializing Least Angle Regression
2023-03-20 17:53:11,678:INFO:Total runtime is 0.34685075283050537 minutes
2023-03-20 17:53:11,678:INFO:SubProcess create_model() called ==================================
2023-03-20 17:53:11,678:INFO:Initializing create_model()
2023-03-20 17:53:11,694:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E87127AB80>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E86F80FB20>, model_only=True, return_train_score=False, kwargs={})
2023-03-20 17:53:11,694:INFO:Checking exceptions
2023-03-20 17:53:11,694:INFO:Importing libraries
2023-03-20 17:53:11,694:INFO:Copying training dataset
2023-03-20 17:53:11,701:INFO:Defining folds
2023-03-20 17:53:11,701:INFO:Declaring metric variables
2023-03-20 17:53:11,701:INFO:Importing untrained model
2023-03-20 17:53:11,701:INFO:Least Angle Regression Imported successfully
2023-03-20 17:53:11,701:INFO:Starting cross validation
2023-03-20 17:53:11,710:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-20 17:53:12,167:WARNING:C:\Users\Roshan\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-03-20 17:53:12,209:WARNING:C:\Users\Roshan\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-03-20 17:53:12,229:WARNING:C:\Users\Roshan\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-03-20 17:53:12,261:WARNING:C:\Users\Roshan\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-03-20 17:53:12,293:WARNING:C:\Users\Roshan\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-03-20 17:53:12,326:WARNING:C:\Users\Roshan\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-03-20 17:53:12,355:WARNING:C:\Users\Roshan\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-03-20 17:53:12,387:WARNING:C:\Users\Roshan\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-03-20 17:53:12,419:WARNING:C:\Users\Roshan\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-03-20 17:53:12,451:WARNING:C:\Users\Roshan\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-03-20 17:53:12,751:INFO:Calculating mean and std
2023-03-20 17:53:12,751:INFO:Creating metrics dataframe
2023-03-20 17:53:12,766:INFO:Uploading results into container
2023-03-20 17:53:12,766:INFO:Uploading model into container now
2023-03-20 17:53:12,766:INFO:_master_model_container: 5
2023-03-20 17:53:12,766:INFO:_display_container: 2
2023-03-20 17:53:12,766:INFO:Lars(random_state=807)
2023-03-20 17:53:12,766:INFO:create_model() successfully completed......................................
2023-03-20 17:53:12,938:INFO:SubProcess create_model() end ==================================
2023-03-20 17:53:12,938:INFO:Creating metrics dataframe
2023-03-20 17:53:12,938:INFO:Initializing Lasso Least Angle Regression
2023-03-20 17:53:12,938:INFO:Total runtime is 0.3678537607192993 minutes
2023-03-20 17:53:12,938:INFO:SubProcess create_model() called ==================================
2023-03-20 17:53:12,938:INFO:Initializing create_model()
2023-03-20 17:53:12,938:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E87127AB80>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E86F80FB20>, model_only=True, return_train_score=False, kwargs={})
2023-03-20 17:53:12,938:INFO:Checking exceptions
2023-03-20 17:53:12,938:INFO:Importing libraries
2023-03-20 17:53:12,938:INFO:Copying training dataset
2023-03-20 17:53:12,970:INFO:Defining folds
2023-03-20 17:53:12,970:INFO:Declaring metric variables
2023-03-20 17:53:12,970:INFO:Importing untrained model
2023-03-20 17:53:12,970:INFO:Lasso Least Angle Regression Imported successfully
2023-03-20 17:53:12,970:INFO:Starting cross validation
2023-03-20 17:53:12,970:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-20 17:53:13,440:WARNING:C:\Users\Roshan\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-03-20 17:53:13,503:WARNING:C:\Users\Roshan\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-03-20 17:53:13,523:WARNING:C:\Users\Roshan\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-03-20 17:53:13,537:WARNING:C:\Users\Roshan\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-03-20 17:53:13,566:WARNING:C:\Users\Roshan\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-03-20 17:53:13,586:WARNING:C:\Users\Roshan\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-03-20 17:53:13,629:WARNING:C:\Users\Roshan\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-03-20 17:53:13,668:WARNING:C:\Users\Roshan\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-03-20 17:53:13,681:WARNING:C:\Users\Roshan\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-03-20 17:53:13,729:WARNING:C:\Users\Roshan\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-03-20 17:53:13,979:INFO:Calculating mean and std
2023-03-20 17:53:13,992:INFO:Creating metrics dataframe
2023-03-20 17:53:13,992:INFO:Uploading results into container
2023-03-20 17:53:13,992:INFO:Uploading model into container now
2023-03-20 17:53:13,992:INFO:_master_model_container: 6
2023-03-20 17:53:13,992:INFO:_display_container: 2
2023-03-20 17:53:13,992:INFO:LassoLars(random_state=807)
2023-03-20 17:53:13,992:INFO:create_model() successfully completed......................................
2023-03-20 17:53:14,165:INFO:SubProcess create_model() end ==================================
2023-03-20 17:53:14,165:INFO:Creating metrics dataframe
2023-03-20 17:53:14,180:INFO:Initializing Orthogonal Matching Pursuit
2023-03-20 17:53:14,180:INFO:Total runtime is 0.38854960997899374 minutes
2023-03-20 17:53:14,180:INFO:SubProcess create_model() called ==================================
2023-03-20 17:53:14,180:INFO:Initializing create_model()
2023-03-20 17:53:14,180:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E87127AB80>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E86F80FB20>, model_only=True, return_train_score=False, kwargs={})
2023-03-20 17:53:14,180:INFO:Checking exceptions
2023-03-20 17:53:14,180:INFO:Importing libraries
2023-03-20 17:53:14,180:INFO:Copying training dataset
2023-03-20 17:53:14,196:INFO:Defining folds
2023-03-20 17:53:14,196:INFO:Declaring metric variables
2023-03-20 17:53:14,196:INFO:Importing untrained model
2023-03-20 17:53:14,196:INFO:Orthogonal Matching Pursuit Imported successfully
2023-03-20 17:53:14,196:INFO:Starting cross validation
2023-03-20 17:53:14,196:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-20 17:53:14,652:WARNING:C:\Users\Roshan\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-03-20 17:53:14,683:WARNING:C:\Users\Roshan\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-03-20 17:53:14,730:WARNING:C:\Users\Roshan\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-03-20 17:53:14,746:WARNING:C:\Users\Roshan\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-03-20 17:53:14,777:WARNING:C:\Users\Roshan\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-03-20 17:53:14,799:WARNING:C:\Users\Roshan\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-03-20 17:53:14,825:WARNING:C:\Users\Roshan\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-03-20 17:53:14,868:WARNING:C:\Users\Roshan\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-03-20 17:53:14,890:WARNING:C:\Users\Roshan\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-03-20 17:53:14,937:WARNING:C:\Users\Roshan\anaconda3\lib\site-packages\sklearn\linear_model\_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-03-20 17:53:15,203:INFO:Calculating mean and std
2023-03-20 17:53:15,203:INFO:Creating metrics dataframe
2023-03-20 17:53:15,203:INFO:Uploading results into container
2023-03-20 17:53:15,203:INFO:Uploading model into container now
2023-03-20 17:53:15,203:INFO:_master_model_container: 7
2023-03-20 17:53:15,203:INFO:_display_container: 2
2023-03-20 17:53:15,203:INFO:OrthogonalMatchingPursuit()
2023-03-20 17:53:15,203:INFO:create_model() successfully completed......................................
2023-03-20 17:53:15,414:INFO:SubProcess create_model() end ==================================
2023-03-20 17:53:15,414:INFO:Creating metrics dataframe
2023-03-20 17:53:15,422:INFO:Initializing Bayesian Ridge
2023-03-20 17:53:15,422:INFO:Total runtime is 0.4092538158098857 minutes
2023-03-20 17:53:15,422:INFO:SubProcess create_model() called ==================================
2023-03-20 17:53:15,422:INFO:Initializing create_model()
2023-03-20 17:53:15,422:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E87127AB80>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E86F80FB20>, model_only=True, return_train_score=False, kwargs={})
2023-03-20 17:53:15,422:INFO:Checking exceptions
2023-03-20 17:53:15,422:INFO:Importing libraries
2023-03-20 17:53:15,422:INFO:Copying training dataset
2023-03-20 17:53:15,438:INFO:Defining folds
2023-03-20 17:53:15,438:INFO:Declaring metric variables
2023-03-20 17:53:15,438:INFO:Importing untrained model
2023-03-20 17:53:15,438:INFO:Bayesian Ridge Imported successfully
2023-03-20 17:53:15,438:INFO:Starting cross validation
2023-03-20 17:53:15,438:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-20 17:53:16,448:INFO:Calculating mean and std
2023-03-20 17:53:16,448:INFO:Creating metrics dataframe
2023-03-20 17:53:16,461:INFO:Uploading results into container
2023-03-20 17:53:16,463:INFO:Uploading model into container now
2023-03-20 17:53:16,463:INFO:_master_model_container: 8
2023-03-20 17:53:16,463:INFO:_display_container: 2
2023-03-20 17:53:16,463:INFO:BayesianRidge()
2023-03-20 17:53:16,463:INFO:create_model() successfully completed......................................
2023-03-20 17:53:16,634:INFO:SubProcess create_model() end ==================================
2023-03-20 17:53:16,634:INFO:Creating metrics dataframe
2023-03-20 17:53:16,634:INFO:Initializing Passive Aggressive Regressor
2023-03-20 17:53:16,634:INFO:Total runtime is 0.4294405420621236 minutes
2023-03-20 17:53:16,634:INFO:SubProcess create_model() called ==================================
2023-03-20 17:53:16,634:INFO:Initializing create_model()
2023-03-20 17:53:16,649:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E87127AB80>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E86F80FB20>, model_only=True, return_train_score=False, kwargs={})
2023-03-20 17:53:16,649:INFO:Checking exceptions
2023-03-20 17:53:16,649:INFO:Importing libraries
2023-03-20 17:53:16,649:INFO:Copying training dataset
2023-03-20 17:53:16,651:INFO:Defining folds
2023-03-20 17:53:16,651:INFO:Declaring metric variables
2023-03-20 17:53:16,651:INFO:Importing untrained model
2023-03-20 17:53:16,651:INFO:Passive Aggressive Regressor Imported successfully
2023-03-20 17:53:16,651:INFO:Starting cross validation
2023-03-20 17:53:16,651:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-20 17:53:17,643:INFO:Calculating mean and std
2023-03-20 17:53:17,643:INFO:Creating metrics dataframe
2023-03-20 17:53:17,658:INFO:Uploading results into container
2023-03-20 17:53:17,658:INFO:Uploading model into container now
2023-03-20 17:53:17,658:INFO:_master_model_container: 9
2023-03-20 17:53:17,658:INFO:_display_container: 2
2023-03-20 17:53:17,658:INFO:PassiveAggressiveRegressor(random_state=807)
2023-03-20 17:53:17,658:INFO:create_model() successfully completed......................................
2023-03-20 17:53:17,839:INFO:SubProcess create_model() end ==================================
2023-03-20 17:53:17,840:INFO:Creating metrics dataframe
2023-03-20 17:53:17,840:INFO:Initializing Huber Regressor
2023-03-20 17:53:17,840:INFO:Total runtime is 0.44954714775085447 minutes
2023-03-20 17:53:17,840:INFO:SubProcess create_model() called ==================================
2023-03-20 17:53:17,840:INFO:Initializing create_model()
2023-03-20 17:53:17,840:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E87127AB80>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E86F80FB20>, model_only=True, return_train_score=False, kwargs={})
2023-03-20 17:53:17,849:INFO:Checking exceptions
2023-03-20 17:53:17,849:INFO:Importing libraries
2023-03-20 17:53:17,849:INFO:Copying training dataset
2023-03-20 17:53:17,849:INFO:Defining folds
2023-03-20 17:53:17,849:INFO:Declaring metric variables
2023-03-20 17:53:17,849:INFO:Importing untrained model
2023-03-20 17:53:17,849:INFO:Huber Regressor Imported successfully
2023-03-20 17:53:17,849:INFO:Starting cross validation
2023-03-20 17:53:17,849:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-20 17:53:19,248:INFO:Calculating mean and std
2023-03-20 17:53:19,248:INFO:Creating metrics dataframe
2023-03-20 17:53:19,264:INFO:Uploading results into container
2023-03-20 17:53:19,264:INFO:Uploading model into container now
2023-03-20 17:53:19,264:INFO:_master_model_container: 10
2023-03-20 17:53:19,264:INFO:_display_container: 2
2023-03-20 17:53:19,264:INFO:HuberRegressor()
2023-03-20 17:53:19,264:INFO:create_model() successfully completed......................................
2023-03-20 17:53:19,437:INFO:SubProcess create_model() end ==================================
2023-03-20 17:53:19,437:INFO:Creating metrics dataframe
2023-03-20 17:53:19,437:INFO:Initializing K Neighbors Regressor
2023-03-20 17:53:19,437:INFO:Total runtime is 0.4761624733606974 minutes
2023-03-20 17:53:19,437:INFO:SubProcess create_model() called ==================================
2023-03-20 17:53:19,453:INFO:Initializing create_model()
2023-03-20 17:53:19,453:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E87127AB80>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E86F80FB20>, model_only=True, return_train_score=False, kwargs={})
2023-03-20 17:53:19,453:INFO:Checking exceptions
2023-03-20 17:53:19,453:INFO:Importing libraries
2023-03-20 17:53:19,453:INFO:Copying training dataset
2023-03-20 17:53:19,455:INFO:Defining folds
2023-03-20 17:53:19,455:INFO:Declaring metric variables
2023-03-20 17:53:19,455:INFO:Importing untrained model
2023-03-20 17:53:19,455:INFO:K Neighbors Regressor Imported successfully
2023-03-20 17:53:19,455:INFO:Starting cross validation
2023-03-20 17:53:19,455:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-20 17:53:20,568:INFO:Calculating mean and std
2023-03-20 17:53:20,575:INFO:Creating metrics dataframe
2023-03-20 17:53:20,575:INFO:Uploading results into container
2023-03-20 17:53:20,575:INFO:Uploading model into container now
2023-03-20 17:53:20,575:INFO:_master_model_container: 11
2023-03-20 17:53:20,575:INFO:_display_container: 2
2023-03-20 17:53:20,575:INFO:KNeighborsRegressor(n_jobs=-1)
2023-03-20 17:53:20,575:INFO:create_model() successfully completed......................................
2023-03-20 17:53:20,762:INFO:SubProcess create_model() end ==================================
2023-03-20 17:53:20,767:INFO:Creating metrics dataframe
2023-03-20 17:53:20,784:INFO:Initializing Decision Tree Regressor
2023-03-20 17:53:20,784:INFO:Total runtime is 0.4986175894737243 minutes
2023-03-20 17:53:20,784:INFO:SubProcess create_model() called ==================================
2023-03-20 17:53:20,784:INFO:Initializing create_model()
2023-03-20 17:53:20,784:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E87127AB80>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E86F80FB20>, model_only=True, return_train_score=False, kwargs={})
2023-03-20 17:53:20,784:INFO:Checking exceptions
2023-03-20 17:53:20,784:INFO:Importing libraries
2023-03-20 17:53:20,784:INFO:Copying training dataset
2023-03-20 17:53:20,798:INFO:Defining folds
2023-03-20 17:53:20,798:INFO:Declaring metric variables
2023-03-20 17:53:20,798:INFO:Importing untrained model
2023-03-20 17:53:20,798:INFO:Decision Tree Regressor Imported successfully
2023-03-20 17:53:20,798:INFO:Starting cross validation
2023-03-20 17:53:20,798:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-20 17:53:22,078:INFO:Calculating mean and std
2023-03-20 17:53:22,078:INFO:Creating metrics dataframe
2023-03-20 17:53:22,078:INFO:Uploading results into container
2023-03-20 17:53:22,093:INFO:Uploading model into container now
2023-03-20 17:53:22,093:INFO:_master_model_container: 12
2023-03-20 17:53:22,093:INFO:_display_container: 2
2023-03-20 17:53:22,093:INFO:DecisionTreeRegressor(random_state=807)
2023-03-20 17:53:22,093:INFO:create_model() successfully completed......................................
2023-03-20 17:53:22,266:INFO:SubProcess create_model() end ==================================
2023-03-20 17:53:22,266:INFO:Creating metrics dataframe
2023-03-20 17:53:22,284:INFO:Initializing Random Forest Regressor
2023-03-20 17:53:22,284:INFO:Total runtime is 0.5236156026522318 minutes
2023-03-20 17:53:22,284:INFO:SubProcess create_model() called ==================================
2023-03-20 17:53:22,284:INFO:Initializing create_model()
2023-03-20 17:53:22,284:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E87127AB80>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E86F80FB20>, model_only=True, return_train_score=False, kwargs={})
2023-03-20 17:53:22,284:INFO:Checking exceptions
2023-03-20 17:53:22,284:INFO:Importing libraries
2023-03-20 17:53:22,284:INFO:Copying training dataset
2023-03-20 17:53:22,298:INFO:Defining folds
2023-03-20 17:53:22,298:INFO:Declaring metric variables
2023-03-20 17:53:22,298:INFO:Importing untrained model
2023-03-20 17:53:22,298:INFO:Random Forest Regressor Imported successfully
2023-03-20 17:53:22,298:INFO:Starting cross validation
2023-03-20 17:53:22,298:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-20 17:53:28,731:WARNING:C:\Users\Roshan\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 1.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-20 17:53:30,978:WARNING:C:\Users\Roshan\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 1.75s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-20 17:53:31,405:WARNING:C:\Users\Roshan\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 1.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-20 17:53:31,546:WARNING:C:\Users\Roshan\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 1.10s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-20 17:53:33,157:WARNING:C:\Users\Roshan\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.69s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-20 17:53:33,845:WARNING:C:\Users\Roshan\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:295: UserWarning: Persisting input arguments took 1.35s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-03-20 17:53:33,864:WARNING:C:\Users\Roshan\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.75s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-20 17:53:34,773:INFO:Calculating mean and std
2023-03-20 17:53:34,773:INFO:Creating metrics dataframe
2023-03-20 17:53:34,773:INFO:Uploading results into container
2023-03-20 17:53:34,773:INFO:Uploading model into container now
2023-03-20 17:53:34,773:INFO:_master_model_container: 13
2023-03-20 17:53:34,773:INFO:_display_container: 2
2023-03-20 17:53:34,773:INFO:RandomForestRegressor(n_jobs=-1, random_state=807)
2023-03-20 17:53:34,773:INFO:create_model() successfully completed......................................
2023-03-20 17:53:34,963:INFO:SubProcess create_model() end ==================================
2023-03-20 17:53:34,963:INFO:Creating metrics dataframe
2023-03-20 17:53:34,963:INFO:Initializing Extra Trees Regressor
2023-03-20 17:53:34,963:INFO:Total runtime is 0.734930153687795 minutes
2023-03-20 17:53:34,963:INFO:SubProcess create_model() called ==================================
2023-03-20 17:53:34,963:INFO:Initializing create_model()
2023-03-20 17:53:34,963:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E87127AB80>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E86F80FB20>, model_only=True, return_train_score=False, kwargs={})
2023-03-20 17:53:34,963:INFO:Checking exceptions
2023-03-20 17:53:34,963:INFO:Importing libraries
2023-03-20 17:53:34,963:INFO:Copying training dataset
2023-03-20 17:53:34,979:INFO:Defining folds
2023-03-20 17:53:34,979:INFO:Declaring metric variables
2023-03-20 17:53:34,979:INFO:Importing untrained model
2023-03-20 17:53:34,979:INFO:Extra Trees Regressor Imported successfully
2023-03-20 17:53:34,979:INFO:Starting cross validation
2023-03-20 17:53:34,979:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-20 17:53:37,155:WARNING:C:\Users\Roshan\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:230: UserWarning: Persisting input arguments took 0.67s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-03-20 17:53:38,328:WARNING:C:\Users\Roshan\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.57s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-20 17:53:39,782:WARNING:C:\Users\Roshan\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.78s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-20 17:53:39,985:WARNING:C:\Users\Roshan\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 1.02s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-20 17:53:40,079:WARNING:C:\Users\Roshan\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:252: UserWarning: Persisting input arguments took 0.72s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-03-20 17:53:41,278:INFO:Calculating mean and std
2023-03-20 17:53:41,278:INFO:Creating metrics dataframe
2023-03-20 17:53:41,278:INFO:Uploading results into container
2023-03-20 17:53:41,278:INFO:Uploading model into container now
2023-03-20 17:53:41,278:INFO:_master_model_container: 14
2023-03-20 17:53:41,278:INFO:_display_container: 2
2023-03-20 17:53:41,278:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=807)
2023-03-20 17:53:41,278:INFO:create_model() successfully completed......................................
2023-03-20 17:53:41,482:INFO:SubProcess create_model() end ==================================
2023-03-20 17:53:41,482:INFO:Creating metrics dataframe
2023-03-20 17:53:41,482:INFO:Initializing AdaBoost Regressor
2023-03-20 17:53:41,482:INFO:Total runtime is 0.8435829162597657 minutes
2023-03-20 17:53:41,482:INFO:SubProcess create_model() called ==================================
2023-03-20 17:53:41,482:INFO:Initializing create_model()
2023-03-20 17:53:41,482:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E87127AB80>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E86F80FB20>, model_only=True, return_train_score=False, kwargs={})
2023-03-20 17:53:41,482:INFO:Checking exceptions
2023-03-20 17:53:41,482:INFO:Importing libraries
2023-03-20 17:53:41,482:INFO:Copying training dataset
2023-03-20 17:53:41,498:INFO:Defining folds
2023-03-20 17:53:41,498:INFO:Declaring metric variables
2023-03-20 17:53:41,498:INFO:Importing untrained model
2023-03-20 17:53:41,498:INFO:AdaBoost Regressor Imported successfully
2023-03-20 17:53:41,498:INFO:Starting cross validation
2023-03-20 17:53:41,498:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-20 17:53:44,846:INFO:Calculating mean and std
2023-03-20 17:53:44,846:INFO:Creating metrics dataframe
2023-03-20 17:53:44,862:INFO:Uploading results into container
2023-03-20 17:53:44,862:INFO:Uploading model into container now
2023-03-20 17:53:44,862:INFO:_master_model_container: 15
2023-03-20 17:53:44,862:INFO:_display_container: 2
2023-03-20 17:53:44,862:INFO:AdaBoostRegressor(random_state=807)
2023-03-20 17:53:44,862:INFO:create_model() successfully completed......................................
2023-03-20 17:53:45,036:INFO:SubProcess create_model() end ==================================
2023-03-20 17:53:45,036:INFO:Creating metrics dataframe
2023-03-20 17:53:45,036:INFO:Initializing Gradient Boosting Regressor
2023-03-20 17:53:45,036:INFO:Total runtime is 0.9028126915295919 minutes
2023-03-20 17:53:45,036:INFO:SubProcess create_model() called ==================================
2023-03-20 17:53:45,036:INFO:Initializing create_model()
2023-03-20 17:53:45,050:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E87127AB80>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E86F80FB20>, model_only=True, return_train_score=False, kwargs={})
2023-03-20 17:53:45,050:INFO:Checking exceptions
2023-03-20 17:53:45,050:INFO:Importing libraries
2023-03-20 17:53:45,050:INFO:Copying training dataset
2023-03-20 17:53:45,052:INFO:Defining folds
2023-03-20 17:53:45,052:INFO:Declaring metric variables
2023-03-20 17:53:45,052:INFO:Importing untrained model
2023-03-20 17:53:45,052:INFO:Gradient Boosting Regressor Imported successfully
2023-03-20 17:53:45,052:INFO:Starting cross validation
2023-03-20 17:53:45,052:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-20 17:53:52,952:INFO:Calculating mean and std
2023-03-20 17:53:52,952:INFO:Creating metrics dataframe
2023-03-20 17:53:52,967:INFO:Uploading results into container
2023-03-20 17:53:52,967:INFO:Uploading model into container now
2023-03-20 17:53:52,967:INFO:_master_model_container: 16
2023-03-20 17:53:52,967:INFO:_display_container: 2
2023-03-20 17:53:52,967:INFO:GradientBoostingRegressor(random_state=807)
2023-03-20 17:53:52,967:INFO:create_model() successfully completed......................................
2023-03-20 17:53:53,141:INFO:SubProcess create_model() end ==================================
2023-03-20 17:53:53,141:INFO:Creating metrics dataframe
2023-03-20 17:53:53,156:INFO:Initializing Light Gradient Boosting Machine
2023-03-20 17:53:53,156:INFO:Total runtime is 1.0381518205006917 minutes
2023-03-20 17:53:53,156:INFO:SubProcess create_model() called ==================================
2023-03-20 17:53:53,156:INFO:Initializing create_model()
2023-03-20 17:53:53,156:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E87127AB80>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E86F80FB20>, model_only=True, return_train_score=False, kwargs={})
2023-03-20 17:53:53,156:INFO:Checking exceptions
2023-03-20 17:53:53,156:INFO:Importing libraries
2023-03-20 17:53:53,156:INFO:Copying training dataset
2023-03-20 17:53:53,156:INFO:Defining folds
2023-03-20 17:53:53,156:INFO:Declaring metric variables
2023-03-20 17:53:53,156:INFO:Importing untrained model
2023-03-20 17:53:53,156:INFO:Light Gradient Boosting Machine Imported successfully
2023-03-20 17:53:53,172:INFO:Starting cross validation
2023-03-20 17:53:53,172:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-20 17:53:56,484:INFO:Calculating mean and std
2023-03-20 17:53:56,484:INFO:Creating metrics dataframe
2023-03-20 17:53:56,487:INFO:Uploading results into container
2023-03-20 17:53:56,487:INFO:Uploading model into container now
2023-03-20 17:53:56,487:INFO:_master_model_container: 17
2023-03-20 17:53:56,487:INFO:_display_container: 2
2023-03-20 17:53:56,487:INFO:LGBMRegressor(random_state=807)
2023-03-20 17:53:56,487:INFO:create_model() successfully completed......................................
2023-03-20 17:53:56,670:INFO:SubProcess create_model() end ==================================
2023-03-20 17:53:56,670:INFO:Creating metrics dataframe
2023-03-20 17:53:56,672:INFO:Initializing Dummy Regressor
2023-03-20 17:53:56,672:INFO:Total runtime is 1.096747076511383 minutes
2023-03-20 17:53:56,672:INFO:SubProcess create_model() called ==================================
2023-03-20 17:53:56,672:INFO:Initializing create_model()
2023-03-20 17:53:56,672:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E87127AB80>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E86F80FB20>, model_only=True, return_train_score=False, kwargs={})
2023-03-20 17:53:56,672:INFO:Checking exceptions
2023-03-20 17:53:56,672:INFO:Importing libraries
2023-03-20 17:53:56,672:INFO:Copying training dataset
2023-03-20 17:53:56,688:INFO:Defining folds
2023-03-20 17:53:56,688:INFO:Declaring metric variables
2023-03-20 17:53:56,688:INFO:Importing untrained model
2023-03-20 17:53:56,688:INFO:Dummy Regressor Imported successfully
2023-03-20 17:53:56,694:INFO:Starting cross validation
2023-03-20 17:53:56,694:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-03-20 17:53:57,665:INFO:Calculating mean and std
2023-03-20 17:53:57,675:INFO:Creating metrics dataframe
2023-03-20 17:53:57,676:INFO:Uploading results into container
2023-03-20 17:53:57,676:INFO:Uploading model into container now
2023-03-20 17:53:57,676:INFO:_master_model_container: 18
2023-03-20 17:53:57,676:INFO:_display_container: 2
2023-03-20 17:53:57,681:INFO:DummyRegressor()
2023-03-20 17:53:57,681:INFO:create_model() successfully completed......................................
2023-03-20 17:53:57,854:INFO:SubProcess create_model() end ==================================
2023-03-20 17:53:57,854:INFO:Creating metrics dataframe
2023-03-20 17:53:57,872:INFO:Initializing create_model()
2023-03-20 17:53:57,872:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E87127AB80>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=807), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-03-20 17:53:57,872:INFO:Checking exceptions
2023-03-20 17:53:57,872:INFO:Importing libraries
2023-03-20 17:53:57,872:INFO:Copying training dataset
2023-03-20 17:53:57,872:INFO:Defining folds
2023-03-20 17:53:57,872:INFO:Declaring metric variables
2023-03-20 17:53:57,872:INFO:Importing untrained model
2023-03-20 17:53:57,872:INFO:Declaring custom model
2023-03-20 17:53:57,872:INFO:Extra Trees Regressor Imported successfully
2023-03-20 17:53:57,886:INFO:Cross validation set to False
2023-03-20 17:53:57,886:INFO:Fitting Model
2023-03-20 17:53:59,132:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=807)
2023-03-20 17:53:59,132:INFO:create_model() successfully completed......................................
2023-03-20 17:53:59,335:INFO:_master_model_container: 18
2023-03-20 17:53:59,335:INFO:_display_container: 2
2023-03-20 17:53:59,335:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=807)
2023-03-20 17:53:59,335:INFO:compare_models() successfully completed......................................
2023-03-20 17:53:59,388:INFO:Initializing save_model()
2023-03-20 17:53:59,388:INFO:save_model(model=ExtraTreesRegressor(n_jobs=-1, random_state=807), model_name=best_model, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\Roshan\AppData\Local\Temp\joblib),
         steps=[('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('numerical_imputer',
                 TransformerWrapper(include=['Unnamed: 0', 'Total Volume',
                                             '4046', '4225', '4770',
                                             'Total Bags', 'Small Bags',
                                             'Large Bags', 'XLarge Bags',
                                             'year'],
                                    transformer=SimpleImputer())),
                ('categ...
                 TransformerWrapper(include=['type'],
                                    transformer=OrdinalEncoder(cols=['type'],
                                                               handle_missing='return_nan',
                                                               mapping=[{'col': 'type',
                                                                         'data_type': dtype('O'),
                                                                         'mapping': conventional    0
organic         1
NaN            -1
dtype: int64}]))),
                ('rest_encoding',
                 TransformerWrapper(include=['Date', 'region'],
                                    transformer=LeaveOneOutEncoder(cols=['Date',
                                                                         'region'],
                                                                   handle_missing='return_nan',
                                                                   random_state=807)))]), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2023-03-20 17:53:59,388:INFO:Adding model into prep_pipe
2023-03-20 17:53:59,590:INFO:best_model.pkl saved in current working directory
2023-03-20 17:53:59,622:INFO:Pipeline(memory=FastMemory(location=C:\Users\Roshan\AppData\Local\Temp\joblib),
         steps=[('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('numerical_imputer',
                 TransformerWrapper(include=['Unnamed: 0', 'Total Volume',
                                             '4046', '4225', '4770',
                                             'Total Bags', 'Small Bags',
                                             'Large Bags', 'XLarge Bags',
                                             'year'],
                                    transformer=SimpleImputer())),
                ('categ...
                                                               handle_missing='return_nan',
                                                               mapping=[{'col': 'type',
                                                                         'data_type': dtype('O'),
                                                                         'mapping': conventional    0
organic         1
NaN            -1
dtype: int64}]))),
                ('rest_encoding',
                 TransformerWrapper(include=['Date', 'region'],
                                    transformer=LeaveOneOutEncoder(cols=['Date',
                                                                         'region'],
                                                                   handle_missing='return_nan',
                                                                   random_state=807))),
                ('trained_model',
                 ExtraTreesRegressor(n_jobs=-1, random_state=807))])
2023-03-20 17:53:59,622:INFO:save_model() successfully completed......................................
2023-12-02 17:19:55,087:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-12-02 17:19:55,088:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-12-02 17:19:55,088:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-12-02 17:19:55,088:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-12-02 17:19:55,814:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-12-09 19:08:26,489:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-12-09 19:08:26,489:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-12-09 19:08:26,489:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-12-09 19:08:26,489:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-12-09 19:08:27,181:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
